{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from faker import Faker\n",
    "import random\n",
    "np.random.seed()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "palindromes = []\n",
    "for i in range(1024):\n",
    "    binary_string = format(i, '010b')\n",
    "    x.append(binary_string)\n",
    "    if binary_string == binary_string[::-1]:\n",
    "        palindromes.append(binary_string)\n",
    "x = np.array(x)\n",
    "palindromes = np.array(palindromes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0000000000', '0000110000', '0001001000', '0001111000',\n",
       "       '0010000100', '0010110100', '0011001100', '0011111100',\n",
       "       '0100000010', '0100110010', '0101001010', '0101111010',\n",
       "       '0110000110', '0110110110', '0111001110', '0111111110',\n",
       "       '1000000001', '1000110001', '1001001001', '1001111001',\n",
       "       '1010000101', '1010110101', '1011001101', '1011111101',\n",
       "       '1100000011', '1100110011', '1101001011', '1101111011',\n",
       "       '1110000111', '1110110111', '1111001111', '1111111111'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0110110110', '1101001011', '0010110100', '0001001000',\n",
       "       '0110000110', '1011111101', '0100000010', '1010110101',\n",
       "       '0000000000', '0011111100', '1001001001', '0011001100',\n",
       "       '0111001110', '1011001101', '1001111001', '1000110001',\n",
       "       '1000000001', '0101001010', '1110110111', '0001111000',\n",
       "       '0111111110', '1110000111', '0010000100', '1101111011',\n",
       "       '0101111010', '1100110011', '1111001111', '0100110010',\n",
       "       '0000110000', '1100000011', '1111111111', '1010000101'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(palindromes)\n",
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = np.concatenate((x, palindromes))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for binary_string in x:\n",
    "    y.append(binary_string == binary_string[::-1])\n",
    "y = np.array(y)\n",
    "permutation_index = np.random.permutation(len(x))\n",
    "x = x[permutation_index]\n",
    "y = y[permutation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   6, -12])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.array([1, 2, -3])\n",
    "# b = np.array([2, 3, 4])\n",
    "# a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 20\n",
    "output_size = 1\n",
    "\n",
    "weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[991.61380209]]\n",
      "Epoch 100 : loss [[989.2316454]]\n",
      "Epoch 200 : loss [[319.53270712]]\n",
      "Epoch 300 : loss [[319.57421463]]\n",
      "Epoch 400 : loss [[319.61364199]]\n",
      "Epoch 500 : loss [[319.6512102]]\n",
      "Epoch 600 : loss [[319.6870946]]\n",
      "Epoch 700 : loss [[319.72143354]]\n",
      "Epoch 800 : loss [[319.75433739]]\n",
      "Epoch 900 : loss [[319.78589815]]\n",
      "Epoch 1000 : loss [[319.81620019]]\n",
      "Epoch 1100 : loss [[319.84533201]]\n",
      "Epoch 1200 : loss [[319.87339917]]\n",
      "Epoch 1300 : loss [[319.90053773]]\n",
      "Epoch 1400 : loss [[319.92692755]]\n",
      "Epoch 1500 : loss [[319.9528046]]\n",
      "Epoch 1600 : loss [[319.97847091]]\n",
      "Epoch 1700 : loss [[320.00430116]]\n",
      "Epoch 1800 : loss [[320.03074492]]\n",
      "Epoch 1900 : loss [[320.05832377]]\n",
      "Epoch 2000 : loss [[320.08762303]]\n",
      "Epoch 2100 : loss [[320.11927799]]\n",
      "Epoch 2200 : loss [[320.15395461]]\n",
      "Epoch 2300 : loss [[320.19232432]]\n",
      "Epoch 2400 : loss [[320.23503171]]\n",
      "Epoch 2500 : loss [[320.28265285]]\n",
      "Epoch 2600 : loss [[320.33564028]]\n",
      "Epoch 2700 : loss [[320.39424877]]\n",
      "Epoch 2800 : loss [[320.45843371]]\n",
      "Epoch 2900 : loss [[320.52771224]]\n",
      "Epoch 3000 : loss [[320.60097475]]\n",
      "Epoch 3100 : loss [[320.67623404]]\n",
      "Epoch 3200 : loss [[320.75029944]]\n",
      "Epoch 3300 : loss [[320.81836663]]\n",
      "Epoch 3400 : loss [[320.87352024]]\n",
      "Epoch 3500 : loss [[320.90615562]]\n",
      "Epoch 3600 : loss [[320.90333478]]\n",
      "Epoch 3700 : loss [[320.84808857]]\n",
      "Epoch 3800 : loss [[320.71864462]]\n",
      "Epoch 3900 : loss [[320.48748889]]\n",
      "Epoch 4000 : loss [[320.12009745]]\n",
      "Epoch 4100 : loss [[319.57321731]]\n",
      "Epoch 4200 : loss [[318.79283617]]\n",
      "Epoch 4300 : loss [[317.71237063]]\n",
      "Epoch 4400 : loss [[316.25183063]]\n",
      "Epoch 4500 : loss [[314.31860957]]\n",
      "Epoch 4600 : loss [[311.81032712]]\n",
      "Epoch 4700 : loss [[308.62023224]]\n",
      "Epoch 4800 : loss [[304.64616066]]\n",
      "Epoch 4900 : loss [[299.80425637]]\n",
      "Epoch 5000 : loss [[294.04706493]]\n",
      "Epoch 5100 : loss [[287.38122968]]\n",
      "Epoch 5200 : loss [[279.87587872]]\n",
      "Epoch 5300 : loss [[271.65535658]]\n",
      "Epoch 5400 : loss [[262.87946312]]\n",
      "Epoch 5500 : loss [[253.72091432]]\n",
      "Epoch 5600 : loss [[244.34743878]]\n",
      "Epoch 5700 : loss [[234.9103267]]\n",
      "Epoch 5800 : loss [[225.53835093]]\n",
      "Epoch 5900 : loss [[216.33570851]]\n",
      "Epoch 6000 : loss [[207.38289088]]\n",
      "Epoch 6100 : loss [[198.73939359]]\n",
      "Epoch 6200 : loss [[190.44717023]]\n",
      "Epoch 6300 : loss [[182.53397393]]\n",
      "Epoch 6400 : loss [[175.01614429]]\n",
      "Epoch 6500 : loss [[167.90077537]]\n",
      "Epoch 6600 : loss [[161.18740928]]\n",
      "Epoch 6700 : loss [[154.86944061]]\n",
      "Epoch 6800 : loss [[148.93536325]]\n",
      "Epoch 6900 : loss [[143.36991774]]\n",
      "Epoch 7000 : loss [[138.15514523]]\n",
      "Epoch 7100 : loss [[133.27133094]]\n",
      "Epoch 7200 : loss [[128.69781856]]\n",
      "Epoch 7300 : loss [[124.41368476]]\n",
      "Epoch 7400 : loss [[120.39827326]]\n",
      "Epoch 7500 : loss [[116.6315961]]\n",
      "Epoch 7600 : loss [[113.09461596]]\n",
      "Epoch 7700 : loss [[109.76942693]]\n",
      "Epoch 7800 : loss [[106.6393526]]\n",
      "Epoch 7900 : loss [[103.68898013]]\n",
      "Epoch 8000 : loss [[100.90414718]]\n",
      "Epoch 8100 : loss [[98.27189634]]\n",
      "Epoch 8200 : loss [[95.78040878]]\n",
      "Epoch 8300 : loss [[93.41892608]]\n",
      "Epoch 8400 : loss [[91.1776669]]\n",
      "Epoch 8500 : loss [[89.04774305]]\n",
      "Epoch 8600 : loss [[87.02107814]]\n",
      "Epoch 8700 : loss [[85.09033038]]\n",
      "Epoch 8800 : loss [[83.24882098]]\n",
      "Epoch 8900 : loss [[81.49046816]]\n",
      "Epoch 9000 : loss [[79.80972729]]\n",
      "Epoch 9100 : loss [[78.20153656]]\n",
      "Epoch 9200 : loss [[76.66126823]]\n",
      "Epoch 9300 : loss [[75.18468479]]\n",
      "Epoch 9400 : loss [[73.7678998]]\n",
      "Epoch 9500 : loss [[72.40734284]]\n",
      "Epoch 9600 : loss [[71.09972829]]\n",
      "Epoch 9700 : loss [[69.84202742]]\n",
      "Epoch 9800 : loss [[68.63144352]]\n",
      "Epoch 9900 : loss [[67.46538972]]\n"
     ]
    }
   ],
   "source": [
    "# LEARNING_RATE = 1e-7\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[0.70983834]]\n",
      "Epoch 100 : loss [[0.7091767]]\n",
      "Epoch 200 : loss [[0.70852412]]\n",
      "Epoch 300 : loss [[0.70787714]]\n",
      "Epoch 400 : loss [[0.70723423]]\n",
      "Epoch 500 : loss [[0.70659466]]\n",
      "Epoch 600 : loss [[0.70595803]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m hlayer_output \u001b[38;5;241m=\u001b[39m sigmoid(hlayer_logits)\n\u001b[1;32m      9\u001b[0m final_logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(hlayer_output, weights_ho)\n\u001b[0;32m---> 10\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tot_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(final_output \u001b[38;5;241m-\u001b[39m y[i])\n\u001b[1;32m     14\u001b[0m output_delta \u001b[38;5;241m=\u001b[39m (y[i] \u001b[38;5;241m-\u001b[39m final_output) \u001b[38;5;241m*\u001b[39m final_output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m final_output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99802693]]\n",
      "[[9.87927878e-05]]\n"
     ]
    }
   ],
   "source": [
    "x_test1 = '1100110011'\n",
    "x_test2 = '1100110000'\n",
    "def test(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "    return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)), weights_ho))\n",
    "\n",
    "print(test(x_test1))\n",
    "print(test(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('weights_ih.npy', weights_ih)\n",
    "# np.save('weights_ho.npy', weights_ho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import activation, dataset, losses\n",
    "from model import *\n",
    "import numpy as np\n",
    "# np.random.seed(7)\n",
    "\n",
    "\n",
    "Dataset = dataset.Palindrome_Dataset(n_bits=10)\n",
    "model = Palindrome_Model(input_size=10, output_size=1,hidden_layer_sizes=[4],activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/screa/Desktop/Sem8/CS772/assign1-palindrome/utils/dataset.py:29: UserWarning: you are shuffling a 'flatiter' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(x.flat)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x,y = Dataset.get_data(shuffle=True, biasing_factor=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
       "  'weights': array([[ 0.53395377,  0.23218934, -0.28231011, -0.59693814],\n",
       "         [ 0.45579783, -1.23376619,  0.47297493,  0.09048471],\n",
       "         [ 0.2898087 , -0.40248243, -0.28032975,  0.33549292],\n",
       "         [-0.01318235,  0.78686707, -0.51578312, -0.16396029],\n",
       "         [ 0.92861159,  0.07549704,  1.10145881, -0.23826712],\n",
       "         [ 0.196562  , -0.41292983, -0.29635503, -0.29084583],\n",
       "         [-0.51092125, -0.02046567, -0.99829916,  0.02753536],\n",
       "         [ 0.20506253,  0.06761003, -0.24076845,  0.33732247],\n",
       "         [-0.31232972,  0.45552252, -0.0904001 , -0.1570045 ],\n",
       "         [ 0.04495314,  0.28331099, -0.31902885,  0.09601966]]),\n",
       "  'biases': array([-0.93115687,  1.07258205, -0.89303028,  0.03468321]),\n",
       "  'activation': 'linear'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[-0.26644013],\n",
       "         [-0.31473152],\n",
       "         [ 0.25819514],\n",
       "         [-0.26744164]]),\n",
       "  'biases': array([-0.43499538]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_optimizer(lr=0.001,loss=\"bce\")\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 1664/1664 [00:00<00:00, 7100.98sample/s, accuracy=59.6, loss=1.37e+4]\n",
      "Epoch 2/100: 100%|██████████| 1664/1664 [00:00<00:00, 8654.24sample/s, accuracy=59.6, loss=6.71e+3]\n",
      "Epoch 3/100: 100%|██████████| 1664/1664 [00:00<00:00, 8572.79sample/s, accuracy=59.5, loss=4.52e+3]\n",
      "Epoch 4/100: 100%|██████████| 1664/1664 [00:00<00:00, 7794.00sample/s, accuracy=59.5, loss=3.86e+3]\n",
      "Epoch 5/100: 100%|██████████| 1664/1664 [00:00<00:00, 8515.62sample/s, accuracy=59.6, loss=3.67e+3]\n",
      "Epoch 6/100: 100%|██████████| 1664/1664 [00:00<00:00, 8119.82sample/s, accuracy=59.6, loss=3.61e+3]\n",
      "Epoch 7/100: 100%|██████████| 1664/1664 [00:00<00:00, 7168.68sample/s, accuracy=59.6, loss=3.6e+3]\n",
      "Epoch 8/100: 100%|██████████| 1664/1664 [00:00<00:00, 8898.46sample/s, accuracy=59.6, loss=3.6e+3] \n",
      "Epoch 9/100: 100%|██████████| 1664/1664 [00:00<00:00, 9191.84sample/s, accuracy=59.6, loss=3.61e+3] \n",
      "Epoch 10/100: 100%|██████████| 1664/1664 [00:00<00:00, 9073.68sample/s, accuracy=59.6, loss=3.62e+3] \n",
      "Epoch 11/100: 100%|██████████| 1664/1664 [00:00<00:00, 9235.36sample/s, accuracy=59.6, loss=3.62e+3] \n",
      "Epoch 12/100: 100%|██████████| 1664/1664 [00:00<00:00, 9071.59sample/s, accuracy=59.6, loss=3.63e+3] \n",
      "Epoch 13/100: 100%|██████████| 1664/1664 [00:00<00:00, 8913.14sample/s, accuracy=59.6, loss=3.64e+3] \n",
      "Epoch 14/100: 100%|██████████| 1664/1664 [00:00<00:00, 9128.77sample/s, accuracy=59.6, loss=3.65e+3] \n",
      "Epoch 15/100: 100%|██████████| 1664/1664 [00:00<00:00, 9291.17sample/s, accuracy=59.6, loss=3.66e+3] \n",
      "Epoch 16/100: 100%|██████████| 1664/1664 [00:00<00:00, 9026.17sample/s, accuracy=59.6, loss=3.67e+3] \n",
      "Epoch 17/100: 100%|██████████| 1664/1664 [00:00<00:00, 8992.24sample/s, accuracy=59.6, loss=3.67e+3] \n",
      "Epoch 18/100: 100%|██████████| 1664/1664 [00:00<00:00, 9010.90sample/s, accuracy=59.6, loss=3.68e+3] \n",
      "Epoch 19/100: 100%|██████████| 1664/1664 [00:00<00:00, 9363.43sample/s, accuracy=59.6, loss=3.69e+3] \n",
      "Epoch 20/100: 100%|██████████| 1664/1664 [00:00<00:00, 9103.95sample/s, accuracy=59.6, loss=3.7e+3] \n",
      "Epoch 21/100: 100%|██████████| 1664/1664 [00:00<00:00, 9202.18sample/s, accuracy=59.6, loss=3.7e+3] \n",
      "Epoch 22/100: 100%|██████████| 1664/1664 [00:00<00:00, 9185.88sample/s, accuracy=59.6, loss=3.71e+3] \n",
      "Epoch 23/100: 100%|██████████| 1664/1664 [00:00<00:00, 7882.80sample/s, accuracy=59.6, loss=3.72e+3]\n",
      "Epoch 24/100: 100%|██████████| 1664/1664 [00:00<00:00, 7862.25sample/s, accuracy=59.6, loss=3.72e+3]\n",
      "Epoch 25/100: 100%|██████████| 1664/1664 [00:00<00:00, 7932.42sample/s, accuracy=59.6, loss=3.73e+3]\n",
      "Epoch 26/100: 100%|██████████| 1664/1664 [00:00<00:00, 8931.76sample/s, accuracy=59.6, loss=3.74e+3] \n",
      "Epoch 27/100: 100%|██████████| 1664/1664 [00:00<00:00, 8850.64sample/s, accuracy=59.6, loss=3.74e+3] \n",
      "Epoch 28/100: 100%|██████████| 1664/1664 [00:00<00:00, 9047.04sample/s, accuracy=59.6, loss=3.75e+3] \n",
      "Epoch 29/100: 100%|██████████| 1664/1664 [00:00<00:00, 9117.08sample/s, accuracy=59.6, loss=3.76e+3] \n",
      "Epoch 30/100: 100%|██████████| 1664/1664 [00:00<00:00, 8943.42sample/s, accuracy=59.6, loss=3.76e+3] \n",
      "Epoch 31/100: 100%|██████████| 1664/1664 [00:00<00:00, 9307.05sample/s, accuracy=59.6, loss=3.77e+3] \n",
      "Epoch 32/100: 100%|██████████| 1664/1664 [00:00<00:00, 9154.64sample/s, accuracy=59.6, loss=3.77e+3] \n",
      "Epoch 33/100: 100%|██████████| 1664/1664 [00:00<00:00, 8587.10sample/s, accuracy=59.6, loss=3.78e+3] \n",
      "Epoch 34/100: 100%|██████████| 1664/1664 [00:00<00:00, 8230.37sample/s, accuracy=59.6, loss=3.78e+3]\n",
      "Epoch 35/100: 100%|██████████| 1664/1664 [00:00<00:00, 8151.19sample/s, accuracy=59.6, loss=3.79e+3]\n",
      "Epoch 36/100: 100%|██████████| 1664/1664 [00:00<00:00, 8622.49sample/s, accuracy=59.6, loss=3.79e+3]\n",
      "Epoch 37/100: 100%|██████████| 1664/1664 [00:00<00:00, 9137.01sample/s, accuracy=59.6, loss=3.8e+3] \n",
      "Epoch 38/100: 100%|██████████| 1664/1664 [00:00<00:00, 8379.85sample/s, accuracy=59.6, loss=3.8e+3] \n",
      "Epoch 39/100: 100%|██████████| 1664/1664 [00:00<00:00, 7971.53sample/s, accuracy=59.6, loss=3.81e+3]\n",
      "Epoch 40/100: 100%|██████████| 1664/1664 [00:00<00:00, 8983.59sample/s, accuracy=59.6, loss=3.81e+3] \n",
      "Epoch 41/100: 100%|██████████| 1664/1664 [00:00<00:00, 8832.54sample/s, accuracy=59.6, loss=3.82e+3] \n",
      "Epoch 42/100: 100%|██████████| 1664/1664 [00:00<00:00, 8386.60sample/s, accuracy=59.6, loss=3.82e+3]\n",
      "Epoch 43/100: 100%|██████████| 1664/1664 [00:00<00:00, 8154.86sample/s, accuracy=59.6, loss=3.83e+3]\n",
      "Epoch 44/100: 100%|██████████| 1664/1664 [00:00<00:00, 8775.35sample/s, accuracy=59.6, loss=3.83e+3] \n",
      "Epoch 45/100: 100%|██████████| 1664/1664 [00:00<00:00, 8693.32sample/s, accuracy=59.6, loss=3.83e+3] \n",
      "Epoch 46/100: 100%|██████████| 1664/1664 [00:00<00:00, 8639.82sample/s, accuracy=59.6, loss=3.84e+3] \n",
      "Epoch 47/100: 100%|██████████| 1664/1664 [00:00<00:00, 8511.30sample/s, accuracy=59.6, loss=3.84e+3]\n",
      "Epoch 48/100: 100%|██████████| 1664/1664 [00:00<00:00, 8095.99sample/s, accuracy=59.6, loss=3.84e+3]\n",
      "Epoch 49/100: 100%|██████████| 1664/1664 [00:00<00:00, 7602.88sample/s, accuracy=59.6, loss=3.85e+3]\n",
      "Epoch 50/100: 100%|██████████| 1664/1664 [00:00<00:00, 8912.07sample/s, accuracy=59.6, loss=3.85e+3] \n",
      "Epoch 51/100: 100%|██████████| 1664/1664 [00:00<00:00, 9038.32sample/s, accuracy=59.6, loss=3.85e+3] \n",
      "Epoch 52/100: 100%|██████████| 1664/1664 [00:00<00:00, 8687.56sample/s, accuracy=59.6, loss=3.86e+3] \n",
      "Epoch 53/100: 100%|██████████| 1664/1664 [00:00<00:00, 8838.76sample/s, accuracy=59.6, loss=3.86e+3] \n",
      "Epoch 54/100: 100%|██████████| 1664/1664 [00:00<00:00, 8682.62sample/s, accuracy=59.6, loss=3.86e+3] \n",
      "Epoch 55/100: 100%|██████████| 1664/1664 [00:00<00:00, 8323.82sample/s, accuracy=59.6, loss=3.87e+3]\n",
      "Epoch 56/100: 100%|██████████| 1664/1664 [00:00<00:00, 8193.63sample/s, accuracy=59.6, loss=3.87e+3]\n",
      "Epoch 57/100: 100%|██████████| 1664/1664 [00:00<00:00, 7855.79sample/s, accuracy=59.6, loss=3.87e+3]\n",
      "Epoch 58/100: 100%|██████████| 1664/1664 [00:00<00:00, 8124.08sample/s, accuracy=59.6, loss=3.87e+3]\n",
      "Epoch 59/100: 100%|██████████| 1664/1664 [00:00<00:00, 8066.16sample/s, accuracy=59.6, loss=3.88e+3]\n",
      "Epoch 60/100: 100%|██████████| 1664/1664 [00:00<00:00, 8012.63sample/s, accuracy=59.6, loss=3.88e+3]\n",
      "Epoch 61/100: 100%|██████████| 1664/1664 [00:00<00:00, 7833.87sample/s, accuracy=59.6, loss=3.88e+3]\n",
      "Epoch 62/100: 100%|██████████| 1664/1664 [00:00<00:00, 8910.62sample/s, accuracy=59.6, loss=3.88e+3] \n",
      "Epoch 63/100: 100%|██████████| 1664/1664 [00:00<00:00, 8951.76sample/s, accuracy=59.6, loss=3.89e+3] \n",
      "Epoch 64/100: 100%|██████████| 1664/1664 [00:00<00:00, 8838.81sample/s, accuracy=59.6, loss=3.89e+3] \n",
      "Epoch 65/100: 100%|██████████| 1664/1664 [00:00<00:00, 8900.63sample/s, accuracy=59.6, loss=3.89e+3] \n",
      "Epoch 66/100: 100%|██████████| 1664/1664 [00:00<00:00, 8465.51sample/s, accuracy=59.6, loss=3.89e+3]\n",
      "Epoch 67/100: 100%|██████████| 1664/1664 [00:00<00:00, 8175.29sample/s, accuracy=59.6, loss=3.9e+3]\n",
      "Epoch 68/100: 100%|██████████| 1664/1664 [00:00<00:00, 7950.83sample/s, accuracy=59.6, loss=3.9e+3]\n",
      "Epoch 69/100: 100%|██████████| 1664/1664 [00:00<00:00, 7750.83sample/s, accuracy=59.6, loss=3.9e+3]\n",
      "Epoch 70/100: 100%|██████████| 1664/1664 [00:00<00:00, 8010.29sample/s, accuracy=59.6, loss=3.9e+3]\n",
      "Epoch 71/100: 100%|██████████| 1664/1664 [00:00<00:00, 8994.63sample/s, accuracy=59.6, loss=3.9e+3] \n",
      "Epoch 72/100: 100%|██████████| 1664/1664 [00:00<00:00, 8824.41sample/s, accuracy=59.6, loss=3.91e+3] \n",
      "Epoch 73/100: 100%|██████████| 1664/1664 [00:00<00:00, 8827.62sample/s, accuracy=59.6, loss=3.91e+3] \n",
      "Epoch 74/100: 100%|██████████| 1664/1664 [00:00<00:00, 8739.49sample/s, accuracy=59.6, loss=3.91e+3] \n",
      "Epoch 75/100: 100%|██████████| 1664/1664 [00:00<00:00, 8811.74sample/s, accuracy=59.6, loss=3.91e+3] \n",
      "Epoch 76/100: 100%|██████████| 1664/1664 [00:00<00:00, 8152.40sample/s, accuracy=59.6, loss=3.91e+3]\n",
      "Epoch 77/100: 100%|██████████| 1664/1664 [00:00<00:00, 8988.68sample/s, accuracy=59.6, loss=3.91e+3] \n",
      "Epoch 78/100: 100%|██████████| 1664/1664 [00:00<00:00, 8808.56sample/s, accuracy=59.6, loss=3.92e+3] \n",
      "Epoch 79/100: 100%|██████████| 1664/1664 [00:00<00:00, 8113.19sample/s, accuracy=59.6, loss=3.92e+3]\n",
      "Epoch 80/100: 100%|██████████| 1664/1664 [00:00<00:00, 8771.08sample/s, accuracy=59.6, loss=3.92e+3] \n",
      "Epoch 81/100: 100%|██████████| 1664/1664 [00:00<00:00, 8537.51sample/s, accuracy=59.6, loss=3.92e+3]\n",
      "Epoch 82/100: 100%|██████████| 1664/1664 [00:00<00:00, 8415.40sample/s, accuracy=59.6, loss=3.92e+3]\n",
      "Epoch 83/100: 100%|██████████| 1664/1664 [00:00<00:00, 8473.16sample/s, accuracy=59.6, loss=3.92e+3]\n",
      "Epoch 84/100: 100%|██████████| 1664/1664 [00:00<00:00, 8663.42sample/s, accuracy=59.6, loss=3.93e+3]\n",
      "Epoch 85/100: 100%|██████████| 1664/1664 [00:00<00:00, 6898.01sample/s, accuracy=59.6, loss=3.93e+3]\n",
      "Epoch 86/100: 100%|██████████| 1664/1664 [00:00<00:00, 7774.83sample/s, accuracy=59.6, loss=3.93e+3]\n",
      "Epoch 87/100: 100%|██████████| 1664/1664 [00:00<00:00, 7747.42sample/s, accuracy=59.6, loss=3.93e+3]\n",
      "Epoch 88/100: 100%|██████████| 1664/1664 [00:00<00:00, 8407.80sample/s, accuracy=59.6, loss=3.93e+3]\n",
      "Epoch 89/100: 100%|██████████| 1664/1664 [00:00<00:00, 8143.93sample/s, accuracy=59.6, loss=3.93e+3]\n",
      "Epoch 90/100: 100%|██████████| 1664/1664 [00:00<00:00, 8174.61sample/s, accuracy=59.6, loss=3.93e+3]\n",
      "Epoch 91/100: 100%|██████████| 1664/1664 [00:00<00:00, 8128.37sample/s, accuracy=59.6, loss=3.93e+3]\n",
      "Epoch 92/100: 100%|██████████| 1664/1664 [00:00<00:00, 8189.88sample/s, accuracy=59.6, loss=3.94e+3]\n",
      "Epoch 93/100: 100%|██████████| 1664/1664 [00:00<00:00, 8311.06sample/s, accuracy=59.6, loss=3.94e+3]\n",
      "Epoch 94/100: 100%|██████████| 1664/1664 [00:00<00:00, 7447.02sample/s, accuracy=59.6, loss=3.94e+3]\n",
      "Epoch 95/100: 100%|██████████| 1664/1664 [00:00<00:00, 8235.03sample/s, accuracy=59.6, loss=3.94e+3]\n",
      "Epoch 96/100: 100%|██████████| 1664/1664 [00:00<00:00, 8905.96sample/s, accuracy=59.6, loss=3.94e+3] \n",
      "Epoch 97/100: 100%|██████████| 1664/1664 [00:00<00:00, 8902.25sample/s, accuracy=59.6, loss=3.94e+3] \n",
      "Epoch 98/100: 100%|██████████| 1664/1664 [00:00<00:00, 8813.29sample/s, accuracy=59.6, loss=3.94e+3] \n",
      "Epoch 99/100: 100%|██████████| 1664/1664 [00:00<00:00, 8691.60sample/s, accuracy=59.6, loss=3.94e+3] \n",
      "Epoch 100/100: 100%|██████████| 1664/1664 [00:00<00:00, 8821.16sample/s, accuracy=59.6, loss=3.94e+3] \n"
     ]
    }
   ],
   "source": [
    "accuracies, losses = model.train(x,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 0 1 0 1 0]\n",
      " [0 1 0 1 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 1 0]\n",
      " [0 1 0 0 1 1 0 0 1 1]\n",
      " [1 0 1 1 1 1 1 1 0 1]\n",
      " [1 1 1 1 1 0 0 1 1 1]\n",
      " [1 1 1 1 0 0 0 0 1 1]\n",
      " [0 1 0 1 0 0 1 0 1 0]\n",
      " [0 1 0 1 1 1 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 1 1 0 0]\n",
      " [0 1 0 1 1 1 1 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 0 0]\n",
      " [0 0 1 1 0 0 1 1 0 0]\n",
      " [1 0 1 0 1 1 0 1 0 1]\n",
      " [1 1 1 1 0 0 0 1 0 1]\n",
      " [1 1 1 0 1 1 0 1 1 1]\n",
      " [0 0 0 0 0 1 1 1 0 1]\n",
      " [0 1 0 1 1 1 1 0 1 0]\n",
      " [0 1 0 0 0 0 1 0 1 1]\n",
      " [0 0 0 1 1 1 1 0 0 0]\n",
      " [1 0 0 1 1 0 0 0 1 0]\n",
      " [1 0 1 1 0 1 0 0 0 0]\n",
      " [0 1 0 1 0 1 0 0 1 1]\n",
      " [1 0 0 0 1 1 1 0 0 1]\n",
      " [0 1 0 0 0 0 1 1 0 1]\n",
      " [0 1 0 1 0 0 1 0 1 0]\n",
      " [0 0 1 0 0 1 0 0 0 0]\n",
      " [0 1 1 0 1 1 0 1 1 0]\n",
      " [0 1 0 0 0 1 1 0 1 0]\n",
      " [1 0 0 1 1 1 1 0 0 1]\n",
      " [0 0 0 0 0 1 1 1 1 1]\n",
      " [0 0 1 0 1 1 1 0 1 0]\n",
      " [0 0 0 1 0 0 1 0 0 0]\n",
      " [0 1 0 0 1 1 0 0 1 0]\n",
      " [0 0 1 1 1 0 1 1 1 1]\n",
      " [1 1 1 0 0 0 0 1 1 1]\n",
      " [0 0 1 1 0 1 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 1 0]\n",
      " [1 1 0 1 1 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 1 0 0 1 1 0]\n",
      " [0 1 0 1 0 1 1 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 1 1]\n",
      " [0 0 1 0 1 1 1 0 0 1]\n",
      " [1 0 1 1 0 0 1 0 1 0]\n",
      " [1 1 1 1 0 0 1 1 1 1]\n",
      " [1 0 0 0 1 0 1 1 1 1]] [0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1\n",
      " 0 1 0 1 0 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "temp_x = x[:48]\n",
    "temp_y = y[:48]\n",
    "print(temp_x, temp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolving Bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 32/32 [00:00<00:00, 5707.26sample/s, accuracy=87.5, loss=657]\n",
      "Epoch 2/10: 100%|██████████| 32/32 [00:00<00:00, 6183.15sample/s, accuracy=87.5, loss=634]\n",
      "Epoch 3/10: 100%|██████████| 32/32 [00:00<00:00, 6691.15sample/s, accuracy=96.9, loss=612]\n",
      "Epoch 4/10: 100%|██████████| 32/32 [00:00<00:00, 4147.64sample/s, accuracy=100, loss=590]\n",
      "Epoch 5/10: 100%|██████████| 32/32 [00:00<00:00, 3555.72sample/s, accuracy=100, loss=570]\n",
      "Epoch 6/10: 100%|██████████| 32/32 [00:00<00:00, 5180.55sample/s, accuracy=100, loss=550]\n",
      "Epoch 7/10: 100%|██████████| 32/32 [00:00<00:00, 6226.76sample/s, accuracy=100, loss=530]\n",
      "Epoch 8/10: 100%|██████████| 32/32 [00:00<00:00, 5819.36sample/s, accuracy=100, loss=512]\n",
      "Epoch 9/10: 100%|██████████| 32/32 [00:00<00:00, 8082.48sample/s, accuracy=100, loss=494]\n",
      "Epoch 10/10: 100%|██████████| 32/32 [00:00<00:00, 6074.57sample/s, accuracy=100, loss=477]\n"
     ]
    }
   ],
   "source": [
    "x_palindromes = np.array([np.reshape(np.array([int(char) for char in s]), (10,)) for s in Dataset.palindromes])\n",
    "y_palindromes = np.array([1]*32)\n",
    "\n",
    "x_non_palindrome = np.array([np.reshape(np.array([int(char) for char in s]), (10,)) for s in Dataset.non_palindromes])\n",
    "y_non_palindrome = np.array([0]*len(x_non_palindrome))\n",
    "temp_x = np.concatenate((temp_x,x_palindromes))\n",
    "temp_y = np.concatenate((temp_y, y_palindromes))\n",
    "accuracies, losses = model.train(x_palindromes,y_palindromes,epochs=10)\n",
    "# print(temp_x, temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 80/80 [00:00<00:00, 5717.91sample/s, accuracy=56.2, loss=11.9]\n",
      "Epoch 2/100: 100%|██████████| 80/80 [00:00<00:00, 6305.56sample/s, accuracy=56.2, loss=9.8]\n",
      "Epoch 3/100: 100%|██████████| 80/80 [00:00<00:00, 3753.88sample/s, accuracy=56.2, loss=9.66]\n",
      "Epoch 4/100: 100%|██████████| 80/80 [00:00<00:00, 5021.16sample/s, accuracy=56.2, loss=9.59]\n",
      "Epoch 5/100: 100%|██████████| 80/80 [00:00<00:00, 5328.64sample/s, accuracy=56.2, loss=9.52]\n",
      "Epoch 6/100: 100%|██████████| 80/80 [00:00<00:00, 5852.04sample/s, accuracy=56.2, loss=9.47]\n",
      "Epoch 7/100: 100%|██████████| 80/80 [00:00<00:00, 5588.40sample/s, accuracy=56.2, loss=9.43]\n",
      "Epoch 8/100: 100%|██████████| 80/80 [00:00<00:00, 5990.37sample/s, accuracy=56.2, loss=9.39]\n",
      "Epoch 9/100: 100%|██████████| 80/80 [00:00<00:00, 5459.56sample/s, accuracy=56.2, loss=9.35]\n",
      "Epoch 10/100: 100%|██████████| 80/80 [00:00<00:00, 5561.54sample/s, accuracy=56.2, loss=9.32]\n",
      "Epoch 11/100: 100%|██████████| 80/80 [00:00<00:00, 5873.14sample/s, accuracy=56.2, loss=9.29]\n",
      "Epoch 12/100: 100%|██████████| 80/80 [00:00<00:00, 5480.60sample/s, accuracy=56.2, loss=9.26]\n",
      "Epoch 13/100: 100%|██████████| 80/80 [00:00<00:00, 6120.50sample/s, accuracy=56.2, loss=9.24]\n",
      "Epoch 14/100: 100%|██████████| 80/80 [00:00<00:00, 5943.36sample/s, accuracy=56.2, loss=9.22]\n",
      "Epoch 15/100: 100%|██████████| 80/80 [00:00<00:00, 5235.35sample/s, accuracy=56.2, loss=9.19]\n",
      "Epoch 16/100: 100%|██████████| 80/80 [00:00<00:00, 6096.82sample/s, accuracy=56.2, loss=9.17]\n",
      "Epoch 17/100: 100%|██████████| 80/80 [00:00<00:00, 6085.98sample/s, accuracy=56.2, loss=9.15]\n",
      "Epoch 18/100: 100%|██████████| 80/80 [00:00<00:00, 6105.47sample/s, accuracy=56.2, loss=9.13]\n",
      "Epoch 19/100: 100%|██████████| 80/80 [00:00<00:00, 6855.12sample/s, accuracy=56.2, loss=9.11]\n",
      "Epoch 20/100: 100%|██████████| 80/80 [00:00<00:00, 6854.42sample/s, accuracy=56.2, loss=9.1]\n",
      "Epoch 21/100: 100%|██████████| 80/80 [00:00<00:00, 6289.37sample/s, accuracy=56.2, loss=9.08]\n",
      "Epoch 22/100: 100%|██████████| 80/80 [00:00<00:00, 5525.18sample/s, accuracy=56.2, loss=9.06]\n",
      "Epoch 23/100: 100%|██████████| 80/80 [00:00<00:00, 5708.28sample/s, accuracy=56.2, loss=9.04]\n",
      "Epoch 24/100: 100%|██████████| 80/80 [00:00<00:00, 4119.03sample/s, accuracy=56.2, loss=9.03]\n",
      "Epoch 25/100: 100%|██████████| 80/80 [00:00<00:00, 2972.42sample/s, accuracy=56.2, loss=9.01]\n",
      "Epoch 26/100: 100%|██████████| 80/80 [00:00<00:00, 3295.82sample/s, accuracy=56.2, loss=8.99]\n",
      "Epoch 27/100: 100%|██████████| 80/80 [00:00<00:00, 5779.57sample/s, accuracy=56.2, loss=8.98]\n",
      "Epoch 28/100: 100%|██████████| 80/80 [00:00<00:00, 6390.10sample/s, accuracy=56.2, loss=8.96]\n",
      "Epoch 29/100: 100%|██████████| 80/80 [00:00<00:00, 5904.98sample/s, accuracy=56.2, loss=8.95]\n",
      "Epoch 30/100: 100%|██████████| 80/80 [00:00<00:00, 5783.55sample/s, accuracy=56.2, loss=8.93]\n",
      "Epoch 31/100: 100%|██████████| 80/80 [00:00<00:00, 5836.06sample/s, accuracy=56.2, loss=8.91]\n",
      "Epoch 32/100: 100%|██████████| 80/80 [00:00<00:00, 5614.49sample/s, accuracy=56.2, loss=8.9]\n",
      "Epoch 33/100: 100%|██████████| 80/80 [00:00<00:00, 5391.40sample/s, accuracy=56.2, loss=8.88]\n",
      "Epoch 34/100: 100%|██████████| 80/80 [00:00<00:00, 5770.92sample/s, accuracy=56.2, loss=8.86]\n",
      "Epoch 35/100: 100%|██████████| 80/80 [00:00<00:00, 6600.01sample/s, accuracy=56.2, loss=8.85]\n",
      "Epoch 36/100: 100%|██████████| 80/80 [00:00<00:00, 5163.57sample/s, accuracy=56.2, loss=8.83]\n",
      "Epoch 37/100: 100%|██████████| 80/80 [00:00<00:00, 5976.60sample/s, accuracy=56.2, loss=8.81]\n",
      "Epoch 38/100: 100%|██████████| 80/80 [00:00<00:00, 5838.50sample/s, accuracy=56.2, loss=8.8]\n",
      "Epoch 39/100: 100%|██████████| 80/80 [00:00<00:00, 5456.63sample/s, accuracy=56.2, loss=8.78]\n",
      "Epoch 40/100: 100%|██████████| 80/80 [00:00<00:00, 6367.55sample/s, accuracy=56.2, loss=8.76]\n",
      "Epoch 41/100: 100%|██████████| 80/80 [00:00<00:00, 6334.97sample/s, accuracy=56.2, loss=8.74]\n",
      "Epoch 42/100: 100%|██████████| 80/80 [00:00<00:00, 6122.51sample/s, accuracy=56.2, loss=8.72]\n",
      "Epoch 43/100: 100%|██████████| 80/80 [00:00<00:00, 6489.09sample/s, accuracy=56.2, loss=8.71]\n",
      "Epoch 44/100: 100%|██████████| 80/80 [00:00<00:00, 7138.94sample/s, accuracy=56.2, loss=8.69]\n",
      "Epoch 45/100: 100%|██████████| 80/80 [00:00<00:00, 6177.29sample/s, accuracy=56.2, loss=8.67]\n",
      "Epoch 46/100: 100%|██████████| 80/80 [00:00<00:00, 6519.09sample/s, accuracy=56.2, loss=8.65]\n",
      "Epoch 47/100: 100%|██████████| 80/80 [00:00<00:00, 5764.47sample/s, accuracy=56.2, loss=8.63]\n",
      "Epoch 48/100: 100%|██████████| 80/80 [00:00<00:00, 6014.63sample/s, accuracy=56.2, loss=8.61]\n",
      "Epoch 49/100: 100%|██████████| 80/80 [00:00<00:00, 6305.45sample/s, accuracy=56.2, loss=8.59]\n",
      "Epoch 50/100: 100%|██████████| 80/80 [00:00<00:00, 6145.84sample/s, accuracy=57.5, loss=8.57]\n",
      "Epoch 51/100: 100%|██████████| 80/80 [00:00<00:00, 4474.88sample/s, accuracy=57.5, loss=8.55]\n",
      "Epoch 52/100: 100%|██████████| 80/80 [00:00<00:00, 4500.08sample/s, accuracy=57.5, loss=8.53]\n",
      "Epoch 53/100: 100%|██████████| 80/80 [00:00<00:00, 5584.96sample/s, accuracy=58.8, loss=8.51]\n",
      "Epoch 54/100: 100%|██████████| 80/80 [00:00<00:00, 5889.22sample/s, accuracy=58.8, loss=8.48]\n",
      "Epoch 55/100: 100%|██████████| 80/80 [00:00<00:00, 6105.80sample/s, accuracy=58.8, loss=8.46]\n",
      "Epoch 56/100: 100%|██████████| 80/80 [00:00<00:00, 6196.23sample/s, accuracy=58.8, loss=8.44]\n",
      "Epoch 57/100: 100%|██████████| 80/80 [00:00<00:00, 5536.12sample/s, accuracy=58.8, loss=8.42]\n",
      "Epoch 58/100: 100%|██████████| 80/80 [00:00<00:00, 5899.06sample/s, accuracy=60, loss=8.4]\n",
      "Epoch 59/100: 100%|██████████| 80/80 [00:00<00:00, 5796.64sample/s, accuracy=60, loss=8.38]\n",
      "Epoch 60/100: 100%|██████████| 80/80 [00:00<00:00, 6090.95sample/s, accuracy=60, loss=8.35]\n",
      "Epoch 61/100: 100%|██████████| 80/80 [00:00<00:00, 6135.50sample/s, accuracy=60, loss=8.33]\n",
      "Epoch 62/100: 100%|██████████| 80/80 [00:00<00:00, 5480.87sample/s, accuracy=60, loss=8.31]\n",
      "Epoch 63/100: 100%|██████████| 80/80 [00:00<00:00, 6172.29sample/s, accuracy=60, loss=8.29]\n",
      "Epoch 64/100: 100%|██████████| 80/80 [00:00<00:00, 5691.82sample/s, accuracy=60, loss=8.26]\n",
      "Epoch 65/100: 100%|██████████| 80/80 [00:00<00:00, 7506.08sample/s, accuracy=60, loss=8.24]\n",
      "Epoch 66/100: 100%|██████████| 80/80 [00:00<00:00, 6370.33sample/s, accuracy=60, loss=8.22]\n",
      "Epoch 67/100: 100%|██████████| 80/80 [00:00<00:00, 6074.52sample/s, accuracy=60, loss=8.2]\n",
      "Epoch 68/100: 100%|██████████| 80/80 [00:00<00:00, 5714.12sample/s, accuracy=60, loss=8.18]\n",
      "Epoch 69/100: 100%|██████████| 80/80 [00:00<00:00, 6323.63sample/s, accuracy=61.3, loss=8.16]\n",
      "Epoch 70/100: 100%|██████████| 80/80 [00:00<00:00, 5782.85sample/s, accuracy=62.5, loss=8.14]\n",
      "Epoch 71/100: 100%|██████████| 80/80 [00:00<00:00, 6043.23sample/s, accuracy=62.5, loss=8.11]\n",
      "Epoch 72/100: 100%|██████████| 80/80 [00:00<00:00, 6068.92sample/s, accuracy=62.5, loss=8.09]\n",
      "Epoch 73/100: 100%|██████████| 80/80 [00:00<00:00, 5711.39sample/s, accuracy=62.5, loss=8.07]\n",
      "Epoch 74/100: 100%|██████████| 80/80 [00:00<00:00, 6913.02sample/s, accuracy=62.5, loss=8.05]\n",
      "Epoch 75/100: 100%|██████████| 80/80 [00:00<00:00, 5805.97sample/s, accuracy=62.5, loss=8.03]\n",
      "Epoch 76/100: 100%|██████████| 80/80 [00:00<00:00, 5472.73sample/s, accuracy=62.5, loss=8.02]\n",
      "Epoch 77/100: 100%|██████████| 80/80 [00:00<00:00, 6968.44sample/s, accuracy=62.5, loss=8]\n",
      "Epoch 78/100: 100%|██████████| 80/80 [00:00<00:00, 7069.45sample/s, accuracy=62.5, loss=7.98]\n",
      "Epoch 79/100: 100%|██████████| 80/80 [00:00<00:00, 6700.57sample/s, accuracy=62.5, loss=7.96]\n",
      "Epoch 80/100: 100%|██████████| 80/80 [00:00<00:00, 6666.62sample/s, accuracy=62.5, loss=7.94]\n",
      "Epoch 81/100: 100%|██████████| 80/80 [00:00<00:00, 6462.84sample/s, accuracy=62.5, loss=7.93]\n",
      "Epoch 82/100: 100%|██████████| 80/80 [00:00<00:00, 6211.25sample/s, accuracy=62.5, loss=7.91]\n",
      "Epoch 83/100: 100%|██████████| 80/80 [00:00<00:00, 5703.72sample/s, accuracy=62.5, loss=7.9]\n",
      "Epoch 84/100: 100%|██████████| 80/80 [00:00<00:00, 5755.67sample/s, accuracy=62.5, loss=7.88]\n",
      "Epoch 85/100: 100%|██████████| 80/80 [00:00<00:00, 5886.23sample/s, accuracy=62.5, loss=7.87]\n",
      "Epoch 86/100: 100%|██████████| 80/80 [00:00<00:00, 6051.51sample/s, accuracy=63.7, loss=7.85]\n",
      "Epoch 87/100: 100%|██████████| 80/80 [00:00<00:00, 6603.64sample/s, accuracy=65, loss=7.84]\n",
      "Epoch 88/100: 100%|██████████| 80/80 [00:00<00:00, 4948.37sample/s, accuracy=65, loss=7.83]\n",
      "Epoch 89/100: 100%|██████████| 80/80 [00:00<00:00, 5756.27sample/s, accuracy=65, loss=7.81]\n",
      "Epoch 90/100: 100%|██████████| 80/80 [00:00<00:00, 5606.52sample/s, accuracy=65, loss=7.8]\n",
      "Epoch 91/100: 100%|██████████| 80/80 [00:00<00:00, 5862.37sample/s, accuracy=66.2, loss=7.79]\n",
      "Epoch 92/100: 100%|██████████| 80/80 [00:00<00:00, 4702.07sample/s, accuracy=66.2, loss=7.78]\n",
      "Epoch 93/100: 100%|██████████| 80/80 [00:00<00:00, 5893.26sample/s, accuracy=66.2, loss=7.77]\n",
      "Epoch 94/100: 100%|██████████| 80/80 [00:00<00:00, 6653.53sample/s, accuracy=66.2, loss=7.76]\n",
      "Epoch 95/100: 100%|██████████| 80/80 [00:00<00:00, 6454.51sample/s, accuracy=66.2, loss=7.75]\n",
      "Epoch 96/100: 100%|██████████| 80/80 [00:00<00:00, 5371.20sample/s, accuracy=66.2, loss=7.74]\n",
      "Epoch 97/100: 100%|██████████| 80/80 [00:00<00:00, 3921.51sample/s, accuracy=66.2, loss=7.73]\n",
      "Epoch 98/100: 100%|██████████| 80/80 [00:00<00:00, 4424.60sample/s, accuracy=66.2, loss=7.72]\n",
      "Epoch 99/100: 100%|██████████| 80/80 [00:00<00:00, 5434.80sample/s, accuracy=66.2, loss=7.71]\n",
      "Epoch 100/100: 100%|██████████| 80/80 [00:00<00:00, 5464.18sample/s, accuracy=66.2, loss=7.71]\n"
     ]
    }
   ],
   "source": [
    "# model.train(x_non_palindrome, y_non_palindrome, epochs=20)\n",
    "\n",
    "model.set_optimizer(lr=0.005,loss=\"mse\")\n",
    "accuracies, losses = model.train(temp_x,temp_y,epochs=100)\n",
    "# model.train(x_palindromes, y_palindromes, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_palindromes)\n",
    "accuracy_metric(predictions, y_palindromes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.036290322580644"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_non_palindrome)\n",
    "# print(predictions)\n",
    "accuracy_metric(predictions, y_non_palindrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch  Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import activation, dataset, losses\n",
    "from model import *\n",
    "import numpy as np\n",
    "# np.random.seed(7)\n",
    "\n",
    "Dataset = dataset.Palindrome_Dataset(n_bits=10)\n",
    "x,y = Dataset.get_data(shuffle=True, biasing_factor=20)\n",
    "model = Palindrome_Model(input_size=10, output_size=1,hidden_layer_sizes=[4,4],activation='sigmoid')\n",
    "model.set_optimizer(lr=0.005,loss=\"bce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([1,1,1,1,1,1,1,1,0,1])\n",
    "y_temp = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(model,X:np.ndarray, y:np.ndarray, k_folds:int = 4, epochs_per_fold:int = 25):\n",
    "        fold_size = len(X) // k_folds\n",
    "        accuracies_fold = []\n",
    "        accuracies=[]\n",
    "        losses = []\n",
    "        for i in range(k_folds):\n",
    "            start, end = i * fold_size, (i + 1) * fold_size\n",
    "            X_test_fold, y_test_fold = X[start:end], y[start:end]\n",
    "            X_train_fold = np.concatenate([X[:start], X[end:]])\n",
    "            y_train_fold = np.concatenate([y[:start], y[end:]])\n",
    "            print(f\"Training Fold {i+1}\\n\")\n",
    "            accuracy, loss = model.train(X_train_fold, y_train_fold, epochs_per_fold)\n",
    "            accuracies.extend(accuracy)\n",
    "            losses.extend(loss)\n",
    "            print(\"\\n\"+10*\"----\"+\"\\n\")\n",
    "            predictions = model.predict(X_test_fold)\n",
    "            accuracies_fold.append(accuracy_metric(predictions, y_test_fold))\n",
    "        return accuracies_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 6145.67sample/s, accuracy=58.8, loss=72.6]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 6259.24sample/s, accuracy=58.5, loss=81]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5800.76sample/s, accuracy=59.1, loss=76.8]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5048.63sample/s, accuracy=59.7, loss=75.2]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 5120.30sample/s, accuracy=59.1, loss=74.5]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 4877.05sample/s, accuracy=57.5, loss=74]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 5737.11sample/s, accuracy=56.8, loss=73.6]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5839.34sample/s, accuracy=58, loss=73.4]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 5796.17sample/s, accuracy=59.5, loss=73.3]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 6017.27sample/s, accuracy=59.5, loss=73.3]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5868.15sample/s, accuracy=59.5, loss=73.2]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 6148.26sample/s, accuracy=59.5, loss=73.2]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 6096.12sample/s, accuracy=59.5, loss=73.1]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 5941.14sample/s, accuracy=59.5, loss=73]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 5923.73sample/s, accuracy=59.5, loss=72.8]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 5879.43sample/s, accuracy=59.5, loss=72.8]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 5757.96sample/s, accuracy=59.5, loss=72.7]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5968.77sample/s, accuracy=59.5, loss=72.7]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 5928.94sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 6154.41sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 6033.58sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 5949.04sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 5864.41sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 6186.83sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 5954.09sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5891.05sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5759.69sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5872.23sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5781.25sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5521.10sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5327.87sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 3875.14sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 4476.58sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5267.82sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 5573.77sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5719.37sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5797.93sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 5362.26sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 5732.04sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 6062.71sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 5972.58sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5875.23sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5730.14sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 5664.59sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 5858.48sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 5826.30sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 6173.43sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 5908.28sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 5898.21sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 5973.76sample/s, accuracy=59.5, loss=72.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 5349.59sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 5839.98sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5989.46sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5877.77sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 5808.05sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 6014.37sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 6091.99sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5941.68sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 6146.15sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 6145.60sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5932.58sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 4966.03sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 4696.89sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 5160.41sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 5597.84sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 5851.78sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 5878.99sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5930.92sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 6157.15sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 6198.24sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 6109.15sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 4991.46sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 5392.01sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 5392.91sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 5764.90sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5892.28sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5805.04sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5729.07sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5965.06sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5543.70sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5950.71sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 6076.13sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 6049.61sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5788.06sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 5335.04sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5159.74sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5270.26sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 3923.86sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 4431.38sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 4445.32sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 4166.71sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 4935.65sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5358.40sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 5267.25sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 5044.56sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 3956.20sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 4582.01sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 5204.32sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 5656.63sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 5874.39sample/s, accuracy=59.5, loss=72.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 4072.14sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 4979.82sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5673.51sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5605.24sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 5870.71sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 5979.24sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 5712.00sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5884.66sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 5670.23sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 5869.53sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5761.17sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 5901.85sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 5867.53sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 5822.28sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 5917.93sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 5800.05sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 5173.44sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5525.92sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 5784.08sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 5854.24sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 5805.54sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 4357.70sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 4964.48sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 5537.01sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 5746.07sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5719.92sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5843.27sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5554.79sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5818.71sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5968.76sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5872.24sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 5795.32sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 5800.76sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5787.63sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 6065.56sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5964.29sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5977.60sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 6169.51sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 6071.15sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 6181.91sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 6047.00sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5945.95sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5938.27sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 6037.42sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 6084.57sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 5965.02sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 5991.41sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 6076.42sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 6194.80sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 6090.02sample/s, accuracy=60.8, loss=82.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 3825.49sample/s, accuracy=58.7, loss=70.6]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 4763.10sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5553.69sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5849.57sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 5513.05sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 5441.36sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 5139.57sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5179.19sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 5631.86sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 5851.86sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5937.42sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 6153.62sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 6138.11sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 5907.09sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 6033.16sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 6056.54sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 6036.86sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5927.75sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 5993.49sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 6152.60sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 6192.27sample/s, accuracy=58.7, loss=67.2]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 6042.96sample/s, accuracy=58.7, loss=67.2]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 6059.40sample/s, accuracy=58.7, loss=67.2]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 6112.43sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 6134.91sample/s, accuracy=58.7, loss=67.2]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5979.45sample/s, accuracy=61.9, loss=67.3]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5716.27sample/s, accuracy=58.3, loss=67.3]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5812.85sample/s, accuracy=58.8, loss=67.2]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5987.34sample/s, accuracy=58.7, loss=67.3]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5976.28sample/s, accuracy=61.5, loss=67.5]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 6105.12sample/s, accuracy=59.1, loss=67.6]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 6118.25sample/s, accuracy=54.6, loss=67.6]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 6040.62sample/s, accuracy=56.2, loss=67.6]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 6035.39sample/s, accuracy=56.1, loss=67.6]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 6035.23sample/s, accuracy=57.7, loss=67.6]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 6191.15sample/s, accuracy=57.1, loss=67.7]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 4493.77sample/s, accuracy=57.4, loss=67.8]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 5294.01sample/s, accuracy=56, loss=67.8]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 5745.77sample/s, accuracy=55, loss=67.8]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 5850.45sample/s, accuracy=54.7, loss=67.8]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 5346.09sample/s, accuracy=56.1, loss=67.8]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5766.20sample/s, accuracy=55, loss=67.8]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5923.83sample/s, accuracy=55.4, loss=67.8]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 5933.51sample/s, accuracy=55.4, loss=67.8]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 6108.93sample/s, accuracy=55.5, loss=67.9]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 5899.31sample/s, accuracy=55.5, loss=67.9]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 6006.28sample/s, accuracy=55.4, loss=67.9]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 5846.20sample/s, accuracy=55.4, loss=67.9]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 5936.29sample/s, accuracy=55.4, loss=67.9]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 5977.70sample/s, accuracy=55.6, loss=67.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accs = k_fold_cross_validation(model, x, y, epochs_per_fold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.01442307692308"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60.09615384615385, 60.09615384615385, 56.00961538461539, 59.855769230769226]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.61538461538461"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x)\n",
    "accuracy_metric(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
       "  'weights': array([[ 0.92075584,  0.98020454, -0.17354498,  0.54963896, -0.61341082],\n",
       "         [-0.3069449 , -0.31859287, -0.7935808 ,  0.24452297, -1.06643863],\n",
       "         [ 0.32264924, -0.32461446, -0.21445626, -0.47678489, -0.25638755],\n",
       "         [-0.62537194, -0.19053209, -0.21555031, -0.40445053, -0.1660093 ],\n",
       "         [-0.07174505,  0.42259881, -0.24471143, -0.01031693, -0.81025356],\n",
       "         [ 0.69404405,  0.21085697, -0.28454665,  0.52845819, -0.09958278],\n",
       "         [-0.14040927,  0.51493797,  0.30452068, -0.20036355,  0.52997397],\n",
       "         [ 0.35928047,  0.55598655,  0.20385861,  0.29601196, -0.03650077],\n",
       "         [-0.37006127, -0.24986717, -0.1882553 ,  0.28326173,  0.48526483],\n",
       "         [-0.69906679,  0.24546093, -0.45782992,  0.78897229, -0.65061248]]),\n",
       "  'biases': array([ 1.03922811, -0.59154367, -0.61716551, -0.83110799,  0.51746456]),\n",
       "  'activation': 'linear'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[ 0.03572792],\n",
       "         [ 0.08053775],\n",
       "         [-0.13718967],\n",
       "         [-0.02308033],\n",
       "         [ 0.03733735]]),\n",
       "  'biases': array([-0.57042209]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y)):\n",
    "    if predictions[i]==1:\n",
    "        count+=1\n",
    "        # print(x[i], y[i], predictions[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121 (484.00 Byte)\n",
      "Trainable params: 121 (484.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(10,)),          # Input layer with size 10\n",
    "    layers.Dense(10, activation='linear'),          # Hidden layer with size 4 and linear activation\n",
    "    layers.Dense(1, activation='sigmoid')           # Output layer with size 1 and sigmoid activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/208 [==============================] - 0s 931us/step - loss: 0.6762 - accuracy: 0.5962\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 0s 923us/step - loss: 0.6759 - accuracy: 0.5962\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 0s 864us/step - loss: 0.6761 - accuracy: 0.5962\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 0s 876us/step - loss: 0.6759 - accuracy: 0.5962\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 0s 870us/step - loss: 0.6760 - accuracy: 0.5962\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 0s 860us/step - loss: 0.6756 - accuracy: 0.5962\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 0s 966us/step - loss: 0.6762 - accuracy: 0.5962\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 0s 967us/step - loss: 0.6761 - accuracy: 0.5962\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5962\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa5f4529f00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=10, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sem8",
   "language": "python",
   "name": "env_sem8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
