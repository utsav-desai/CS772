{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from faker import Faker\n",
    "import random\n",
    "np.random.seed()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "palindromes = []\n",
    "for i in range(1024):\n",
    "    binary_string = format(i, '010b')\n",
    "    x.append(binary_string)\n",
    "    if binary_string == binary_string[::-1]:\n",
    "        palindromes.append(binary_string)\n",
    "x = np.array(x)\n",
    "palindromes = np.array(palindromes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0000000000', '0000110000', '0001001000', '0001111000',\n",
       "       '0010000100', '0010110100', '0011001100', '0011111100',\n",
       "       '0100000010', '0100110010', '0101001010', '0101111010',\n",
       "       '0110000110', '0110110110', '0111001110', '0111111110',\n",
       "       '1000000001', '1000110001', '1001001001', '1001111001',\n",
       "       '1010000101', '1010110101', '1011001101', '1011111101',\n",
       "       '1100000011', '1100110011', '1101001011', '1101111011',\n",
       "       '1110000111', '1110110111', '1111001111', '1111111111'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0110110110', '1101001011', '0010110100', '0001001000',\n",
       "       '0110000110', '1011111101', '0100000010', '1010110101',\n",
       "       '0000000000', '0011111100', '1001001001', '0011001100',\n",
       "       '0111001110', '1011001101', '1001111001', '1000110001',\n",
       "       '1000000001', '0101001010', '1110110111', '0001111000',\n",
       "       '0111111110', '1110000111', '0010000100', '1101111011',\n",
       "       '0101111010', '1100110011', '1111001111', '0100110010',\n",
       "       '0000110000', '1100000011', '1111111111', '1010000101'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(palindromes)\n",
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = np.concatenate((x, palindromes))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for binary_string in x:\n",
    "    y.append(binary_string == binary_string[::-1])\n",
    "y = np.array(y)\n",
    "permutation_index = np.random.permutation(len(x))\n",
    "x = x[permutation_index]\n",
    "y = y[permutation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   6, -12])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.array([1, 2, -3])\n",
    "# b = np.array([2, 3, 4])\n",
    "# a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 20\n",
    "output_size = 1\n",
    "\n",
    "weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[991.61380209]]\n",
      "Epoch 100 : loss [[989.2316454]]\n",
      "Epoch 200 : loss [[319.53270712]]\n",
      "Epoch 300 : loss [[319.57421463]]\n",
      "Epoch 400 : loss [[319.61364199]]\n",
      "Epoch 500 : loss [[319.6512102]]\n",
      "Epoch 600 : loss [[319.6870946]]\n",
      "Epoch 700 : loss [[319.72143354]]\n",
      "Epoch 800 : loss [[319.75433739]]\n",
      "Epoch 900 : loss [[319.78589815]]\n",
      "Epoch 1000 : loss [[319.81620019]]\n",
      "Epoch 1100 : loss [[319.84533201]]\n",
      "Epoch 1200 : loss [[319.87339917]]\n",
      "Epoch 1300 : loss [[319.90053773]]\n",
      "Epoch 1400 : loss [[319.92692755]]\n",
      "Epoch 1500 : loss [[319.9528046]]\n",
      "Epoch 1600 : loss [[319.97847091]]\n",
      "Epoch 1700 : loss [[320.00430116]]\n",
      "Epoch 1800 : loss [[320.03074492]]\n",
      "Epoch 1900 : loss [[320.05832377]]\n",
      "Epoch 2000 : loss [[320.08762303]]\n",
      "Epoch 2100 : loss [[320.11927799]]\n",
      "Epoch 2200 : loss [[320.15395461]]\n",
      "Epoch 2300 : loss [[320.19232432]]\n",
      "Epoch 2400 : loss [[320.23503171]]\n",
      "Epoch 2500 : loss [[320.28265285]]\n",
      "Epoch 2600 : loss [[320.33564028]]\n",
      "Epoch 2700 : loss [[320.39424877]]\n",
      "Epoch 2800 : loss [[320.45843371]]\n",
      "Epoch 2900 : loss [[320.52771224]]\n",
      "Epoch 3000 : loss [[320.60097475]]\n",
      "Epoch 3100 : loss [[320.67623404]]\n",
      "Epoch 3200 : loss [[320.75029944]]\n",
      "Epoch 3300 : loss [[320.81836663]]\n",
      "Epoch 3400 : loss [[320.87352024]]\n",
      "Epoch 3500 : loss [[320.90615562]]\n",
      "Epoch 3600 : loss [[320.90333478]]\n",
      "Epoch 3700 : loss [[320.84808857]]\n",
      "Epoch 3800 : loss [[320.71864462]]\n",
      "Epoch 3900 : loss [[320.48748889]]\n",
      "Epoch 4000 : loss [[320.12009745]]\n",
      "Epoch 4100 : loss [[319.57321731]]\n",
      "Epoch 4200 : loss [[318.79283617]]\n",
      "Epoch 4300 : loss [[317.71237063]]\n",
      "Epoch 4400 : loss [[316.25183063]]\n",
      "Epoch 4500 : loss [[314.31860957]]\n",
      "Epoch 4600 : loss [[311.81032712]]\n",
      "Epoch 4700 : loss [[308.62023224]]\n",
      "Epoch 4800 : loss [[304.64616066]]\n",
      "Epoch 4900 : loss [[299.80425637]]\n",
      "Epoch 5000 : loss [[294.04706493]]\n",
      "Epoch 5100 : loss [[287.38122968]]\n",
      "Epoch 5200 : loss [[279.87587872]]\n",
      "Epoch 5300 : loss [[271.65535658]]\n",
      "Epoch 5400 : loss [[262.87946312]]\n",
      "Epoch 5500 : loss [[253.72091432]]\n",
      "Epoch 5600 : loss [[244.34743878]]\n",
      "Epoch 5700 : loss [[234.9103267]]\n",
      "Epoch 5800 : loss [[225.53835093]]\n",
      "Epoch 5900 : loss [[216.33570851]]\n",
      "Epoch 6000 : loss [[207.38289088]]\n",
      "Epoch 6100 : loss [[198.73939359]]\n",
      "Epoch 6200 : loss [[190.44717023]]\n",
      "Epoch 6300 : loss [[182.53397393]]\n",
      "Epoch 6400 : loss [[175.01614429]]\n",
      "Epoch 6500 : loss [[167.90077537]]\n",
      "Epoch 6600 : loss [[161.18740928]]\n",
      "Epoch 6700 : loss [[154.86944061]]\n",
      "Epoch 6800 : loss [[148.93536325]]\n",
      "Epoch 6900 : loss [[143.36991774]]\n",
      "Epoch 7000 : loss [[138.15514523]]\n",
      "Epoch 7100 : loss [[133.27133094]]\n",
      "Epoch 7200 : loss [[128.69781856]]\n",
      "Epoch 7300 : loss [[124.41368476]]\n",
      "Epoch 7400 : loss [[120.39827326]]\n",
      "Epoch 7500 : loss [[116.6315961]]\n",
      "Epoch 7600 : loss [[113.09461596]]\n",
      "Epoch 7700 : loss [[109.76942693]]\n",
      "Epoch 7800 : loss [[106.6393526]]\n",
      "Epoch 7900 : loss [[103.68898013]]\n",
      "Epoch 8000 : loss [[100.90414718]]\n",
      "Epoch 8100 : loss [[98.27189634]]\n",
      "Epoch 8200 : loss [[95.78040878]]\n",
      "Epoch 8300 : loss [[93.41892608]]\n",
      "Epoch 8400 : loss [[91.1776669]]\n",
      "Epoch 8500 : loss [[89.04774305]]\n",
      "Epoch 8600 : loss [[87.02107814]]\n",
      "Epoch 8700 : loss [[85.09033038]]\n",
      "Epoch 8800 : loss [[83.24882098]]\n",
      "Epoch 8900 : loss [[81.49046816]]\n",
      "Epoch 9000 : loss [[79.80972729]]\n",
      "Epoch 9100 : loss [[78.20153656]]\n",
      "Epoch 9200 : loss [[76.66126823]]\n",
      "Epoch 9300 : loss [[75.18468479]]\n",
      "Epoch 9400 : loss [[73.7678998]]\n",
      "Epoch 9500 : loss [[72.40734284]]\n",
      "Epoch 9600 : loss [[71.09972829]]\n",
      "Epoch 9700 : loss [[69.84202742]]\n",
      "Epoch 9800 : loss [[68.63144352]]\n",
      "Epoch 9900 : loss [[67.46538972]]\n"
     ]
    }
   ],
   "source": [
    "# LEARNING_RATE = 1e-7\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[0.70983834]]\n",
      "Epoch 100 : loss [[0.7091767]]\n",
      "Epoch 200 : loss [[0.70852412]]\n",
      "Epoch 300 : loss [[0.70787714]]\n",
      "Epoch 400 : loss [[0.70723423]]\n",
      "Epoch 500 : loss [[0.70659466]]\n",
      "Epoch 600 : loss [[0.70595803]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m hlayer_output \u001b[38;5;241m=\u001b[39m sigmoid(hlayer_logits)\n\u001b[1;32m      9\u001b[0m final_logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(hlayer_output, weights_ho)\n\u001b[0;32m---> 10\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tot_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(final_output \u001b[38;5;241m-\u001b[39m y[i])\n\u001b[1;32m     14\u001b[0m output_delta \u001b[38;5;241m=\u001b[39m (y[i] \u001b[38;5;241m-\u001b[39m final_output) \u001b[38;5;241m*\u001b[39m final_output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m final_output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99802693]]\n",
      "[[9.87927878e-05]]\n"
     ]
    }
   ],
   "source": [
    "x_test1 = '1100110011'\n",
    "x_test2 = '1100110000'\n",
    "def test(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "    return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)), weights_ho))\n",
    "\n",
    "print(test(x_test1))\n",
    "print(test(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('weights_ih.npy', weights_ih)\n",
    "# np.save('weights_ho.npy', weights_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import activation, dataset, losses\n",
    "from model import *\n",
    "import numpy as np\n",
    "\n",
    "Dataset = dataset.Palindrome_Dataset(n_bits=10)\n",
    "x,y = Dataset.get_data(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Palindrome_Model(input_size=1dataset0, output_size=1,hidden_layer_sizes=[4],activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
       "  'weights': array([[ 0.08701854, -0.19543489,  1.12983589,  0.04685803],\n",
       "         [-0.11306758, -0.19295109, -0.36208643, -0.65408091],\n",
       "         [ 0.89565762,  0.90016614, -0.20350269,  0.35228063],\n",
       "         [ 1.16677101,  0.06401665,  0.32028525,  0.37577088],\n",
       "         [ 0.73298734, -0.27092703, -0.048532  ,  0.20221205],\n",
       "         [-0.76231812, -1.06370107,  0.25430709, -0.00645013],\n",
       "         [-0.0719853 ,  0.02542935, -0.90182575, -0.91726245],\n",
       "         [-0.78590996,  0.28289155, -0.28547343,  0.66010028],\n",
       "         [ 1.55533262, -0.39884791, -0.06661003,  0.20458392],\n",
       "         [-0.08053847,  0.58702988, -0.37884862,  0.81494488]]),\n",
       "  'biases': array([-0.35123382, -0.87013436,  0.8724007 , -1.27402972]),\n",
       "  'activation': 'relu'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[ 0.60919384],\n",
       "         [ 0.41314292],\n",
       "         [ 0.26754641],\n",
       "         [-0.51083802]]),\n",
       "  'biases': array([-0.73706457]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = x[100]\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weigths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Sem8/CS772/assign1-palindrome/model.py:59\u001b[0m, in \u001b[0;36mPalindrome_Model.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(x, layer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiases\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m     x \u001b[38;5;241m=\u001b[39m act_funcs[layer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mactivate(x)\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweigths\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBiases:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiases\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weigths'"
     ]
    }
   ],
   "source": [
    "model.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sem8",
   "language": "python",
   "name": "env_sem8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
