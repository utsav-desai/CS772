{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from faker import Faker\n",
    "import random\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "palindromes = []\n",
    "for i in range(1024):\n",
    "    binary_string = format(i, '010b')\n",
    "    x.append(binary_string)\n",
    "    if binary_string == binary_string[::-1]:\n",
    "        palindromes.append(binary_string)\n",
    "        \n",
    "x = np.array(x)\n",
    "palindromes = np.array(palindromes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = np.concatenate((x, palindromes))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for binary_string in x:\n",
    "    y.append(binary_string == binary_string[::-1])\n",
    "y = np.array(y)\n",
    "permutation_index = np.random.permutation(len(x))\n",
    "x = x[permutation_index]\n",
    "y = y[permutation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   6, -12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, -3])\n",
    "b = np.array([2, 3, 4])\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 4\n",
    "output_size = 1\n",
    "\n",
    "weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[350.69293608]]\n",
      "Epoch 100 : loss [[299.4903219]]\n",
      "Epoch 200 : loss [[135.02385372]]\n",
      "Epoch 300 : loss [[89.33586007]]\n",
      "Epoch 400 : loss [[72.28477052]]\n",
      "Epoch 500 : loss [[63.76324349]]\n",
      "Epoch 600 : loss [[51.21375084]]\n",
      "Epoch 700 : loss [[42.90495088]]\n",
      "Epoch 800 : loss [[37.17295526]]\n",
      "Epoch 900 : loss [[33.01231996]]\n",
      "Epoch 1000 : loss [[29.85090628]]\n",
      "Epoch 1100 : loss [[27.35865591]]\n",
      "Epoch 1200 : loss [[25.1734282]]\n",
      "Epoch 1300 : loss [[21.63451688]]\n",
      "Epoch 1400 : loss [[20.43884781]]\n",
      "Epoch 1500 : loss [[19.54680717]]\n",
      "Epoch 1600 : loss [[18.74940425]]\n",
      "Epoch 1700 : loss [[18.02193883]]\n",
      "Epoch 1800 : loss [[17.35287261]]\n",
      "Epoch 1900 : loss [[16.7339093]]\n",
      "Epoch 2000 : loss [[16.15857984]]\n",
      "Epoch 2100 : loss [[15.62164798]]\n",
      "Epoch 2200 : loss [[15.1187365]]\n",
      "Epoch 2300 : loss [[14.64607498]]\n",
      "Epoch 2400 : loss [[14.20033851]]\n",
      "Epoch 2500 : loss [[13.77858456]]\n",
      "Epoch 2600 : loss [[13.37828262]]\n",
      "Epoch 2700 : loss [[12.99699084]]\n",
      "Epoch 2800 : loss [[12.62988553]]\n",
      "Epoch 2900 : loss [[12.26707656]]\n",
      "Epoch 3000 : loss [[11.90246476]]\n",
      "Epoch 3100 : loss [[11.53732999]]\n",
      "Epoch 3200 : loss [[11.15825796]]\n",
      "Epoch 3300 : loss [[10.56144104]]\n",
      "Epoch 3400 : loss [[9.50717164]]\n",
      "Epoch 3500 : loss [[8.51638498]]\n",
      "Epoch 3600 : loss [[7.97365796]]\n",
      "Epoch 3700 : loss [[7.58067351]]\n",
      "Epoch 3800 : loss [[7.16846631]]\n",
      "Epoch 3900 : loss [[6.38755539]]\n",
      "Epoch 4000 : loss [[5.30724763]]\n",
      "Epoch 4100 : loss [[5.0699237]]\n",
      "Epoch 4200 : loss [[4.88941429]]\n",
      "Epoch 4300 : loss [[4.74744895]]\n",
      "Epoch 4400 : loss [[4.6335247]]\n",
      "Epoch 4500 : loss [[4.54011779]]\n",
      "Epoch 4600 : loss [[4.46190204]]\n",
      "Epoch 4700 : loss [[4.39506781]]\n",
      "Epoch 4800 : loss [[4.33686113]]\n",
      "Epoch 4900 : loss [[4.28526022]]\n",
      "Epoch 5000 : loss [[4.23876422]]\n",
      "Epoch 5100 : loss [[4.19625363]]\n",
      "Epoch 5200 : loss [[4.1568919]]\n",
      "Epoch 5300 : loss [[4.12005265]]\n",
      "Epoch 5400 : loss [[4.08526514]]\n",
      "Epoch 5500 : loss [[4.05217357]]\n",
      "Epoch 5600 : loss [[4.02050698]]\n",
      "Epoch 5700 : loss [[3.99005712]]\n",
      "Epoch 5800 : loss [[3.96066229]]\n",
      "Epoch 5900 : loss [[3.93219546]]\n",
      "Epoch 6000 : loss [[3.90455569]]\n",
      "Epoch 6100 : loss [[3.87766173]]\n",
      "Epoch 6200 : loss [[3.85144739]]\n",
      "Epoch 6300 : loss [[3.82585804]]\n",
      "Epoch 6400 : loss [[3.80084806]]\n",
      "Epoch 6500 : loss [[3.77637885]]\n",
      "Epoch 6600 : loss [[3.75241742]]\n",
      "Epoch 6700 : loss [[3.72893524]]\n",
      "Epoch 6800 : loss [[3.70590737]]\n",
      "Epoch 6900 : loss [[3.68331183]]\n",
      "Epoch 7000 : loss [[3.66112904]]\n",
      "Epoch 7100 : loss [[3.63934143]]\n",
      "Epoch 7200 : loss [[3.61793312]]\n",
      "Epoch 7300 : loss [[3.59688964]]\n",
      "Epoch 7400 : loss [[3.57619776]]\n",
      "Epoch 7500 : loss [[3.55584525]]\n",
      "Epoch 7600 : loss [[3.53582081]]\n",
      "Epoch 7700 : loss [[3.51611392]]\n",
      "Epoch 7800 : loss [[3.49671476]]\n",
      "Epoch 7900 : loss [[3.47761409]]\n",
      "Epoch 8000 : loss [[3.45880325]]\n",
      "Epoch 8100 : loss [[3.44027404]]\n",
      "Epoch 8200 : loss [[3.42201871]]\n",
      "Epoch 8300 : loss [[3.40402989]]\n",
      "Epoch 8400 : loss [[3.38630059]]\n",
      "Epoch 8500 : loss [[3.36882412]]\n",
      "Epoch 8600 : loss [[3.35159413]]\n",
      "Epoch 8700 : loss [[3.33460451]]\n",
      "Epoch 8800 : loss [[3.31784941]]\n",
      "Epoch 8900 : loss [[3.30132324]]\n",
      "Epoch 9000 : loss [[3.28502062]]\n",
      "Epoch 9100 : loss [[3.26893635]]\n",
      "Epoch 9200 : loss [[3.25306545]]\n",
      "Epoch 9300 : loss [[3.23740312]]\n",
      "Epoch 9400 : loss [[3.22194472]]\n",
      "Epoch 9500 : loss [[3.20668577]]\n",
      "Epoch 9600 : loss [[3.19162195]]\n",
      "Epoch 9700 : loss [[3.17674908]]\n",
      "Epoch 9800 : loss [[3.1620631]]\n",
      "Epoch 9900 : loss [[3.14756009]]\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wrong predicitons: 0\n",
      "Number of palindromes predicted as non palindromes: 0\n",
      "Number of palindromes non predicted as palindromes: 0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "pal = 0\n",
    "nonpal = 0\n",
    "for i, data in enumerate(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in data]), (1, input_size))\n",
    "    out = sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)), weights_ho))\n",
    "    if out > 0.5 and y[i] == 0:\n",
    "        nonpal += 1\n",
    "        count += 1\n",
    "    if out <= 0.5 and y[i] == 1:\n",
    "        pal += 1\n",
    "        count += 1\n",
    "print(f'Total wrong predicitons: {count}')\n",
    "print(f'Number of palindromes predicted as non palindromes: {pal}')\n",
    "print(f'Number of palindromes non predicted as palindromes: {nonpal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99983459]]\n",
      "[[3.25529473e-09]]\n"
     ]
    }
   ],
   "source": [
    "x_test1 = '1000110001'\n",
    "x_test2 = '1100110000'\n",
    "def test(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "    return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)), weights_ho))\n",
    "\n",
    "print(test(x_test1))\n",
    "print(test(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('weights_ih.npy', weights_ih)\n",
    "# np.save('weights_ho.npy', weights_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_ih = np.load('/Users/utsavmdesai/Documents/Utsav/SEM 8/CS 772/Assignments/assign1-palindrome/weights_ih.npy')\n",
    "# weights_ho = np.load('/Users/utsavmdesai/Documents/Utsav/SEM 8/CS 772/Assignments/assign1-palindrome/weights_ho.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29.52616281],\n",
       "       [-17.98447369],\n",
       "       [ 29.44768643],\n",
       "       [-35.3861514 ]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.24782865,   1.35153133,   9.98111405,   0.03075372],\n",
       "       [ -4.304942  ,  -2.42478086,   5.02954046,   7.35538849],\n",
       "       [  6.86795366,   1.09115832,  -6.18489002,   0.14353161],\n",
       "       [-24.95550334,   1.08248183,  25.85099723,   0.10903376],\n",
       "       [-12.3281825 ,   1.10220228,  13.1483093 ,   0.12144731],\n",
       "       [ 13.04143585,   1.10960998, -12.42752292,   0.12517852],\n",
       "       [ 25.64254456,   1.08344555, -25.16144267,   0.11997235],\n",
       "       [ -6.13460765,   1.09091388,   6.92799378,   0.13539465],\n",
       "       [  4.98673407,  -2.4219316 ,  -4.33870904,   7.37191884],\n",
       "       [  9.90112064,   1.35089313,  -9.32615158,   0.03972586]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_ih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs772",
   "language": "python",
   "name": "cs772"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
