{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "markdown",
=======
   "cell_type": "code",
   "execution_count": 2,
>>>>>>> main
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Import Libraries"
=======
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from faker import Faker\n",
    "import random\n",
    "import time\n",
    "np.random.seed()"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87113/2556754689.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from faker import Faker\n",
    "import random\n",
    "np.random.seed()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
=======
   "execution_count": 53,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "palindromes = []\n",
    "for i in range(1024):\n",
    "    binary_string = format(i, '010b')\n",
    "    x.append(binary_string)\n",
    "    if binary_string == binary_string[::-1]:\n",
    "        palindromes.append(binary_string)\n",
    "        \n",
    "x = np.array(x)\n",
    "palindromes = np.array(palindromes)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0000000000', '0000110000', '0001001000', '0001111000',\n",
       "       '0010000100', '0010110100', '0011001100', '0011111100',\n",
       "       '0100000010', '0100110010', '0101001010', '0101111010',\n",
       "       '0110000110', '0110110110', '0111001110', '0111111110',\n",
       "       '1000000001', '1000110001', '1001001001', '1001111001',\n",
       "       '1010000101', '1010110101', '1011001101', '1011111101',\n",
       "       '1100000011', '1100110011', '1101001011', '1101111011',\n",
       "       '1110000111', '1110110111', '1111001111', '1111111111'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0111111110', '1011001101', '0001111000', '0111001110',\n",
       "       '0100110010', '1011111101', '1101001011', '1110000111',\n",
       "       '1000000001', '1110110111', '0101001010', '1001001001',\n",
       "       '1000110001', '0001001000', '1100110011', '0000110000',\n",
       "       '1010000101', '1001111001', '1010110101', '1111111111',\n",
       "       '0110000110', '0010110100', '0110110110', '0011111100',\n",
       "       '0000000000', '0010000100', '1101111011', '0100000010',\n",
       "       '1111001111', '0011001100', '0101111010', '1100000011'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(palindromes)\n",
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
   "execution_count": 54,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = np.concatenate((x, palindromes))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 55,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for binary_string in x:\n",
    "    y.append(binary_string == binary_string[::-1])\n",
    "y = np.array(y)\n",
    "permutation_index = np.random.permutation(len(x))\n",
    "x = x[permutation_index]\n",
    "y = y[permutation_index]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 6,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   6, -12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> main
   "source": [
    "# a = np.array([1, 2, -3])\n",
    "# b = np.array([2, 3, 4])\n",
    "# a*b"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 81,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 4\n",
    "output_size = 1\n",
    "\n",
    "weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
=======
   "execution_count": 82,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 0 : loss 0\n",
      "Epoch 100 : loss 0\n",
      "Epoch 200 : loss 0\n",
      "Epoch 300 : loss 0\n",
      "Epoch 400 : loss 0\n",
      "Epoch 500 : loss 0\n",
      "Epoch 600 : loss 0\n",
      "Epoch 700 : loss 0\n",
      "Epoch 800 : loss 0\n",
      "Epoch 900 : loss 0\n",
      "Epoch 1000 : loss 0\n",
      "Epoch 1100 : loss 0\n",
      "Epoch 1200 : loss 0\n",
      "Epoch 1300 : loss 0\n",
      "Epoch 1400 : loss 0\n",
      "Epoch 1500 : loss 0\n",
      "Epoch 1600 : loss 0\n",
      "Epoch 1700 : loss 0\n",
      "Epoch 1800 : loss 0\n",
      "Epoch 1900 : loss 0\n",
      "Epoch 2000 : loss 0\n",
      "Epoch 2100 : loss 0\n",
      "Epoch 2200 : loss 0\n",
      "Epoch 2300 : loss 0\n",
      "Epoch 2400 : loss 0\n",
      "Epoch 2500 : loss 0\n",
      "Epoch 2600 : loss 0\n",
      "Epoch 2700 : loss 0\n",
      "Epoch 2800 : loss 0\n",
      "Epoch 2900 : loss 0\n",
      "Epoch 3000 : loss 0\n",
      "Epoch 3100 : loss 0\n",
      "Epoch 3200 : loss 0\n",
      "Epoch 3300 : loss 0\n",
      "Epoch 3400 : loss 0\n",
      "Epoch 3500 : loss 0\n",
      "Epoch 3600 : loss 0\n",
      "Epoch 3700 : loss 0\n",
      "Epoch 3800 : loss 0\n",
      "Epoch 3900 : loss 0\n",
      "Epoch 4000 : loss 0\n",
      "Epoch 4100 : loss 0\n",
      "Epoch 4200 : loss 0\n",
      "Epoch 4300 : loss 0\n",
      "Epoch 4400 : loss 0\n",
      "Epoch 4500 : loss 0\n",
      "Epoch 4600 : loss 0\n",
      "Epoch 4700 : loss 0\n",
      "Epoch 4800 : loss 0\n",
      "Epoch 4900 : loss 0\n",
      "Epoch 5000 : loss 0\n",
      "Epoch 5100 : loss 0\n",
      "Epoch 5200 : loss 0\n",
      "Epoch 5300 : loss 0\n",
      "Epoch 5400 : loss 0\n",
      "Epoch 5500 : loss 0\n",
      "Epoch 5600 : loss 0\n",
      "Epoch 5700 : loss 0\n",
      "Epoch 5800 : loss 0\n",
      "Epoch 5900 : loss 0\n",
      "Epoch 6000 : loss 0\n",
      "Epoch 6100 : loss 0\n",
      "Epoch 6200 : loss 0\n",
      "Epoch 6300 : loss 0\n",
      "Epoch 6400 : loss 0\n",
      "Epoch 6500 : loss 0\n",
      "Epoch 6600 : loss 0\n",
      "Epoch 6700 : loss 0\n",
      "Epoch 6800 : loss 0\n",
      "Epoch 6900 : loss 0\n",
      "Epoch 7000 : loss 0\n",
      "Epoch 7100 : loss 0\n",
      "Epoch 7200 : loss 0\n",
      "Epoch 7300 : loss 0\n",
      "Epoch 7400 : loss 0\n",
      "Epoch 7500 : loss 0\n",
      "Epoch 7600 : loss 0\n",
      "Epoch 7700 : loss 0\n",
      "Epoch 7800 : loss 0\n",
      "Epoch 7900 : loss 0\n",
      "Epoch 8000 : loss 0\n",
      "Epoch 8100 : loss 0\n",
      "Epoch 8200 : loss 0\n",
      "Epoch 8300 : loss 0\n",
      "Epoch 8400 : loss 0\n",
      "Epoch 8500 : loss 0\n",
      "Epoch 8600 : loss 0\n",
      "Epoch 8700 : loss 0\n",
      "Epoch 8800 : loss 0\n",
      "Epoch 8900 : loss 0\n",
      "Epoch 9000 : loss 0\n",
      "Epoch 9100 : loss 0\n",
      "Epoch 9200 : loss 0\n",
      "Epoch 9300 : loss 0\n",
      "Epoch 9400 : loss 0\n",
      "Epoch 9500 : loss 0\n",
      "Epoch 9600 : loss 0\n",
      "Epoch 9700 : loss 0\n",
      "Epoch 9800 : loss 0\n",
      "Epoch 9900 : loss 0\n"
     ]
    }
   ],
   "source": [
    "# LEARNING_RATE = 1e-7\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss 0\n",
      "Epoch 100 : loss 0\n",
      "Epoch 200 : loss 0\n",
      "Epoch 300 : loss 0\n",
      "Epoch 400 : loss 0\n",
      "Epoch 500 : loss 0\n",
      "Epoch 600 : loss 0\n",
      "Epoch 700 : loss 0\n",
      "Epoch 800 : loss 0\n",
      "Epoch 900 : loss 0\n",
      "Epoch 1000 : loss 0\n",
      "Epoch 1100 : loss 0\n",
      "Epoch 1200 : loss 0\n",
      "Epoch 1300 : loss 0\n",
      "Epoch 1400 : loss 0\n",
      "Epoch 1500 : loss 0\n",
      "Epoch 1600 : loss 0\n",
      "Epoch 1700 : loss 0\n",
      "Epoch 1800 : loss 0\n",
      "Epoch 1900 : loss 0\n",
      "Epoch 2000 : loss 0\n",
      "Epoch 2100 : loss 0\n",
      "Epoch 2200 : loss 0\n",
      "Epoch 2300 : loss 0\n",
      "Epoch 2400 : loss 0\n",
      "Epoch 2500 : loss 0\n",
      "Epoch 2600 : loss 0\n",
      "Epoch 2700 : loss 0\n",
      "Epoch 2800 : loss 0\n",
      "Epoch 2900 : loss 0\n",
      "Epoch 3000 : loss 0\n",
      "Epoch 3100 : loss 0\n",
      "Epoch 3200 : loss 0\n",
      "Epoch 3300 : loss 0\n",
      "Epoch 3400 : loss 0\n",
      "Epoch 3500 : loss 0\n",
      "Epoch 3600 : loss 0\n",
      "Epoch 3700 : loss 0\n",
      "Epoch 3800 : loss 0\n",
      "Epoch 3900 : loss 0\n",
      "Epoch 4000 : loss 0\n",
      "Epoch 4100 : loss 0\n",
      "Epoch 4200 : loss 0\n",
      "Epoch 4300 : loss 0\n",
      "Epoch 4400 : loss 0\n",
      "Epoch 4500 : loss 0\n",
      "Epoch 4600 : loss 0\n",
      "Epoch 4700 : loss 0\n",
      "Epoch 4800 : loss 0\n",
      "Epoch 4900 : loss 0\n",
      "Epoch 5000 : loss 0\n",
      "Epoch 5100 : loss 0\n",
      "Epoch 5200 : loss 0\n",
      "Epoch 5300 : loss 0\n",
      "Epoch 5400 : loss 0\n",
      "Epoch 5500 : loss 0\n",
      "Epoch 5600 : loss 0\n",
      "Epoch 5700 : loss 0\n",
      "Epoch 5800 : loss 0\n",
      "Epoch 5900 : loss 0\n",
      "Epoch 6000 : loss 0\n",
      "Epoch 6100 : loss 0\n",
      "Epoch 6200 : loss 0\n",
      "Epoch 6300 : loss 0\n",
      "Epoch 6400 : loss 0\n",
      "Epoch 6500 : loss 0\n",
      "Epoch 6600 : loss 0\n",
      "Epoch 6700 : loss 0\n",
      "Epoch 6800 : loss 0\n",
      "Epoch 6900 : loss 0\n",
      "Epoch 7000 : loss 0\n",
      "Epoch 7100 : loss 0\n",
      "Epoch 7200 : loss 0\n",
      "Epoch 7300 : loss 0\n",
      "Epoch 7400 : loss 0\n",
      "Epoch 7500 : loss 0\n",
      "Epoch 7600 : loss 0\n",
      "Epoch 7700 : loss 0\n",
      "Epoch 7800 : loss 0\n",
      "Epoch 7900 : loss 0\n",
      "Epoch 8000 : loss 0\n",
      "Epoch 8100 : loss 0\n",
      "Epoch 8200 : loss 0\n",
      "Epoch 8300 : loss 0\n",
      "Epoch 8400 : loss 0\n",
      "Epoch 8500 : loss 0\n",
      "Epoch 8600 : loss 0\n",
      "Epoch 8700 : loss 0\n",
      "Epoch 8800 : loss 0\n",
      "Epoch 8900 : loss 0\n",
      "Epoch 9000 : loss 0\n",
      "Epoch 9100 : loss 0\n",
      "Epoch 9200 : loss 0\n",
      "Epoch 9300 : loss 0\n",
      "Epoch 9400 : loss 0\n",
      "Epoch 9500 : loss 0\n",
      "Epoch 9600 : loss 0\n",
      "Epoch 9700 : loss 0\n",
      "Epoch 9800 : loss 0\n",
      "Epoch 9900 : loss 0\n"
=======
      "Epoch 0 : loss [[350.69293608]]\n",
      "Epoch 100 : loss [[299.4903219]]\n",
      "Epoch 200 : loss [[135.02385372]]\n",
      "Epoch 300 : loss [[89.33586007]]\n",
      "Epoch 400 : loss [[72.28477052]]\n",
      "Epoch 500 : loss [[63.76324349]]\n",
      "Epoch 600 : loss [[51.21375084]]\n",
      "Epoch 700 : loss [[42.90495088]]\n",
      "Epoch 800 : loss [[37.17295526]]\n",
      "Epoch 900 : loss [[33.01231996]]\n",
      "Epoch 1000 : loss [[29.85090628]]\n",
      "Epoch 1100 : loss [[27.35865591]]\n",
      "Epoch 1200 : loss [[25.1734282]]\n",
      "Epoch 1300 : loss [[21.63451688]]\n",
      "Epoch 1400 : loss [[20.43884781]]\n",
      "Epoch 1500 : loss [[19.54680717]]\n",
      "Epoch 1600 : loss [[18.74940425]]\n",
      "Epoch 1700 : loss [[18.02193883]]\n",
      "Epoch 1800 : loss [[17.35287261]]\n",
      "Epoch 1900 : loss [[16.7339093]]\n",
      "Epoch 2000 : loss [[16.15857984]]\n",
      "Epoch 2100 : loss [[15.62164798]]\n",
      "Epoch 2200 : loss [[15.1187365]]\n",
      "Epoch 2300 : loss [[14.64607498]]\n",
      "Epoch 2400 : loss [[14.20033851]]\n",
      "Epoch 2500 : loss [[13.77858456]]\n",
      "Epoch 2600 : loss [[13.37828262]]\n",
      "Epoch 2700 : loss [[12.99699084]]\n",
      "Epoch 2800 : loss [[12.62988553]]\n",
      "Epoch 2900 : loss [[12.26707656]]\n",
      "Epoch 3000 : loss [[11.90246476]]\n",
      "Epoch 3100 : loss [[11.53732999]]\n",
      "Epoch 3200 : loss [[11.15825796]]\n",
      "Epoch 3300 : loss [[10.56144104]]\n",
      "Epoch 3400 : loss [[9.50717164]]\n",
      "Epoch 3500 : loss [[8.51638498]]\n",
      "Epoch 3600 : loss [[7.97365796]]\n",
      "Epoch 3700 : loss [[7.58067351]]\n",
      "Epoch 3800 : loss [[7.16846631]]\n",
      "Epoch 3900 : loss [[6.38755539]]\n",
      "Epoch 4000 : loss [[5.30724763]]\n",
      "Epoch 4100 : loss [[5.0699237]]\n",
      "Epoch 4200 : loss [[4.88941429]]\n",
      "Epoch 4300 : loss [[4.74744895]]\n",
      "Epoch 4400 : loss [[4.6335247]]\n",
      "Epoch 4500 : loss [[4.54011779]]\n",
      "Epoch 4600 : loss [[4.46190204]]\n",
      "Epoch 4700 : loss [[4.39506781]]\n",
      "Epoch 4800 : loss [[4.33686113]]\n",
      "Epoch 4900 : loss [[4.28526022]]\n",
      "Epoch 5000 : loss [[4.23876422]]\n",
      "Epoch 5100 : loss [[4.19625363]]\n",
      "Epoch 5200 : loss [[4.1568919]]\n",
      "Epoch 5300 : loss [[4.12005265]]\n",
      "Epoch 5400 : loss [[4.08526514]]\n",
      "Epoch 5500 : loss [[4.05217357]]\n",
      "Epoch 5600 : loss [[4.02050698]]\n",
      "Epoch 5700 : loss [[3.99005712]]\n",
      "Epoch 5800 : loss [[3.96066229]]\n",
      "Epoch 5900 : loss [[3.93219546]]\n",
      "Epoch 6000 : loss [[3.90455569]]\n",
      "Epoch 6100 : loss [[3.87766173]]\n",
      "Epoch 6200 : loss [[3.85144739]]\n",
      "Epoch 6300 : loss [[3.82585804]]\n",
      "Epoch 6400 : loss [[3.80084806]]\n",
      "Epoch 6500 : loss [[3.77637885]]\n",
      "Epoch 6600 : loss [[3.75241742]]\n",
      "Epoch 6700 : loss [[3.72893524]]\n",
      "Epoch 6800 : loss [[3.70590737]]\n",
      "Epoch 6900 : loss [[3.68331183]]\n",
      "Epoch 7000 : loss [[3.66112904]]\n",
      "Epoch 7100 : loss [[3.63934143]]\n",
      "Epoch 7200 : loss [[3.61793312]]\n",
      "Epoch 7300 : loss [[3.59688964]]\n",
      "Epoch 7400 : loss [[3.57619776]]\n",
      "Epoch 7500 : loss [[3.55584525]]\n",
      "Epoch 7600 : loss [[3.53582081]]\n",
      "Epoch 7700 : loss [[3.51611392]]\n",
      "Epoch 7800 : loss [[3.49671476]]\n",
      "Epoch 7900 : loss [[3.47761409]]\n",
      "Epoch 8000 : loss [[3.45880325]]\n",
      "Epoch 8100 : loss [[3.44027404]]\n",
      "Epoch 8200 : loss [[3.42201871]]\n",
      "Epoch 8300 : loss [[3.40402989]]\n",
      "Epoch 8400 : loss [[3.38630059]]\n",
      "Epoch 8500 : loss [[3.36882412]]\n",
      "Epoch 8600 : loss [[3.35159413]]\n",
      "Epoch 8700 : loss [[3.33460451]]\n",
      "Epoch 8800 : loss [[3.31784941]]\n",
      "Epoch 8900 : loss [[3.30132324]]\n",
      "Epoch 9000 : loss [[3.28502062]]\n",
      "Epoch 9100 : loss [[3.26893635]]\n",
      "Epoch 9200 : loss [[3.25306545]]\n",
      "Epoch 9300 : loss [[3.23740312]]\n",
      "Epoch 9400 : loss [[3.22194472]]\n",
      "Epoch 9500 : loss [[3.20668577]]\n",
      "Epoch 9600 : loss [[3.19162195]]\n",
      "Epoch 9700 : loss [[3.17674908]]\n",
      "Epoch 9800 : loss [[3.1620631]]\n",
      "Epoch 9900 : loss [[3.14756009]]\n"
>>>>>>> main
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 83,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[[0.99986682]]\n",
      "[[0.99969992]]\n"
=======
      "Total wrong predicitons: 0\n",
      "Number of palindromes predicted as non palindromes: 0\n",
      "Number of palindromes non predicted as palindromes: 0\n"
>>>>>>> main
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "pal = 0\n",
    "nonpal = 0\n",
    "for i, data in enumerate(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in data]), (1, input_size))\n",
    "    out = sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)), weights_ho))\n",
    "    if out > 0.5 and y[i] == 0:\n",
    "        nonpal += 1\n",
    "        count += 1\n",
    "    if out <= 0.5 and y[i] == 1:\n",
    "        pal += 1\n",
    "        count += 1\n",
    "print(f'Total wrong predicitons: {count}')\n",
    "print(f'Number of palindromes predicted as non palindromes: {pal}')\n",
    "print(f'Number of palindromes non predicted as palindromes: {nonpal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99983459]]\n",
      "[[3.25529473e-09]]\n"
     ]
    }
   ],
   "source": [
    "x_test1 = '1000110001'\n",
    "x_test2 = '1100110000'\n",
    "def test(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "    return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)), weights_ho))\n",
    "\n",
    "print(test(x_test1))\n",
    "print(test(x_test2))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 97,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('checkpoints/weights_ih' + '_'.join(str(time.time()).split('.')) + '.npy', weights_ih)\n",
    "# np.save('checkpoints/weights_ho' + '_'.join(str(time.time()).split('.')) + '.npy', weights_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ho = np.load('/Users/utsavmdesai/Documents/Utsav/SEM 8/CS 772/Assignments/assign1-palindrome/checkpoints/weights_ho1705923683_8583539.npy')\n",
    "weights_ih = np.load('/Users/utsavmdesai/Documents/Utsav/SEM 8/CS 772/Assignments/assign1-palindrome/checkpoints/weights_ih1705923683_853643.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29.52616281],\n",
       "       [-17.98447369],\n",
       "       [ 29.44768643],\n",
       "       [-35.3861514 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.24782865,   1.35153133,   9.98111405,   0.03075372],\n",
       "       [ -4.304942  ,  -2.42478086,   5.02954046,   7.35538849],\n",
       "       [  6.86795366,   1.09115832,  -6.18489002,   0.14353161],\n",
       "       [-24.95550334,   1.08248183,  25.85099723,   0.10903376],\n",
       "       [-12.3281825 ,   1.10220228,  13.1483093 ,   0.12144731],\n",
       "       [ 13.04143585,   1.10960998, -12.42752292,   0.12517852],\n",
       "       [ 25.64254456,   1.08344555, -25.16144267,   0.11997235],\n",
       "       [ -6.13460765,   1.09091388,   6.92799378,   0.13539465],\n",
       "       [  4.98673407,  -2.4219316 ,  -4.33870904,   7.37191884],\n",
       "       [  9.90112064,   1.35089313,  -9.32615158,   0.03972586]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_ih"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utsavmdesai/Documents/Utsav/SEM 8/CS 772/Assignments/assign1-palindrome/utils/dataset.py:29: UserWarning: you are shuffling a 'flatiter' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(x.flat)\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 8a5a56a1ff5294aac29c152169eacf17d0912abf
   "source": [
    "from utils import activation, dataset, losses\n",
    "from model import *\n",
    "import numpy as np\n",
<<<<<<< HEAD
    "# np.random.seed(69)\n",
    "Dataset = dataset.Palindrome_Dataset(n_bits=10)\n",
    "x,y = Dataset.get_data(shuffle=True, biasing_factor=31)"
=======
    "\n",
    "Dataset = dataset.Palindrome_Dataset(n_bits=10)\n",
    "x_train,y_train = Dataset.get_data(shuffle=True, biasing_factor=20)\n"
>>>>>>> 8a5a56a1ff5294aac29c152169eacf17d0912abf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
       "  'weights': array([[ 0.16769564,  0.75670325,  0.62263716,  0.2727314 ],\n",
       "         [-0.21284762, -0.18264564,  1.06783169, -0.02231364],\n",
       "         [ 0.3576575 , -0.10566537,  0.1255692 ,  0.12361673],\n",
       "         [ 0.98624143, -0.05819921,  0.44425349, -0.11024212],\n",
       "         [-0.3669962 ,  0.03603563, -0.00349523,  0.08239108],\n",
       "         [-0.79323559,  0.46767248, -0.00516988, -0.77978055],\n",
       "         [ 0.61716754, -0.17580501, -0.19064652,  0.01236308],\n",
       "         [-1.3529401 ,  0.79269499, -0.47349823,  0.07774432],\n",
       "         [-0.80749843, -0.65498371, -0.58704537, -0.13027883],\n",
       "         [ 0.19642577, -0.00698707, -0.5577965 ,  0.08915547]]),\n",
       "  'biases': array([ 2.12912468, -0.76292663, -0.32806309,  0.45187915]),\n",
       "  'activation': 'relu'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[-1.08293061],\n",
       "         [-0.23996413],\n",
       "         [-0.44935948],\n",
       "         [-0.6134314 ]]),\n",
       "  'biases': array([0.31689972]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Palindrome_Model(input_size=10, output_size=1,hidden_layer_sizes=[4],activation='sigmoid')\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_optimizer(lr=0.05,loss=\"mse\", optimizer=\"bgd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 1664sample [00:00, 7016.86sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 2/100: 1664sample [00:00, 8511.71sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 3/100: 1664sample [00:00, 7746.94sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 4/100: 1664sample [00:00, 7559.14sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 5/100: 1664sample [00:00, 7449.51sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 6/100: 1664sample [00:00, 6748.77sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 7/100: 1664sample [00:00, 7851.24sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 8/100: 1664sample [00:00, 7956.55sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 9/100: 1664sample [00:00, 8060.25sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 10/100: 1664sample [00:00, 7962.99sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 11/100: 1664sample [00:00, 7919.22sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 12/100: 1664sample [00:00, 8106.63sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 13/100: 1664sample [00:00, 8147.39sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 14/100: 1664sample [00:00, 8038.58sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 15/100: 1664sample [00:00, 8058.39sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 16/100: 1664sample [00:00, 7953.82sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 17/100: 1664sample [00:00, 7303.57sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 18/100: 1664sample [00:00, 8782.80sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 19/100: 1664sample [00:00, 8576.85sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 20/100: 1664sample [00:00, 8682.90sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 21/100: 1664sample [00:00, 8619.08sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 22/100: 1664sample [00:00, 8578.44sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 23/100: 1664sample [00:00, 8374.61sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 24/100: 1664sample [00:00, 8118.90sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 25/100: 1664sample [00:00, 8271.80sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 26/100: 1664sample [00:00, 8303.45sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 27/100: 1664sample [00:00, 8251.30sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 28/100: 1664sample [00:00, 8251.34sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 29/100: 1664sample [00:00, 8140.53sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 30/100: 1664sample [00:00, 8223.20sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 31/100: 1664sample [00:00, 8490.22sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 32/100: 1664sample [00:00, 8211.66sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 33/100: 1664sample [00:00, 8355.29sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 34/100: 1664sample [00:00, 8226.00sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 35/100: 1664sample [00:00, 8374.55sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 36/100: 1664sample [00:00, 8385.36sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 37/100: 1664sample [00:00, 8381.71sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 38/100: 1664sample [00:00, 8615.69sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 39/100: 1664sample [00:00, 8574.37sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 40/100: 1664sample [00:00, 8565.06sample/s, accuracy=59.6, loss=12.6] \n",
      "Epoch 41/100: 1664sample [00:00, 8479.95sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 42/100: 1664sample [00:00, 8039.24sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 43/100: 1664sample [00:00, 8535.36sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 44/100: 1664sample [00:00, 8572.52sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 45/100: 1664sample [00:00, 7984.61sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 46/100: 1664sample [00:00, 8045.73sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 47/100: 1664sample [00:00, 7555.51sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 48/100: 1664sample [00:00, 7904.47sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 49/100: 1664sample [00:00, 7816.54sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 50/100: 1664sample [00:00, 7996.44sample/s, accuracy=59.6, loss=12.6]\n",
      "Epoch 51/100: 512sample [00:00, 6589.46sample/s]        \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracies, losses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Sem8/CS772/assign1-palindrome/model.py:162\u001b[0m, in \u001b[0;36mPalindrome_Model.train\u001b[0;34m(self, X_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[1;32m    160\u001b[0m         batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(predicted, targets)                    \n\u001b[1;32m    161\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m--> 162\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(batch_size)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Sem8/CS772/assign1-palindrome/model.py:116\u001b[0m, in \u001b[0;36mPalindrome_Model.backward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m    114\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiases\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    115\u001b[0m     net\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m--> 116\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_funcs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mactivation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     o\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    119\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, target)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracies, losses = model.train(x_train,y_train,epochs=100,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2725399.477086875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(x)\n",
    "y_pred = np.clip(y_pred, 1e-12, 1 - 1e-12)\n",
    "-np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - (y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_x = x[:48]\n",
    "# temp_y = y[:48]\n",
    "# print(temp_x, temp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolving Bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset\n",
    "from model import Palindrome_Model\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "Dataset = dataset.Palindrome_Dataset(n_bits=10)\n",
    "x,y = Dataset.get_data(shuffle=True, biasing_factor=20)\n",
    "model = Palindrome_Model(input_size=10, output_size=1,hidden_layer_sizes=[4],activation='sigmoid')\n",
    "model.set_optimizer(lr=0.005,loss=\"bce\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 1 1 0 1] 1\n",
      "[1 1 1 1 1 1 1 1 0 1] 0\n"
     ]
    }
   ],
   "source": [
    "temp = [np.array([1,0,1,1,1,1,1,1,0,1]), np.array([1,1,1,1,1,1,1,1,0,1])]\n",
    "y_temp = [1, 0]\n",
    "\n",
    "\n",
    "for x,y in zip(temp,y_temp):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88834677],\n",
       "       [0.89637692]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backward([temp[1]], [y_temp[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0.]), array([0.89496408])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_palindromes = np.array([np.reshape(np.array([int(char) for char in s]), (10,)) for s in Dataset.palindromes])\n",
    "y_palindromes = np.array([1]*32)\n",
    "\n",
    "x_non_palindrome = np.array([np.reshape(np.array([int(char) for char in s]), (10,)) for s in Dataset.non_palindromes])\n",
    "y_non_palindrome = np.array([0]*len(x_non_palindrome))\n",
    "temp_x = np.concatenate((temp_x,x_palindromes))\n",
    "temp_y = np.concatenate((temp_y, y_palindromes))\n",
    "accuracies, losses = model.train(x_palindromes,y_palindromes,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_optimizer(lr=0.005,loss=\"mse\")\n",
    "accuracies, losses = model.train(temp_x,temp_y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_palindromes)\n",
    "accuracy_metric(predictions, y_palindromes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_non_palindrome)\n",
    "# print(predictions)\n",
    "accuracy_metric(predictions, y_non_palindrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch  Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
<<<<<<< HEAD
       "  'weights': array([[ 0.40990953, -1.31779659, -0.38301809,  0.2574612 ],\n",
       "         [ 0.21247218,  1.01222102,  0.26562002, -0.17084247],\n",
       "         [ 0.110363  , -0.88429782,  0.39847213,  0.37417169],\n",
       "         [-0.01295251, -1.04342606, -0.79104969, -0.28440282],\n",
       "         [ 0.18430906,  0.66152525,  0.12187513,  0.50124038],\n",
       "         [-0.21537762,  0.2625214 ,  0.01846349,  0.7519684 ],\n",
       "         [-0.63087984,  0.37654816, -0.21324107,  0.56693275],\n",
       "         [ 0.1122398 ,  0.45529731, -0.07231488, -0.00450499],\n",
       "         [-0.31628952,  0.8490859 ,  0.96884588, -0.61978351],\n",
       "         [ 0.39202648, -0.34820188,  0.49324658,  0.03635917]]),\n",
       "  'biases': array([-0.83539984,  0.4867526 ,  1.01051752,  0.81133522]),\n",
       "  'activation': 'linear'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[ 0.14447131],\n",
       "         [ 0.02631347],\n",
       "         [ 0.10839844],\n",
       "         [-0.88407763]]),\n",
       "  'biases': array([-2.3570417]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 3,
=======
       "  'weights': array([[ 0.93264673,  0.97459294, -0.12848894,  0.58921758],\n",
       "         [-0.61967231, -0.26271703, -0.26330762, -0.93215773],\n",
       "         [ 0.19383003, -1.06437594,  0.40447317, -0.24151142],\n",
       "         [-0.44076791, -0.58080072, -0.21027712, -0.61963486],\n",
       "         [-0.21196891, -0.25251799, -0.36971576, -0.07134193],\n",
       "         [-0.01738654,  0.49040936, -0.42500098, -0.1270861 ],\n",
       "         [-0.82970687,  0.77321702,  0.29156391, -0.54454293],\n",
       "         [ 0.42967041, -0.02238592, -0.17803028,  0.43492721],\n",
       "         [ 0.39676217, -0.09361975,  0.69012828,  0.31874703],\n",
       "         [ 0.4822464 ,  0.3571908 ,  0.47563312,  0.07272139]]),\n",
       "  'biases': array([-0.73642481, -0.58666945, -0.33631103,  0.80275304]),\n",
       "  'activation': 'relu'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[ 0.59679054],\n",
       "         [-0.80576963],\n",
       "         [ 0.08172214],\n",
       "         [-0.04323667]]),\n",
       "  'biases': array([2.17619008]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 4,
>>>>>>> 8a5a56a1ff5294aac29c152169eacf17d0912abf
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 1 1 0 1] 1\n",
      "[1 1 1 1 1 1 1 1 0 1] 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88995978],\n",
       "       [0.89793558]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(model,X:np.ndarray, y:np.ndarray, k_folds:int = 4, epochs_per_fold:int = 25):\n",
    "        fold_size = len(X) // k_folds\n",
    "        accuracies_fold = []\n",
    "        accuracies=[]\n",
    "        losses = []\n",
    "        for i in range(k_folds):\n",
    "            start, end = i * fold_size, (i + 1) * fold_size\n",
    "            X_test_fold, y_test_fold = X[start:end], y[start:end]\n",
    "            X_train_fold = np.concatenate([X[:start], X[end:]])\n",
    "            y_train_fold = np.concatenate([y[:start], y[end:]])\n",
    "            print(f\"Training Fold {i+1}\\n\")\n",
    "            accuracy, loss = model.train(X_train_fold, y_train_fold, epochs_per_fold)\n",
    "            accuracies.extend(accuracy)\n",
    "            losses.extend(loss)\n",
    "            print(\"\\n\"+10*\"----\"+\"\\n\")\n",
    "            predictions = model.predict(X_test_fold)\n",
    "            accuracies_fold.append(accuracy_metric(predictions, y_test_fold))\n",
    "        return accuracies_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = k_fold_cross_validation(model, x, y, epochs_per_fold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x)\n",
    "accuracy_metric(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(y)):\n",
    "    if predictions[i]==1:\n",
    "        count+=1\n",
    "        # print(x[i], y[i], predictions[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
>>>>>>> 8a5a56a1ff5294aac29c152169eacf17d0912abf
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 1/20:   1%|          | 15/2016 [00:00<00:01, 1754.99sample/s, loss=0.00872]"
=======
      "2024-01-31 14:15:37.847322: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-31 14:15:37.849795: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-31 14:15:37.884502: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 14:15:37.884540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 14:15:37.885533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 14:15:37.891463: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-31 14:15:37.891916: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 14:15:38.733732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 44        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49 (196.00 Byte)\n",
      "Trainable params: 49 (196.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
>>>>>>> 8a5a56a1ff5294aac29c152169eacf17d0912abf
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 1/20: 100%|| 2016/2016 [00:00<00:00, 2381.17sample/s, loss=0.00291] \n",
      "Epoch 2/20: 100%|| 2016/2016 [00:00<00:00, 2515.73sample/s, loss=0.00125] \n",
      "Epoch 3/20: 100%|| 2016/2016 [00:00<00:00, 2347.07sample/s, loss=0.000746]\n",
      "Epoch 4/20: 100%|| 2016/2016 [00:00<00:00, 2384.17sample/s, loss=0.000511]\n",
      "Epoch 5/20: 100%|| 2016/2016 [00:00<00:00, 2397.74sample/s, loss=0.00038] \n",
      "Epoch 6/20: 100%|| 2016/2016 [00:00<00:00, 2263.85sample/s, loss=0.000297]\n",
      "Epoch 7/20: 100%|| 2016/2016 [00:00<00:00, 2392.24sample/s, loss=0.000241]\n",
      "Epoch 8/20: 100%|| 2016/2016 [00:00<00:00, 2402.77sample/s, loss=0.000201]\n",
      "Epoch 9/20: 100%|| 2016/2016 [00:00<00:00, 2312.36sample/s, loss=0.000171]\n",
      "Epoch 10/20: 100%|| 2016/2016 [00:00<00:00, 2356.93sample/s, loss=0.000148]\n",
      "Epoch 11/20: 100%|| 2016/2016 [00:00<00:00, 2211.95sample/s, loss=0.00013] \n",
      "Epoch 12/20: 100%|| 2016/2016 [00:00<00:00, 2422.24sample/s, loss=0.000115]\n",
      "Epoch 13/20: 100%|| 2016/2016 [00:00<00:00, 2421.56sample/s, loss=0.000103]\n",
      "Epoch 14/20: 100%|| 2016/2016 [00:00<00:00, 2281.89sample/s, loss=9.33e-5] \n",
      "Epoch 15/20: 100%|| 2016/2016 [00:00<00:00, 2243.70sample/s, loss=8.48e-5] \n",
      "Epoch 16/20: 100%|| 2016/2016 [00:00<00:00, 2167.77sample/s, loss=7.75e-5] \n",
      "Epoch 17/20: 100%|| 2016/2016 [00:00<00:00, 2254.49sample/s, loss=7.12e-5] \n",
      "Epoch 18/20: 100%|| 2016/2016 [00:00<00:00, 2300.51sample/s, loss=6.58e-5] \n",
      "Epoch 19/20: 100%|| 2016/2016 [00:00<00:00, 2316.86sample/s, loss=6.1e-5]  \n",
      "Epoch 20/20: 100%|| 2016/2016 [00:00<00:00, 2142.58sample/s, loss=5.68e-5] \n"
=======
      "2024-01-31 14:15:39.663450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 14:15:39.663830: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
>>>>>>> 8a5a56a1ff5294aac29c152169eacf17d0912abf
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "model.train(x,y,epochs=20)"
=======
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(10,)),          # Input layer with size 10\n",
    "    layers.Dense(4, activation='relu'),          # Hidden layer with size 4 and linear activation\n",
    "    layers.Dense(1, activation='sigmoid')           # Output layer with size 1 and sigmoid activation\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0)\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
>>>>>>> 8a5a56a1ff5294aac29c152169eacf17d0912abf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
   "execution_count": 25,
>>>>>>> 8a5a56a1ff5294aac29c152169eacf17d0912abf
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.8948\n",
      "Epoch 2/30\n",
      "104/104 [==============================] - 0s 899us/step - loss: 0.1507 - accuracy: 0.8948\n",
      "Epoch 3/30\n",
      "104/104 [==============================] - 0s 959us/step - loss: 0.1494 - accuracy: 0.8942\n",
      "Epoch 4/30\n",
      "104/104 [==============================] - 0s 903us/step - loss: 0.1483 - accuracy: 0.8948\n",
      "Epoch 5/30\n",
      "104/104 [==============================] - 0s 851us/step - loss: 0.1472 - accuracy: 0.8936\n",
      "Epoch 6/30\n",
      "104/104 [==============================] - 0s 954us/step - loss: 0.1461 - accuracy: 0.8936\n",
      "Epoch 7/30\n",
      "104/104 [==============================] - 0s 918us/step - loss: 0.1450 - accuracy: 0.8942\n",
      "Epoch 8/30\n",
      "104/104 [==============================] - 0s 914us/step - loss: 0.1439 - accuracy: 0.8942\n",
      "Epoch 9/30\n",
      "104/104 [==============================] - 0s 908us/step - loss: 0.1428 - accuracy: 0.8942\n",
      "Epoch 10/30\n",
      "104/104 [==============================] - 0s 889us/step - loss: 0.1417 - accuracy: 0.8942\n",
      "Epoch 11/30\n",
      "104/104 [==============================] - 0s 985us/step - loss: 0.1407 - accuracy: 0.8948\n",
      "Epoch 12/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.8942\n",
      "Epoch 13/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.8960\n",
      "Epoch 14/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.8972\n",
      "Epoch 15/30\n",
      "104/104 [==============================] - 0s 995us/step - loss: 0.1367 - accuracy: 0.8960\n",
      "Epoch 16/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.8990\n",
      "Epoch 17/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.8990\n",
      "Epoch 18/30\n",
      "104/104 [==============================] - 0s 972us/step - loss: 0.1338 - accuracy: 0.8996\n",
      "Epoch 19/30\n",
      "104/104 [==============================] - 0s 939us/step - loss: 0.1329 - accuracy: 0.8984\n",
      "Epoch 20/30\n",
      "104/104 [==============================] - 0s 943us/step - loss: 0.1320 - accuracy: 0.9014\n",
      "Epoch 21/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.9002\n",
      "Epoch 22/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9014\n",
      "Epoch 23/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9014\n",
      "Epoch 24/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.8996\n",
      "Epoch 25/30\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9002\n",
      "Epoch 26/30\n",
      "104/104 [==============================] - 0s 927us/step - loss: 0.1268 - accuracy: 0.9020\n",
      "Epoch 27/30\n",
      "104/104 [==============================] - 0s 948us/step - loss: 0.1260 - accuracy: 0.9008\n",
      "Epoch 28/30\n",
      "104/104 [==============================] - 0s 916us/step - loss: 0.1252 - accuracy: 0.9002\n",
      "Epoch 29/30\n",
      "104/104 [==============================] - 0s 982us/step - loss: 0.1244 - accuracy: 0.9032\n",
      "Epoch 30/30\n",
      "104/104 [==============================] - 0s 948us/step - loss: 0.1236 - accuracy: 0.9014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "49.2063492063492"
      ]
     },
     "execution_count": 6,
=======
       "<keras.src.callbacks.History at 0x7f2d7c5c63e0>"
      ]
     },
     "execution_count": 25,
>>>>>>> 8a5a56a1ff5294aac29c152169eacf17d0912abf
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=30, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_palindrome(arr):\n",
    "    if np.array_equal(arr, np.flip(arr)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for inp in x:\n",
    "    y_pred.append(is_palindrome(inp))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y)):\n",
    "    if not y_pred[i]==y[i]:\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs772",
   "language": "python",
   "name": "cs772"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
