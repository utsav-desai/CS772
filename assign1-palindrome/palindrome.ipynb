{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from faker import Faker\n",
    "import random\n",
    "np.random.seed()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "palindromes = []\n",
    "for i in range(1024):\n",
    "    binary_string = format(i, '010b')\n",
    "    x.append(binary_string)\n",
    "    if binary_string == binary_string[::-1]:\n",
    "        palindromes.append(binary_string)\n",
    "x = np.array(x)\n",
    "palindromes = np.array(palindromes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0000000000', '0000110000', '0001001000', '0001111000',\n",
       "       '0010000100', '0010110100', '0011001100', '0011111100',\n",
       "       '0100000010', '0100110010', '0101001010', '0101111010',\n",
       "       '0110000110', '0110110110', '0111001110', '0111111110',\n",
       "       '1000000001', '1000110001', '1001001001', '1001111001',\n",
       "       '1010000101', '1010110101', '1011001101', '1011111101',\n",
       "       '1100000011', '1100110011', '1101001011', '1101111011',\n",
       "       '1110000111', '1110110111', '1111001111', '1111111111'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0110110110', '1101001011', '0010110100', '0001001000',\n",
       "       '0110000110', '1011111101', '0100000010', '1010110101',\n",
       "       '0000000000', '0011111100', '1001001001', '0011001100',\n",
       "       '0111001110', '1011001101', '1001111001', '1000110001',\n",
       "       '1000000001', '0101001010', '1110110111', '0001111000',\n",
       "       '0111111110', '1110000111', '0010000100', '1101111011',\n",
       "       '0101111010', '1100110011', '1111001111', '0100110010',\n",
       "       '0000110000', '1100000011', '1111111111', '1010000101'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(palindromes)\n",
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = np.concatenate((x, palindromes))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for binary_string in x:\n",
    "    y.append(binary_string == binary_string[::-1])\n",
    "y = np.array(y)\n",
    "permutation_index = np.random.permutation(len(x))\n",
    "x = x[permutation_index]\n",
    "y = y[permutation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   6, -12])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.array([1, 2, -3])\n",
    "# b = np.array([2, 3, 4])\n",
    "# a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 20\n",
    "output_size = 1\n",
    "\n",
    "weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[991.61380209]]\n",
      "Epoch 100 : loss [[989.2316454]]\n",
      "Epoch 200 : loss [[319.53270712]]\n",
      "Epoch 300 : loss [[319.57421463]]\n",
      "Epoch 400 : loss [[319.61364199]]\n",
      "Epoch 500 : loss [[319.6512102]]\n",
      "Epoch 600 : loss [[319.6870946]]\n",
      "Epoch 700 : loss [[319.72143354]]\n",
      "Epoch 800 : loss [[319.75433739]]\n",
      "Epoch 900 : loss [[319.78589815]]\n",
      "Epoch 1000 : loss [[319.81620019]]\n",
      "Epoch 1100 : loss [[319.84533201]]\n",
      "Epoch 1200 : loss [[319.87339917]]\n",
      "Epoch 1300 : loss [[319.90053773]]\n",
      "Epoch 1400 : loss [[319.92692755]]\n",
      "Epoch 1500 : loss [[319.9528046]]\n",
      "Epoch 1600 : loss [[319.97847091]]\n",
      "Epoch 1700 : loss [[320.00430116]]\n",
      "Epoch 1800 : loss [[320.03074492]]\n",
      "Epoch 1900 : loss [[320.05832377]]\n",
      "Epoch 2000 : loss [[320.08762303]]\n",
      "Epoch 2100 : loss [[320.11927799]]\n",
      "Epoch 2200 : loss [[320.15395461]]\n",
      "Epoch 2300 : loss [[320.19232432]]\n",
      "Epoch 2400 : loss [[320.23503171]]\n",
      "Epoch 2500 : loss [[320.28265285]]\n",
      "Epoch 2600 : loss [[320.33564028]]\n",
      "Epoch 2700 : loss [[320.39424877]]\n",
      "Epoch 2800 : loss [[320.45843371]]\n",
      "Epoch 2900 : loss [[320.52771224]]\n",
      "Epoch 3000 : loss [[320.60097475]]\n",
      "Epoch 3100 : loss [[320.67623404]]\n",
      "Epoch 3200 : loss [[320.75029944]]\n",
      "Epoch 3300 : loss [[320.81836663]]\n",
      "Epoch 3400 : loss [[320.87352024]]\n",
      "Epoch 3500 : loss [[320.90615562]]\n",
      "Epoch 3600 : loss [[320.90333478]]\n",
      "Epoch 3700 : loss [[320.84808857]]\n",
      "Epoch 3800 : loss [[320.71864462]]\n",
      "Epoch 3900 : loss [[320.48748889]]\n",
      "Epoch 4000 : loss [[320.12009745]]\n",
      "Epoch 4100 : loss [[319.57321731]]\n",
      "Epoch 4200 : loss [[318.79283617]]\n",
      "Epoch 4300 : loss [[317.71237063]]\n",
      "Epoch 4400 : loss [[316.25183063]]\n",
      "Epoch 4500 : loss [[314.31860957]]\n",
      "Epoch 4600 : loss [[311.81032712]]\n",
      "Epoch 4700 : loss [[308.62023224]]\n",
      "Epoch 4800 : loss [[304.64616066]]\n",
      "Epoch 4900 : loss [[299.80425637]]\n",
      "Epoch 5000 : loss [[294.04706493]]\n",
      "Epoch 5100 : loss [[287.38122968]]\n",
      "Epoch 5200 : loss [[279.87587872]]\n",
      "Epoch 5300 : loss [[271.65535658]]\n",
      "Epoch 5400 : loss [[262.87946312]]\n",
      "Epoch 5500 : loss [[253.72091432]]\n",
      "Epoch 5600 : loss [[244.34743878]]\n",
      "Epoch 5700 : loss [[234.9103267]]\n",
      "Epoch 5800 : loss [[225.53835093]]\n",
      "Epoch 5900 : loss [[216.33570851]]\n",
      "Epoch 6000 : loss [[207.38289088]]\n",
      "Epoch 6100 : loss [[198.73939359]]\n",
      "Epoch 6200 : loss [[190.44717023]]\n",
      "Epoch 6300 : loss [[182.53397393]]\n",
      "Epoch 6400 : loss [[175.01614429]]\n",
      "Epoch 6500 : loss [[167.90077537]]\n",
      "Epoch 6600 : loss [[161.18740928]]\n",
      "Epoch 6700 : loss [[154.86944061]]\n",
      "Epoch 6800 : loss [[148.93536325]]\n",
      "Epoch 6900 : loss [[143.36991774]]\n",
      "Epoch 7000 : loss [[138.15514523]]\n",
      "Epoch 7100 : loss [[133.27133094]]\n",
      "Epoch 7200 : loss [[128.69781856]]\n",
      "Epoch 7300 : loss [[124.41368476]]\n",
      "Epoch 7400 : loss [[120.39827326]]\n",
      "Epoch 7500 : loss [[116.6315961]]\n",
      "Epoch 7600 : loss [[113.09461596]]\n",
      "Epoch 7700 : loss [[109.76942693]]\n",
      "Epoch 7800 : loss [[106.6393526]]\n",
      "Epoch 7900 : loss [[103.68898013]]\n",
      "Epoch 8000 : loss [[100.90414718]]\n",
      "Epoch 8100 : loss [[98.27189634]]\n",
      "Epoch 8200 : loss [[95.78040878]]\n",
      "Epoch 8300 : loss [[93.41892608]]\n",
      "Epoch 8400 : loss [[91.1776669]]\n",
      "Epoch 8500 : loss [[89.04774305]]\n",
      "Epoch 8600 : loss [[87.02107814]]\n",
      "Epoch 8700 : loss [[85.09033038]]\n",
      "Epoch 8800 : loss [[83.24882098]]\n",
      "Epoch 8900 : loss [[81.49046816]]\n",
      "Epoch 9000 : loss [[79.80972729]]\n",
      "Epoch 9100 : loss [[78.20153656]]\n",
      "Epoch 9200 : loss [[76.66126823]]\n",
      "Epoch 9300 : loss [[75.18468479]]\n",
      "Epoch 9400 : loss [[73.7678998]]\n",
      "Epoch 9500 : loss [[72.40734284]]\n",
      "Epoch 9600 : loss [[71.09972829]]\n",
      "Epoch 9700 : loss [[69.84202742]]\n",
      "Epoch 9800 : loss [[68.63144352]]\n",
      "Epoch 9900 : loss [[67.46538972]]\n"
     ]
    }
   ],
   "source": [
    "# LEARNING_RATE = 1e-7\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[0.70983834]]\n",
      "Epoch 100 : loss [[0.7091767]]\n",
      "Epoch 200 : loss [[0.70852412]]\n",
      "Epoch 300 : loss [[0.70787714]]\n",
      "Epoch 400 : loss [[0.70723423]]\n",
      "Epoch 500 : loss [[0.70659466]]\n",
      "Epoch 600 : loss [[0.70595803]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m hlayer_output \u001b[38;5;241m=\u001b[39m sigmoid(hlayer_logits)\n\u001b[1;32m      9\u001b[0m final_logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(hlayer_output, weights_ho)\n\u001b[0;32m---> 10\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tot_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(final_output \u001b[38;5;241m-\u001b[39m y[i])\n\u001b[1;32m     14\u001b[0m output_delta \u001b[38;5;241m=\u001b[39m (y[i] \u001b[38;5;241m-\u001b[39m final_output) \u001b[38;5;241m*\u001b[39m final_output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m final_output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99802693]]\n",
      "[[9.87927878e-05]]\n"
     ]
    }
   ],
   "source": [
    "x_test1 = '1100110011'\n",
    "x_test2 = '1100110000'\n",
    "def test(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "    return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)), weights_ho))\n",
    "\n",
    "print(test(x_test1))\n",
    "print(test(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('weights_ih.npy', weights_ih)\n",
    "# np.save('weights_ho.npy', weights_ho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/screa/Desktop/Sem8/CS772/assign1-palindrome/utils/dataset.py:29: UserWarning: you are shuffling a 'flatiter' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(x.flat)\n"
     ]
    }
   ],
   "source": [
    "from utils import activation, dataset, losses\n",
    "from model import *\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "Dataset = dataset.Palindrome_Dataset(n_bits=10)\n",
    "x,y = Dataset.get_data(shuffle=True, biasing_factor=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Palindrome_Model(input_size=10, output_size=1,hidden_layer_sizes=[4],activation='sigmoid')\n",
    "model.set_optimizer(lr=0.0001,loss=\"bce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
       "  'weights': array([[ 0.93264673,  0.97459294, -0.12848894,  0.58921758],\n",
       "         [-0.61967231, -0.26271703, -0.26330762, -0.93215773],\n",
       "         [ 0.19383003, -1.06437594,  0.40447317, -0.24151142],\n",
       "         [-0.44076791, -0.58080072, -0.21027712, -0.61963486],\n",
       "         [-0.21196891, -0.25251799, -0.36971576, -0.07134193],\n",
       "         [-0.01738654,  0.49040936, -0.42500098, -0.1270861 ],\n",
       "         [-0.82970687,  0.77321702,  0.29156391, -0.54454293],\n",
       "         [ 0.42967041, -0.02238592, -0.17803028,  0.43492721],\n",
       "         [ 0.39676217, -0.09361975,  0.69012828,  0.31874703],\n",
       "         [ 0.4822464 ,  0.3571908 ,  0.47563312,  0.07272139]]),\n",
       "  'biases': array([-0.73642481, -0.58666945, -0.33631103,  0.80275304]),\n",
       "  'activation': 'linear'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[ 0.59679054],\n",
       "         [-0.80576963],\n",
       "         [ 0.08172214],\n",
       "         [-0.04323667]]),\n",
       "  'biases': array([2.17619008]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 1 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 0 0 0]\n",
      " [0 0 1 0 0 1 0 0 1 0]\n",
      " [1 0 0 1 0 0 1 0 0 1]\n",
      " [0 1 0 1 1 1 1 0 1 0]\n",
      " [0 1 0 0 1 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [1 1 1 0 1 1 0 1 1 1]\n",
      " [1 1 1 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [1 1 1 1 0 0 1 1 1 1]\n",
      " [0 0 1 0 0 1 0 1 1 1]\n",
      " [1 1 1 0 1 1 0 1 1 1]\n",
      " [1 1 1 1 1 0 0 1 1 0]\n",
      " [1 1 1 1 0 0 1 1 1 1]\n",
      " [0 1 0 0 1 1 0 0 1 0]\n",
      " [1 0 0 0 1 1 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 1 0]\n",
      " [1 1 1 0 0 1 0 0 1 0]\n",
      " [1 1 0 0 0 0 0 0 1 1]\n",
      " [0 0 1 0 1 1 0 0 0 1]\n",
      " [0 0 0 0 1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 1 1]\n",
      " [1 0 1 0 0 0 0 1 0 1]\n",
      " [0 1 1 1 1 1 1 1 1 0]\n",
      " [0 1 1 0 0 0 1 1 1 1]\n",
      " [0 0 1 0 0 1 1 0 0 0]\n",
      " [1 0 1 1 0 0 0 0 1 0]\n",
      " [1 0 1 0 1 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 0 1 1 0 1 0 0]] [1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "temp_x = x[0:32]\n",
    "temp_y = y[0:32]\n",
    "print(temp_x, temp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolving Bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 32/32 [00:00<00:00, 4249.95sample/s, accuracy=96.9, loss=-.126]\n",
      "Epoch 2/10: 100%|██████████| 32/32 [00:00<00:00, 4088.02sample/s, accuracy=96.9, loss=-.126]\n",
      "Epoch 3/10: 100%|██████████| 32/32 [00:00<00:00, 3513.19sample/s, accuracy=96.9, loss=-.126]\n",
      "Epoch 4/10: 100%|██████████| 32/32 [00:00<00:00, 2772.23sample/s, accuracy=96.9, loss=-.126]\n",
      "Epoch 5/10: 100%|██████████| 32/32 [00:00<00:00, 2264.59sample/s, accuracy=96.9, loss=-.126]\n",
      "Epoch 6/10: 100%|██████████| 32/32 [00:00<00:00, 2604.65sample/s, accuracy=96.9, loss=-.126]\n",
      "Epoch 7/10: 100%|██████████| 32/32 [00:00<00:00, 2153.96sample/s, accuracy=96.9, loss=-.126]\n",
      "Epoch 8/10: 100%|██████████| 32/32 [00:00<00:00, 2095.25sample/s, accuracy=96.9, loss=-.126]\n",
      "Epoch 9/10: 100%|██████████| 32/32 [00:00<00:00, 1580.52sample/s, accuracy=96.9, loss=-.126]\n",
      "Epoch 10/10: 100%|██████████| 32/32 [00:00<00:00, 2788.71sample/s, accuracy=96.9, loss=-.126]\n"
     ]
    }
   ],
   "source": [
    "model.set_optimizer(lr=0.0001,loss=\"bce\")\n",
    "accuracies, losses = model.train(temp_x,temp_y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_palindromes = np.array([np.reshape(np.array([int(char) for char in s]), (10,)) for s in Dataset.palindromes])\n",
    "y_palindromes = np.array([1]*32)\n",
    "x_non_palindrome = np.array([np.reshape(np.array([int(char) for char in s]), (10,)) for s in Dataset.non_palindromes])\n",
    "y_non_palindrome = np.array([0]*len(x_non_palindrome))\n",
    "# accuracies, losses = model.train(x_palindromes,y_palindromes,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 992/992 [00:00<00:00, 3885.10sample/s, accuracy=100, loss=-.0213]\n",
      "Epoch 2/20: 100%|██████████| 992/992 [00:00<00:00, 5434.57sample/s, accuracy=100, loss=-.0202]\n",
      "Epoch 3/20: 100%|██████████| 992/992 [00:00<00:00, 5405.05sample/s, accuracy=100, loss=-.0193]\n",
      "Epoch 4/20: 100%|██████████| 992/992 [00:00<00:00, 4351.92sample/s, accuracy=100, loss=-.0184]\n",
      "Epoch 5/20: 100%|██████████| 992/992 [00:00<00:00, 3770.34sample/s, accuracy=100, loss=-.0176]\n",
      "Epoch 6/20: 100%|██████████| 992/992 [00:00<00:00, 3445.08sample/s, accuracy=100, loss=-.0169]\n",
      "Epoch 7/20: 100%|██████████| 992/992 [00:00<00:00, 3836.29sample/s, accuracy=100, loss=-.0162]\n",
      "Epoch 8/20: 100%|██████████| 992/992 [00:00<00:00, 4768.72sample/s, accuracy=100, loss=-.0156]\n",
      "Epoch 9/20: 100%|██████████| 992/992 [00:00<00:00, 5384.34sample/s, accuracy=100, loss=-.015]\n",
      "Epoch 10/20: 100%|██████████| 992/992 [00:00<00:00, 5596.96sample/s, accuracy=100, loss=-.0144]\n",
      "Epoch 11/20: 100%|██████████| 992/992 [00:00<00:00, 5777.07sample/s, accuracy=100, loss=-.0139]\n",
      "Epoch 12/20: 100%|██████████| 992/992 [00:00<00:00, 3920.61sample/s, accuracy=100, loss=-.0135]\n",
      "Epoch 13/20: 100%|██████████| 992/992 [00:00<00:00, 5173.23sample/s, accuracy=100, loss=-.013]\n",
      "Epoch 14/20: 100%|██████████| 992/992 [00:00<00:00, 5344.99sample/s, accuracy=100, loss=-.0126]\n",
      "Epoch 15/20: 100%|██████████| 992/992 [00:00<00:00, 5552.89sample/s, accuracy=100, loss=-.0122]\n",
      "Epoch 16/20: 100%|██████████| 992/992 [00:00<00:00, 5661.14sample/s, accuracy=100, loss=-.0119]\n",
      "Epoch 17/20: 100%|██████████| 992/992 [00:00<00:00, 5703.88sample/s, accuracy=100, loss=-.0115]\n",
      "Epoch 18/20: 100%|██████████| 992/992 [00:00<00:00, 5370.73sample/s, accuracy=100, loss=-.0112]\n",
      "Epoch 19/20: 100%|██████████| 992/992 [00:00<00:00, 5392.81sample/s, accuracy=100, loss=-.0109]\n",
      "Epoch 20/20: 100%|██████████| 992/992 [00:00<00:00, 5545.68sample/s, accuracy=100, loss=-.0106]\n",
      "Epoch 1/100: 100%|██████████| 32/32 [00:00<00:00, 4258.04sample/s, accuracy=100, loss=45.1]\n",
      "Epoch 2/100: 100%|██████████| 32/32 [00:00<00:00, 4413.75sample/s, accuracy=100, loss=1.26]\n",
      "Epoch 3/100: 100%|██████████| 32/32 [00:00<00:00, 3976.59sample/s, accuracy=100, loss=0.578]\n",
      "Epoch 4/100: 100%|██████████| 32/32 [00:00<00:00, 4152.13sample/s, accuracy=100, loss=0.364]\n",
      "Epoch 5/100: 100%|██████████| 32/32 [00:00<00:00, 3106.03sample/s, accuracy=100, loss=0.262]\n",
      "Epoch 6/100: 100%|██████████| 32/32 [00:00<00:00, 3283.05sample/s, accuracy=100, loss=0.203]\n",
      "Epoch 7/100: 100%|██████████| 32/32 [00:00<00:00, 4717.17sample/s, accuracy=100, loss=0.165]\n",
      "Epoch 8/100: 100%|██████████| 32/32 [00:00<00:00, 3497.53sample/s, accuracy=100, loss=0.139]\n",
      "Epoch 9/100: 100%|██████████| 32/32 [00:00<00:00, 2677.29sample/s, accuracy=100, loss=0.119]\n",
      "Epoch 10/100: 100%|██████████| 32/32 [00:00<00:00, 2918.60sample/s, accuracy=100, loss=0.105]\n",
      "Epoch 11/100: 100%|██████████| 32/32 [00:00<00:00, 3664.85sample/s, accuracy=100, loss=0.093]\n",
      "Epoch 12/100: 100%|██████████| 32/32 [00:00<00:00, 3765.08sample/s, accuracy=100, loss=0.0836]\n",
      "Epoch 13/100: 100%|██████████| 32/32 [00:00<00:00, 4180.59sample/s, accuracy=100, loss=0.0759]\n",
      "Epoch 14/100: 100%|██████████| 32/32 [00:00<00:00, 3640.59sample/s, accuracy=100, loss=0.0694]\n",
      "Epoch 15/100: 100%|██████████| 32/32 [00:00<00:00, 3575.33sample/s, accuracy=100, loss=0.0639]\n",
      "Epoch 16/100: 100%|██████████| 32/32 [00:00<00:00, 2764.47sample/s, accuracy=100, loss=0.0592]\n",
      "Epoch 17/100: 100%|██████████| 32/32 [00:00<00:00, 2508.74sample/s, accuracy=100, loss=0.0551]\n",
      "Epoch 18/100: 100%|██████████| 32/32 [00:00<00:00, 2757.03sample/s, accuracy=100, loss=0.0516]\n",
      "Epoch 19/100: 100%|██████████| 32/32 [00:00<00:00, 2962.67sample/s, accuracy=100, loss=0.0484]\n",
      "Epoch 20/100: 100%|██████████| 32/32 [00:00<00:00, 3821.47sample/s, accuracy=100, loss=0.0456]\n",
      "Epoch 21/100: 100%|██████████| 32/32 [00:00<00:00, 2933.34sample/s, accuracy=100, loss=0.0431]\n",
      "Epoch 22/100: 100%|██████████| 32/32 [00:00<00:00, 3426.72sample/s, accuracy=100, loss=0.0409]\n",
      "Epoch 23/100: 100%|██████████| 32/32 [00:00<00:00, 2949.19sample/s, accuracy=100, loss=0.0388]\n",
      "Epoch 24/100: 100%|██████████| 32/32 [00:00<00:00, 3354.69sample/s, accuracy=100, loss=0.037]\n",
      "Epoch 25/100: 100%|██████████| 32/32 [00:00<00:00, 3076.27sample/s, accuracy=100, loss=0.0353]\n",
      "Epoch 26/100: 100%|██████████| 32/32 [00:00<00:00, 2612.26sample/s, accuracy=100, loss=0.0337]\n",
      "Epoch 27/100: 100%|██████████| 32/32 [00:00<00:00, 4157.92sample/s, accuracy=100, loss=0.0323]\n",
      "Epoch 28/100: 100%|██████████| 32/32 [00:00<00:00, 2652.00sample/s, accuracy=100, loss=0.031]\n",
      "Epoch 29/100: 100%|██████████| 32/32 [00:00<00:00, 2868.64sample/s, accuracy=100, loss=0.0298]\n",
      "Epoch 30/100: 100%|██████████| 32/32 [00:00<00:00, 2513.91sample/s, accuracy=100, loss=0.0287]\n",
      "Epoch 31/100: 100%|██████████| 32/32 [00:00<00:00, 2568.32sample/s, accuracy=100, loss=0.0276]\n",
      "Epoch 32/100: 100%|██████████| 32/32 [00:00<00:00, 2734.45sample/s, accuracy=100, loss=0.0267]\n",
      "Epoch 33/100: 100%|██████████| 32/32 [00:00<00:00, 2568.76sample/s, accuracy=100, loss=0.0258]\n",
      "Epoch 34/100: 100%|██████████| 32/32 [00:00<00:00, 2895.56sample/s, accuracy=100, loss=0.0249]\n",
      "Epoch 35/100: 100%|██████████| 32/32 [00:00<00:00, 2434.21sample/s, accuracy=100, loss=0.0241]\n",
      "Epoch 36/100: 100%|██████████| 32/32 [00:00<00:00, 2158.01sample/s, accuracy=100, loss=0.0234]\n",
      "Epoch 37/100: 100%|██████████| 32/32 [00:00<00:00, 1854.68sample/s, accuracy=100, loss=0.0227]\n",
      "Epoch 38/100: 100%|██████████| 32/32 [00:00<00:00, 2407.92sample/s, accuracy=100, loss=0.022]\n",
      "Epoch 39/100: 100%|██████████| 32/32 [00:00<00:00, 3140.62sample/s, accuracy=100, loss=0.0214]\n",
      "Epoch 40/100: 100%|██████████| 32/32 [00:00<00:00, 2521.80sample/s, accuracy=100, loss=0.0208]\n",
      "Epoch 41/100: 100%|██████████| 32/32 [00:00<00:00, 3081.43sample/s, accuracy=100, loss=0.0202]\n",
      "Epoch 42/100: 100%|██████████| 32/32 [00:00<00:00, 1669.60sample/s, accuracy=100, loss=0.0197]\n",
      "Epoch 43/100: 100%|██████████| 32/32 [00:00<00:00, 1917.15sample/s, accuracy=100, loss=0.0192]\n",
      "Epoch 44/100: 100%|██████████| 32/32 [00:00<00:00, 1974.92sample/s, accuracy=100, loss=0.0187]\n",
      "Epoch 45/100: 100%|██████████| 32/32 [00:00<00:00, 2605.26sample/s, accuracy=100, loss=0.0182]\n",
      "Epoch 46/100: 100%|██████████| 32/32 [00:00<00:00, 2297.46sample/s, accuracy=100, loss=0.0178]\n",
      "Epoch 47/100: 100%|██████████| 32/32 [00:00<00:00, 2419.65sample/s, accuracy=100, loss=0.0174]\n",
      "Epoch 48/100: 100%|██████████| 32/32 [00:00<00:00, 2159.82sample/s, accuracy=100, loss=0.017]\n",
      "Epoch 49/100: 100%|██████████| 32/32 [00:00<00:00, 2123.33sample/s, accuracy=100, loss=0.0166]\n",
      "Epoch 50/100: 100%|██████████| 32/32 [00:00<00:00, 2428.36sample/s, accuracy=100, loss=0.0162]\n",
      "Epoch 51/100: 100%|██████████| 32/32 [00:00<00:00, 2322.27sample/s, accuracy=100, loss=0.0159]\n",
      "Epoch 52/100: 100%|██████████| 32/32 [00:00<00:00, 2114.76sample/s, accuracy=100, loss=0.0155]\n",
      "Epoch 53/100: 100%|██████████| 32/32 [00:00<00:00, 2370.17sample/s, accuracy=100, loss=0.0152]\n",
      "Epoch 54/100: 100%|██████████| 32/32 [00:00<00:00, 2259.18sample/s, accuracy=100, loss=0.0149]\n",
      "Epoch 55/100: 100%|██████████| 32/32 [00:00<00:00, 1738.68sample/s, accuracy=100, loss=0.0146]\n",
      "Epoch 56/100: 100%|██████████| 32/32 [00:00<00:00, 1592.35sample/s, accuracy=100, loss=0.0143]\n",
      "Epoch 57/100: 100%|██████████| 32/32 [00:00<00:00, 1270.27sample/s, accuracy=100, loss=0.014]\n",
      "Epoch 58/100: 100%|██████████| 32/32 [00:00<00:00, 1639.04sample/s, accuracy=100, loss=0.0138]\n",
      "Epoch 59/100: 100%|██████████| 32/32 [00:00<00:00, 1781.56sample/s, accuracy=100, loss=0.0135]\n",
      "Epoch 60/100: 100%|██████████| 32/32 [00:00<00:00, 2119.61sample/s, accuracy=100, loss=0.0133]\n",
      "Epoch 61/100: 100%|██████████| 32/32 [00:00<00:00, 2047.59sample/s, accuracy=100, loss=0.013]\n",
      "Epoch 62/100: 100%|██████████| 32/32 [00:00<00:00, 2451.51sample/s, accuracy=100, loss=0.0128]\n",
      "Epoch 63/100: 100%|██████████| 32/32 [00:00<00:00, 1920.06sample/s, accuracy=100, loss=0.0126]\n",
      "Epoch 64/100: 100%|██████████| 32/32 [00:00<00:00, 1525.39sample/s, accuracy=100, loss=0.0124]\n",
      "Epoch 65/100: 100%|██████████| 32/32 [00:00<00:00, 1813.17sample/s, accuracy=100, loss=0.0122]\n",
      "Epoch 66/100: 100%|██████████| 32/32 [00:00<00:00, 2851.27sample/s, accuracy=100, loss=0.012]\n",
      "Epoch 67/100: 100%|██████████| 32/32 [00:00<00:00, 2922.29sample/s, accuracy=100, loss=0.0118]\n",
      "Epoch 68/100: 100%|██████████| 32/32 [00:00<00:00, 1990.45sample/s, accuracy=100, loss=0.0116]\n",
      "Epoch 69/100: 100%|██████████| 32/32 [00:00<00:00, 1865.90sample/s, accuracy=100, loss=0.0114]\n",
      "Epoch 70/100: 100%|██████████| 32/32 [00:00<00:00, 2194.97sample/s, accuracy=100, loss=0.0112]\n",
      "Epoch 71/100: 100%|██████████| 32/32 [00:00<00:00, 1895.14sample/s, accuracy=100, loss=0.011]\n",
      "Epoch 72/100: 100%|██████████| 32/32 [00:00<00:00, 2069.76sample/s, accuracy=100, loss=0.0109]\n",
      "Epoch 73/100: 100%|██████████| 32/32 [00:00<00:00, 1840.72sample/s, accuracy=100, loss=0.0107]\n",
      "Epoch 74/100: 100%|██████████| 32/32 [00:00<00:00, 2280.44sample/s, accuracy=100, loss=0.0105]\n",
      "Epoch 75/100: 100%|██████████| 32/32 [00:00<00:00, 1762.43sample/s, accuracy=100, loss=0.0104]\n",
      "Epoch 76/100: 100%|██████████| 32/32 [00:00<00:00, 1440.03sample/s, accuracy=100, loss=0.0102]\n",
      "Epoch 77/100: 100%|██████████| 32/32 [00:00<00:00, 1942.88sample/s, accuracy=100, loss=0.0101]\n",
      "Epoch 78/100: 100%|██████████| 32/32 [00:00<00:00, 1916.74sample/s, accuracy=100, loss=0.00995]\n",
      "Epoch 79/100: 100%|██████████| 32/32 [00:00<00:00, 1991.39sample/s, accuracy=100, loss=0.00982]\n",
      "Epoch 80/100: 100%|██████████| 32/32 [00:00<00:00, 2070.11sample/s, accuracy=100, loss=0.00968]\n",
      "Epoch 81/100: 100%|██████████| 32/32 [00:00<00:00, 1689.53sample/s, accuracy=100, loss=0.00955]\n",
      "Epoch 82/100: 100%|██████████| 32/32 [00:00<00:00, 1539.34sample/s, accuracy=100, loss=0.00943]\n",
      "Epoch 83/100: 100%|██████████| 32/32 [00:00<00:00, 1764.70sample/s, accuracy=100, loss=0.0093]\n",
      "Epoch 84/100: 100%|██████████| 32/32 [00:00<00:00, 2045.66sample/s, accuracy=100, loss=0.00918]\n",
      "Epoch 85/100: 100%|██████████| 32/32 [00:00<00:00, 2438.15sample/s, accuracy=100, loss=0.00906]\n",
      "Epoch 86/100: 100%|██████████| 32/32 [00:00<00:00, 1884.37sample/s, accuracy=100, loss=0.00895]\n",
      "Epoch 87/100: 100%|██████████| 32/32 [00:00<00:00, 2095.48sample/s, accuracy=100, loss=0.00884]\n",
      "Epoch 88/100: 100%|██████████| 32/32 [00:00<00:00, 1729.65sample/s, accuracy=100, loss=0.00873]\n",
      "Epoch 89/100: 100%|██████████| 32/32 [00:00<00:00, 1995.86sample/s, accuracy=100, loss=0.00862]\n",
      "Epoch 90/100: 100%|██████████| 32/32 [00:00<00:00, 2156.42sample/s, accuracy=100, loss=0.00852]\n",
      "Epoch 91/100: 100%|██████████| 32/32 [00:00<00:00, 1647.59sample/s, accuracy=100, loss=0.00841]\n",
      "Epoch 92/100: 100%|██████████| 32/32 [00:00<00:00, 2048.69sample/s, accuracy=100, loss=0.00831]\n",
      "Epoch 93/100: 100%|██████████| 32/32 [00:00<00:00, 1982.01sample/s, accuracy=100, loss=0.00822]\n",
      "Epoch 94/100: 100%|██████████| 32/32 [00:00<00:00, 2355.77sample/s, accuracy=100, loss=0.00812]\n",
      "Epoch 95/100: 100%|██████████| 32/32 [00:00<00:00, 2071.23sample/s, accuracy=100, loss=0.00803]\n",
      "Epoch 96/100: 100%|██████████| 32/32 [00:00<00:00, 1822.37sample/s, accuracy=100, loss=0.00794]\n",
      "Epoch 97/100: 100%|██████████| 32/32 [00:00<00:00, 1611.99sample/s, accuracy=100, loss=0.00785]\n",
      "Epoch 98/100: 100%|██████████| 32/32 [00:00<00:00, 2412.17sample/s, accuracy=100, loss=0.00776]\n",
      "Epoch 99/100: 100%|██████████| 32/32 [00:00<00:00, 2729.50sample/s, accuracy=100, loss=0.00768]\n",
      "Epoch 100/100: 100%|██████████| 32/32 [00:00<00:00, 2462.58sample/s, accuracy=100, loss=0.00759]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0],\n",
       " [45.05973105989867,\n",
       "  1.2559952902761269,\n",
       "  0.5784481850360385,\n",
       "  0.3641633268367248,\n",
       "  0.2621526260898702,\n",
       "  0.20330128499373304,\n",
       "  0.16529180520398784,\n",
       "  0.1388445076099617,\n",
       "  0.11944275676435223,\n",
       "  0.10463615222751718,\n",
       "  0.09298499504932783,\n",
       "  0.08359007784535709,\n",
       "  0.07586189169099382,\n",
       "  0.06939844284707723,\n",
       "  0.0639165119637865,\n",
       "  0.0592109961068026,\n",
       "  0.05512983133841378,\n",
       "  0.05155796372596646,\n",
       "  0.04840678433993285,\n",
       "  0.04560697691661284,\n",
       "  0.043103560694189545,\n",
       "  0.04085238240555512,\n",
       "  0.03881758724576639,\n",
       "  0.0369697649544236,\n",
       "  0.0352845701790302,\n",
       "  0.03374168166442467,\n",
       "  0.032324007217348794,\n",
       "  0.031017069448053075,\n",
       "  0.02980852618758052,\n",
       "  0.028687792420625295,\n",
       "  0.027645739572307034,\n",
       "  0.02667445433239494,\n",
       "  0.02576704373308103,\n",
       "  0.024917476473505996,\n",
       "  0.02412045288023994,\n",
       "  0.023371297663056706,\n",
       "  0.022665870946093417,\n",
       "  0.02200049404883384,\n",
       "  0.021371887246591576,\n",
       "  0.020777117318285212,\n",
       "  0.020213553135432157,\n",
       "  0.019678827892821046,\n",
       "  0.019170806852567543,\n",
       "  0.018687559686739495,\n",
       "  0.018227336672971176,\n",
       "  0.01778854813225114,\n",
       "  0.017369746606168985,\n",
       "  0.016969611357868807,\n",
       "  0.016586934851468643,\n",
       "  0.016220610921998883,\n",
       "  0.01586962439476243,\n",
       "  0.015533041951485076,\n",
       "  0.015210004072300904,\n",
       "  0.014899717908853837,\n",
       "  0.014601450965622913,\n",
       "  0.01431452548468479,\n",
       "  0.014038313444424282,\n",
       "  0.013772232095394653,\n",
       "  0.013515739967339433,\n",
       "  0.013268333290474603,\n",
       "  0.01302954278182947,\n",
       "  0.012798930753997894,\n",
       "  0.012576088509264638,\n",
       "  0.01236063398683051,\n",
       "  0.012152209634968814,\n",
       "  0.011950480483448636,\n",
       "  0.01175513239463979,\n",
       "  0.011565870474284982,\n",
       "  0.011382417625213024,\n",
       "  0.011204513229266442,\n",
       "  0.011031911944375129,\n",
       "  0.010864382605237314,\n",
       "  0.010701707217371044,\n",
       "  0.010543680035414388,\n",
       "  0.010390106717578809,\n",
       "  0.010240803549033008,\n",
       "  0.010095596727746056,\n",
       "  0.009954321707029909,\n",
       "  0.009816822589595566,\n",
       "  0.009682951568502985,\n",
       "  0.009552568410798932,\n",
       "  0.009425539980131266,\n",
       "  0.009301739794929867,\n",
       "  0.009181047619110842,\n",
       "  0.00906334908256025,\n",
       "  0.008948535328893106,\n",
       "  0.008836502688234719,\n",
       "  0.00872715237297978,\n",
       "  0.008620390194666875,\n",
       "  0.008516126300294967,\n",
       "  0.008414274926522816,\n",
       "  0.008314754170370203,\n",
       "  0.008217485775146645,\n",
       "  0.008122394930429848,\n",
       "  0.008029410085038166,\n",
       "  0.007938462772031835,\n",
       "  0.007849487444840987,\n",
       "  0.007762421323702693,\n",
       "  0.007677204251676311,\n",
       "  0.007593778559533823])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(x_non_palindrome, y_non_palindrome, epochs=20)\n",
    "model.train(x_palindromes, y_palindromes, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_palindromes)\n",
    "# print(predictions)\n",
    "accuracy_metric(predictions, y_palindromes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_non_palindrome)\n",
    "# print(predictions)\n",
    "accuracy_metric(predictions, y_non_palindrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([1,1,1,1,1,1,1,1,1,1])\n",
    "y_temp = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89571334])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backward(temp, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(model,X:np.ndarray, y:np.ndarray, k_folds:int = 4, epochs_per_fold:int = 25):\n",
    "        fold_size = len(X) // k_folds\n",
    "        accuracies_fold = []\n",
    "        accuracies=[]\n",
    "        losses = []\n",
    "        for i in range(k_folds):\n",
    "            start, end = i * fold_size, (i + 1) * fold_size\n",
    "            X_test_fold, y_test_fold = X[start:end], y[start:end]\n",
    "            X_train_fold = np.concatenate([X[:start], X[end:]])\n",
    "            y_train_fold = np.concatenate([y[:start], y[end:]])\n",
    "            print(f\"Training Fold {i+1}\\n\")\n",
    "            accuracy, loss = model.train(X_train_fold, y_train_fold, epochs_per_fold)\n",
    "            accuracies.extend(accuracy)\n",
    "            losses.extend(loss)\n",
    "            print(\"\\n\"+10*\"----\"+\"\\n\")\n",
    "            predictions = model.predict(X_test_fold)\n",
    "            accuracies_fold.append(accuracy_metric(predictions, y_test_fold))\n",
    "        return accuracies_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 6145.67sample/s, accuracy=58.8, loss=72.6]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 6259.24sample/s, accuracy=58.5, loss=81]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5800.76sample/s, accuracy=59.1, loss=76.8]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5048.63sample/s, accuracy=59.7, loss=75.2]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 5120.30sample/s, accuracy=59.1, loss=74.5]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 4877.05sample/s, accuracy=57.5, loss=74]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 5737.11sample/s, accuracy=56.8, loss=73.6]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5839.34sample/s, accuracy=58, loss=73.4]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 5796.17sample/s, accuracy=59.5, loss=73.3]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 6017.27sample/s, accuracy=59.5, loss=73.3]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5868.15sample/s, accuracy=59.5, loss=73.2]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 6148.26sample/s, accuracy=59.5, loss=73.2]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 6096.12sample/s, accuracy=59.5, loss=73.1]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 5941.14sample/s, accuracy=59.5, loss=73]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 5923.73sample/s, accuracy=59.5, loss=72.8]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 5879.43sample/s, accuracy=59.5, loss=72.8]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 5757.96sample/s, accuracy=59.5, loss=72.7]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5968.77sample/s, accuracy=59.5, loss=72.7]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 5928.94sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 6154.41sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 6033.58sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 5949.04sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 5864.41sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 6186.83sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 5954.09sample/s, accuracy=59.5, loss=72.6]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5891.05sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5759.69sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5872.23sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5781.25sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5521.10sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5327.87sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 3875.14sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 4476.58sample/s, accuracy=59.5, loss=72.5]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5267.82sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 5573.77sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5719.37sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5797.93sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 5362.26sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 5732.04sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 6062.71sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 5972.58sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5875.23sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5730.14sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 5664.59sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 5858.48sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 5826.30sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 6173.43sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 5908.28sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 5898.21sample/s, accuracy=59.5, loss=72.4]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 5973.76sample/s, accuracy=59.5, loss=72.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 5349.59sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 5839.98sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5989.46sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5877.77sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 5808.05sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 6014.37sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 6091.99sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5941.68sample/s, accuracy=59.5, loss=72.3]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 6146.15sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 6145.60sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5932.58sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 4966.03sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 4696.89sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 5160.41sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 5597.84sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 5851.78sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 5878.99sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5930.92sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 6157.15sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 6198.24sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 6109.15sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 4991.46sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 5392.01sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 5392.91sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 5764.90sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5892.28sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5805.04sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5729.07sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5965.06sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5543.70sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5950.71sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 6076.13sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 6049.61sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5788.06sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 5335.04sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5159.74sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5270.26sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 3923.86sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 4431.38sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 4445.32sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 4166.71sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 4935.65sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5358.40sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 5267.25sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 5044.56sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 3956.20sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 4582.01sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 5204.32sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 5656.63sample/s, accuracy=59.5, loss=72.2]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 5874.39sample/s, accuracy=59.5, loss=72.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 4072.14sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 4979.82sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5673.51sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5605.24sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 5870.71sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 5979.24sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 5712.00sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5884.66sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 5670.23sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 5869.53sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5761.17sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 5901.85sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 5867.53sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 5822.28sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 5917.93sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 5800.05sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 5173.44sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5525.92sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 5784.08sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 5854.24sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 5805.54sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 4357.70sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 4964.48sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 5537.01sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 5746.07sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5719.92sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5843.27sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5554.79sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5818.71sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5968.76sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5872.24sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 5795.32sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 5800.76sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5787.63sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 6065.56sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5964.29sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5977.60sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 6169.51sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 6071.15sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 6181.91sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 6047.00sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5945.95sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5938.27sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 6037.42sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 6084.57sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 5965.02sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 5991.41sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 6076.42sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 6194.80sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 6090.02sample/s, accuracy=60.8, loss=82.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 3825.49sample/s, accuracy=58.7, loss=70.6]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 4763.10sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5553.69sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5849.57sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 5513.05sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 5441.36sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 5139.57sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5179.19sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 5631.86sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 5851.86sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5937.42sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 6153.62sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 6138.11sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 5907.09sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 6033.16sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 6056.54sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 6036.86sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5927.75sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 5993.49sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 6152.60sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 6192.27sample/s, accuracy=58.7, loss=67.2]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 6042.96sample/s, accuracy=58.7, loss=67.2]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 6059.40sample/s, accuracy=58.7, loss=67.2]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 6112.43sample/s, accuracy=58.7, loss=67.1]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 6134.91sample/s, accuracy=58.7, loss=67.2]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5979.45sample/s, accuracy=61.9, loss=67.3]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5716.27sample/s, accuracy=58.3, loss=67.3]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5812.85sample/s, accuracy=58.8, loss=67.2]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5987.34sample/s, accuracy=58.7, loss=67.3]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5976.28sample/s, accuracy=61.5, loss=67.5]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 6105.12sample/s, accuracy=59.1, loss=67.6]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 6118.25sample/s, accuracy=54.6, loss=67.6]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 6040.62sample/s, accuracy=56.2, loss=67.6]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 6035.39sample/s, accuracy=56.1, loss=67.6]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 6035.23sample/s, accuracy=57.7, loss=67.6]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 6191.15sample/s, accuracy=57.1, loss=67.7]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 4493.77sample/s, accuracy=57.4, loss=67.8]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 5294.01sample/s, accuracy=56, loss=67.8]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 5745.77sample/s, accuracy=55, loss=67.8]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 5850.45sample/s, accuracy=54.7, loss=67.8]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 5346.09sample/s, accuracy=56.1, loss=67.8]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5766.20sample/s, accuracy=55, loss=67.8]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5923.83sample/s, accuracy=55.4, loss=67.8]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 5933.51sample/s, accuracy=55.4, loss=67.8]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 6108.93sample/s, accuracy=55.5, loss=67.9]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 5899.31sample/s, accuracy=55.5, loss=67.9]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 6006.28sample/s, accuracy=55.4, loss=67.9]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 5846.20sample/s, accuracy=55.4, loss=67.9]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 5936.29sample/s, accuracy=55.4, loss=67.9]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 5977.70sample/s, accuracy=55.6, loss=67.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accs = k_fold_cross_validation(model, x, y, epochs_per_fold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.01442307692308"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60.09615384615385, 60.09615384615385, 56.00961538461539, 59.855769230769226]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.61538461538461"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x)\n",
    "accuracy_metric(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
       "  'weights': array([[ 0.92075584,  0.98020454, -0.17354498,  0.54963896, -0.61341082],\n",
       "         [-0.3069449 , -0.31859287, -0.7935808 ,  0.24452297, -1.06643863],\n",
       "         [ 0.32264924, -0.32461446, -0.21445626, -0.47678489, -0.25638755],\n",
       "         [-0.62537194, -0.19053209, -0.21555031, -0.40445053, -0.1660093 ],\n",
       "         [-0.07174505,  0.42259881, -0.24471143, -0.01031693, -0.81025356],\n",
       "         [ 0.69404405,  0.21085697, -0.28454665,  0.52845819, -0.09958278],\n",
       "         [-0.14040927,  0.51493797,  0.30452068, -0.20036355,  0.52997397],\n",
       "         [ 0.35928047,  0.55598655,  0.20385861,  0.29601196, -0.03650077],\n",
       "         [-0.37006127, -0.24986717, -0.1882553 ,  0.28326173,  0.48526483],\n",
       "         [-0.69906679,  0.24546093, -0.45782992,  0.78897229, -0.65061248]]),\n",
       "  'biases': array([ 1.03922811, -0.59154367, -0.61716551, -0.83110799,  0.51746456]),\n",
       "  'activation': 'linear'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[ 0.03572792],\n",
       "         [ 0.08053775],\n",
       "         [-0.13718967],\n",
       "         [-0.02308033],\n",
       "         [ 0.03733735]]),\n",
       "  'biases': array([-0.57042209]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y)):\n",
    "    if predictions[i]==1:\n",
    "        count+=1\n",
    "        # print(x[i], y[i], predictions[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sem8",
   "language": "python",
   "name": "env_sem8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
