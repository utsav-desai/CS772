{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from faker import Faker\n",
    "import random\n",
    "np.random.seed()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "palindromes = []\n",
    "for i in range(1024):\n",
    "    binary_string = format(i, '010b')\n",
    "    x.append(binary_string)\n",
    "    if binary_string == binary_string[::-1]:\n",
    "        palindromes.append(binary_string)\n",
    "x = np.array(x)\n",
    "palindromes = np.array(palindromes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0000000000', '0000110000', '0001001000', '0001111000',\n",
       "       '0010000100', '0010110100', '0011001100', '0011111100',\n",
       "       '0100000010', '0100110010', '0101001010', '0101111010',\n",
       "       '0110000110', '0110110110', '0111001110', '0111111110',\n",
       "       '1000000001', '1000110001', '1001001001', '1001111001',\n",
       "       '1010000101', '1010110101', '1011001101', '1011111101',\n",
       "       '1100000011', '1100110011', '1101001011', '1101111011',\n",
       "       '1110000111', '1110110111', '1111001111', '1111111111'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0101001010', '1111001111', '1110000111', '1100000011',\n",
       "       '0000110000', '0000000000', '0111001110', '1001111001',\n",
       "       '0001001000', '1001001001', '0110110110', '0101111010',\n",
       "       '1000110001', '1011111101', '0111111110', '1010110101',\n",
       "       '0011111100', '0011001100', '1100110011', '0100110010',\n",
       "       '1101111011', '1011001101', '0001111000', '1010000101',\n",
       "       '0100000010', '0010110100', '0010000100', '0110000110',\n",
       "       '1101001011', '1000000001', '1111111111', '1110110111'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(palindromes)\n",
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "# for i in range(5):\n",
    "#     x = np.concatenate((x, palindromes))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for binary_string in x:\n",
    "    y.append(binary_string == binary_string[::-1])\n",
    "y = np.array(y)\n",
    "permutation_index = np.random.permutation(len(x))\n",
    "x = x[permutation_index]\n",
    "y = y[permutation_index]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1, 2, -3])\n",
    "# b = np.array([2, 3, 4])\n",
    "# a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Batches(Not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 2\n",
    "output_size = 1\n",
    "\n",
    "weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)\n",
    "bias_ih = np.random.rand(1, hidden_layer_size)\n",
    "bias_ho = np.random.rand(1, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77132064, 0.02075195],\n",
       "       [0.63364823, 0.74880388],\n",
       "       [0.49850701, 0.22479665],\n",
       "       [0.19806286, 0.76053071],\n",
       "       [0.16911084, 0.08833981],\n",
       "       [0.68535982, 0.95339335],\n",
       "       [0.00394827, 0.51219226],\n",
       "       [0.81262096, 0.61252607],\n",
       "       [0.72175532, 0.29187607],\n",
       "       [0.91777412, 0.71457578]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_ih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [85.94902944]\n",
      "Epoch 1 : loss [53.26866914]\n",
      "Epoch 2 : loss [49.66599335]\n",
      "Epoch 3 : loss [48.18129952]\n",
      "Epoch 4 : loss [47.44014732]\n",
      "Epoch 5 : loss [47.038796]\n",
      "Epoch 6 : loss [46.8124563]\n",
      "Epoch 7 : loss [46.68207067]\n",
      "Epoch 8 : loss [46.60614386]\n",
      "Epoch 9 : loss [46.56173275]\n",
      "Epoch 10 : loss [46.53575933]\n",
      "Epoch 11 : loss [46.52063496]\n",
      "Epoch 12 : loss [46.51191099]\n",
      "Epoch 13 : loss [46.5069647]\n",
      "Epoch 14 : loss [46.50424555]\n",
      "Epoch 15 : loss [46.50283599]\n",
      "Epoch 16 : loss [46.50219324]\n",
      "Epoch 17 : loss [46.50199669]\n",
      "Epoch 18 : loss [46.50205742]\n",
      "Epoch 19 : loss [46.50226447]\n",
      "Epoch 20 : loss [46.50255304]\n",
      "Epoch 21 : loss [46.50288552]\n",
      "Epoch 22 : loss [46.50324027]\n",
      "Epoch 23 : loss [46.50360505]\n",
      "Epoch 24 : loss [46.50397304]\n",
      "Epoch 25 : loss [46.50434058]\n",
      "Epoch 26 : loss [46.50470579]\n",
      "Epoch 27 : loss [46.50506779]\n",
      "Epoch 28 : loss [46.50542627]\n",
      "Epoch 29 : loss [46.50578119]\n",
      "Epoch 30 : loss [46.50613267]\n",
      "Epoch 31 : loss [46.50648086]\n",
      "Epoch 32 : loss [46.50682597]\n",
      "Epoch 33 : loss [46.50716817]\n",
      "Epoch 34 : loss [46.50750764]\n",
      "Epoch 35 : loss [46.50784452]\n",
      "Epoch 36 : loss [46.50817895]\n",
      "Epoch 37 : loss [46.50851104]\n",
      "Epoch 38 : loss [46.50884088]\n",
      "Epoch 39 : loss [46.50916856]\n",
      "Epoch 40 : loss [46.50949416]\n",
      "Epoch 41 : loss [46.50981773]\n",
      "Epoch 42 : loss [46.51013933]\n",
      "Epoch 43 : loss [46.51045901]\n",
      "Epoch 44 : loss [46.51077681]\n",
      "Epoch 45 : loss [46.51109275]\n",
      "Epoch 46 : loss [46.51140689]\n",
      "Epoch 47 : loss [46.51171924]\n",
      "Epoch 48 : loss [46.51202982]\n",
      "Epoch 49 : loss [46.51233867]\n",
      "Epoch 50 : loss [46.5126458]\n",
      "Epoch 51 : loss [46.51295123]\n",
      "Epoch 52 : loss [46.51325498]\n",
      "Epoch 53 : loss [46.51355707]\n",
      "Epoch 54 : loss [46.5138575]\n",
      "Epoch 55 : loss [46.5141563]\n",
      "Epoch 56 : loss [46.51445347]\n",
      "Epoch 57 : loss [46.51474903]\n",
      "Epoch 58 : loss [46.51504299]\n",
      "Epoch 59 : loss [46.51533537]\n",
      "Epoch 60 : loss [46.51562616]\n",
      "Epoch 61 : loss [46.51591539]\n",
      "Epoch 62 : loss [46.51620306]\n",
      "Epoch 63 : loss [46.51648918]\n",
      "Epoch 64 : loss [46.51677377]\n",
      "Epoch 65 : loss [46.51705682]\n",
      "Epoch 66 : loss [46.51733836]\n",
      "Epoch 67 : loss [46.51761838]\n",
      "Epoch 68 : loss [46.5178969]\n",
      "Epoch 69 : loss [46.51817393]\n",
      "Epoch 70 : loss [46.51844947]\n",
      "Epoch 71 : loss [46.51872353]\n",
      "Epoch 72 : loss [46.51899612]\n",
      "Epoch 73 : loss [46.51926726]\n",
      "Epoch 74 : loss [46.51953693]\n",
      "Epoch 75 : loss [46.51980517]\n",
      "Epoch 76 : loss [46.52007196]\n",
      "Epoch 77 : loss [46.52033733]\n",
      "Epoch 78 : loss [46.52060127]\n",
      "Epoch 79 : loss [46.52086379]\n",
      "Epoch 80 : loss [46.52112491]\n",
      "Epoch 81 : loss [46.52138463]\n",
      "Epoch 82 : loss [46.52164296]\n",
      "Epoch 83 : loss [46.5218999]\n",
      "Epoch 84 : loss [46.52215546]\n",
      "Epoch 85 : loss [46.52240965]\n",
      "Epoch 86 : loss [46.52266247]\n",
      "Epoch 87 : loss [46.52291394]\n",
      "Epoch 88 : loss [46.52316406]\n",
      "Epoch 89 : loss [46.52341284]\n",
      "Epoch 90 : loss [46.52366028]\n",
      "Epoch 91 : loss [46.5239064]\n",
      "Epoch 92 : loss [46.52415119]\n",
      "Epoch 93 : loss [46.52439466]\n",
      "Epoch 94 : loss [46.52463683]\n",
      "Epoch 95 : loss [46.5248777]\n",
      "Epoch 96 : loss [46.52511727]\n",
      "Epoch 97 : loss [46.52535555]\n",
      "Epoch 98 : loss [46.52559256]\n",
      "Epoch 99 : loss [46.52582828]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwoklEQVR4nO3df3QUdZ7/+1d1N2k6kLQKJt1ZYwguDArM6IgLC5zlxwiCjNclyg6oIwzncnVgVtGjIP6YQXch6q4sZ2VXF76eHDjIwHdm0evMXL/80IEdF9SIg4voCo4BoxKzIqQTEjqku+4fnS6MCZjOj6qYz/NxTp1Jqqq739Ul83nl8/lUlWXbti0AAACX+LwuAAAAmIXwAQAAXEX4AAAAriJ8AAAAVxE+AACAqwgfAADAVYQPAADgKsIHAABwVcDrAr4umUzqs88+U05OjizL8rocAADQDrZtq7a2VgUFBfL5zt+30ePCx2effabCwkKvywAAAB1QWVmpSy655Lz79LjwkZOTIylVfG5ursfVAACA9ojFYiosLHTa8fPpceEjPdSSm5tL+AAA4FumPVMmmHAKAABcRfgAAACuInwAAABXET4AAICrCB8AAMBVhA8AAOAqwgcAAHAV4QMAALiK8AEAAFxF+AAAAK4ifAAAAFcRPgAAgKt63IPlukvVJ0d071svK2H59E/fm6yCQUO8LgkAACMZEz6STWf0avgvJUnVn39C+AAAwCPGDLtcMCDf+bm+/pSHlQAAYDZjwkd2Tq4sOylJaiB8AADgGWPChyT5lZAk1cdPe1wJAADmyih8NDU16eGHH1ZxcbFCoZAGDx6sxx57TMlk0tln3rx5siyrxTJmzJguL7wjfM3hI94Y97gSAADMldGE0yeeeELPPvus1q9fr+HDh+utt97ST37yE4XDYd19993OftOmTVNZWZnze1ZWVtdV3AkBJdQoqbGJ8AEAgFcyCh979+7VjTfeqBkzZkiSBg0apF/+8pd66623WuwXDAYViUS6rsoukh52OdOU/IY9AQBAd8lo2GX8+PF65ZVXdOjQIUnSO++8o9dee03XX399i/127dqlvLw8DR06VAsWLFB1dXXXVdwJPqVCRzzZ5HElAACYK6Oej6VLl6qmpkbDhg2T3+9XIpHQihUrNGfOHGef6dOna9asWSoqKlJFRYUeeeQRTZ48Wfv27VMwGGz1nvF4XPH42WGQWCzWicM5P7+dkCzpTDLRbZ8BAADOL6PwsWXLFm3cuFGbNm3S8OHDtX//fi1evFgFBQWaO3euJOlHP/qRs/+IESM0atQoFRUV6Xe/+51KSkpavWdpaakeffTRTh5G+6QnnJ6R7crnAQCA1jIadrn//vv1wAMPaPbs2Ro5cqR+/OMf65577lFpaek5XxONRlVUVKTDhw+3uX3ZsmWqqalxlsrKysyOIAP+5mGXhE34AADAKxn1fNTX18vna5lX/H5/i0ttv+748eOqrKxUNBptc3swGGxzOKY7+O1Uz0eCng8AADyTUfi44YYbtGLFCl166aUaPny4/vjHP2rVqlWaP3++JKmurk7Lly/XTTfdpGg0qiNHjujBBx/UwIEDNXPmzG45gEykez7OeFwHAAAmyyh8PP3003rkkUe0cOFCVVdXq6CgQHfccYd+/vOfS0r1ghw4cEAbNmzQyZMnFY1GNWnSJG3ZskU5OTndcgCZ8KV7PiyPCwEAwGAZhY+cnBytXr1aq1evbnN7KBTStm3buqKubhFIz/mwSB8AAHjFqGe7+JofLNdE9gAAwDNGhY/0HU6T9HwAAOAZo8JHuucj4SN8AADgFaPChz8dPsgeAAB4xtDwYdRhAwDQoxjVCqcfLJdk2AUAAM8YFT78SeZ8AADgNaPCh6/5tupc7QIAgHeMCh9OzwfhAwAAz5gVPuz0nA+jDhsAgB7FqFbYZ6eGXej5AADAO0aFD+dSW3o+AADwjFGtcLrngwmnAAB4x6zwwYRTAAA8Z1T48Ds9H0YdNgAAPYpRrbDfmXBq1GEDANCjGNUKc4dTAAC8Z1T48DHsAgCA54xqhc/e4dSowwYAoEcxqhX2c6ktAACeMyp8WKmODyXk97YQAAAMZlT44GoXAAC8Z1QrzLALAADeMyt8JNM9Hwy7AADgFaPCR6A5fCTNOmwAAHoUo1rh9MEy5wMAAO8Y1QoH0hNOudoFAADPGBU+fKnswR1OAQDwkFGtcJ/m/02YddgAAPQoRrXCAaUuseVqFwAAvGNU+PA139+Dng8AALxjVCuc1TzXgwmnAAB4J6Pw0dTUpIcffljFxcUKhUIaPHiwHnvsMSWbnxYrSbZta/ny5SooKFAoFNLEiRN18ODBLi+8I/r4UqEjybALAACeySh8PPHEE3r22We1Zs0avf/++3ryySf1D//wD3r66aedfZ588kmtWrVKa9asUXl5uSKRiKZMmaLa2touLz5TWc2hg54PAAC8k1H42Lt3r2688UbNmDFDgwYN0s0336ypU6fqrbfekpTq9Vi9erUeeughlZSUaMSIEVq/fr3q6+u1adOmbjmATPQJBCQRPgAA8FJG4WP8+PF65ZVXdOjQIUnSO++8o9dee03XX3+9JKmiokJVVVWaOnWq85pgMKgJEyZoz549bb5nPB5XLBZrsXSXrEDqYlsmnAIA4J1AJjsvXbpUNTU1GjZsmPx+vxKJhFasWKE5c+ZIkqqqqiRJ+fn5LV6Xn5+vo0ePtvmepaWlevTRRztSe8ZCWUFJUiKzwwYAAF0ooy6ALVu2aOPGjdq0aZPefvttrV+/Xv/4j/+o9evXt9jP+toj623bbrUubdmyZaqpqXGWysrKDA+h/UKhkCQeLAcAgJcy6gK4//779cADD2j27NmSpJEjR+ro0aMqLS3V3LlzFYlEJKV6QKLRqPO66urqVr0hacFgUMFgsKP1Z6Rv32xJkm35VHPiuMIXDnDlcwEAwFkZdQHU19fL52v5Er/f71xqW1xcrEgkoh07djjbGxsbtXv3bo0dO7YLyu2c/v1znZ9PHv/cw0oAADBXRj0fN9xwg1asWKFLL71Uw4cP1x//+EetWrVK8+fPl5Qablm8eLFWrlypIUOGaMiQIVq5cqWys7N1yy23dMsBZCI7O1eqS/3cUNd9E1sBAMC5ZRQ+nn76aT3yyCNauHChqqurVVBQoDvuuEM///nPnX2WLFmihoYGLVy4UCdOnNDo0aO1fft25eTkdHnxmcq9aIBUfVySVEf4AADAE5Zt27bXRXxVLBZTOBxWTU2NcnNzv/kFGTjd0KBBr38gSfrfTRX6qykzu/T9AQAwVSbtt1GXffQNheSzE5Kkhvp6j6sBAMBMRoUPSfKrOXzET3tcCQAAZjI2fDQ2NXpcCQAAZjI2fMSbznhcCQAAZjI2fJxJJjyuBAAAMxkXPnzp8JEgfAAA4AXjwoe/+WqXRno+AADwhHnhQ6lbwTepR93eBAAAYxgYPlI9Hk0e1wEAgKmMCx8+O9XzkaDnAwAATxgXPtLDLsz4AADAG+aFj+YJp02Wx4UAAGAo48KHL93zYZE+AADwgnHhw98856PJR/gAAMALBoaP1LBLguwBAIAnjAsfvuarXJIMuwAA4AnjwofT88GwCwAAnjAufPjsVM8HE04BAPCGceEjPeGUng8AALxhbvig5wMAAE8YFz7St1e3CR8AAHjCuPBxdtjFuEMHAKBHMK4F9jHsAgCAp4wLH/7mq12S9HwAAOAJ41pgf5JLbQEA8JJx4SM97JK0jDt0AAB6BONa4PSwC/f5AADAG8aFD1+SCacAAHjJuPDhTDhl2AUAAE8Y1wL7nZ4P4w4dAIAewbgW2KLnAwAATxnXAjsTTgkfAAB4IqMWeNCgQbIsq9WyaNEiSdK8efNabRszZky3FN5R6ft8JJlwCgCAJwKZ7FxeXq5EIuH8/u6772rKlCmaNWuWs27atGkqKytzfs/KyuqCMrsOPR8AAHgro/Bx8cUXt/j98ccf12WXXaYJEyY464LBoCKRSNdU1w3O3uHU73ElAACYqcN//jc2Nmrjxo2aP3++rK8MYezatUt5eXkaOnSoFixYoOrq6vO+TzweVywWa7F0J196wqkYdgEAwAsdDh8vvviiTp48qXnz5jnrpk+frueff16vvvqqnnrqKZWXl2vy5MmKx+PnfJ/S0lKFw2FnKSws7GhJ7eJPZQ96PgAA8Ihl281dARm67rrrlJWVpd/85jfn3OfYsWMqKirS5s2bVVJS0uY+8Xi8RTiJxWIqLCxUTU2NcnNzO1Laef38uce1dvA0Xdb0J/3nlJu6/P0BADBRLBZTOBxuV/ud0ZyPtKNHj2rnzp3aunXrefeLRqMqKirS4cOHz7lPMBhUMBjsSBkd4tzh1LyrjAEA6BE61AKXlZUpLy9PM2bMOO9+x48fV2VlpaLRaIeK6w4Bhl0AAPBUxuEjmUyqrKxMc+fOVSBwtuOkrq5O9913n/bu3asjR45o165duuGGGzRw4EDNnDmzS4vujPQBJ+j5AADAExkPu+zcuVMff/yx5s+f32K93+/XgQMHtGHDBp08eVLRaFSTJk3Sli1blJOT02UFd1ag+SoXbq8OAIA3Mg4fU6dOVVtzVEOhkLZt29YlRXWn9AEnxLALAABeMO7P/3TPB8MuAAB4w7gWOMuX6vFgwikAAN4wLnwEfKlDTjLsAgCAJ4wLH1n+1KwP5nwAAOAN48JHMNBHEuEDAACvGBc+sgJZkggfAAB4xbjwEQr2lUT4AADAK8aFj759U+Ejafl1uqHB42oAADCPceGjX7+zd1uNnfzCw0oAADCTceGjf/+zj/mNfXncw0oAADCTceEj9JXwUV8f87ASAADMZFz4uGBAvvNzXR3hAwAAtxkXPsIXDpBlJyVJp0/Xe1wNAADmMS58SJJPqfDRwNUuAAC4zsjw4VeTJKmhMe5xJQAAmMfQ8JHq+WhsOuNxJQAAmMfQ8JGQJJ1pavK4EgAAzGN0+Gi0Ex5XAgCAeYwMH77m0HEmSfgAAMBtRoaPsz0fSY8rAQDAPIaGj1ToSNq2x5UAAGAeM8NH87BLkwgfAAC4zczw0dzzwYW2AAC4z8jw4Wue65G0PC4EAAADGRk+0hNOmyzSBwAAbjMyfDg9Hx7XAQCAiYwMH+k5H00+ej4AAHCbmeGj+WqXBOEDAADXGRk+fM3390gw5wMAANcZGT78zXM+CB8AALjPyPDha57zYRt59AAAeCuj5nfQoEGyLKvVsmjRIkmSbdtavny5CgoKFAqFNHHiRB08eLBbCu8Mej4AAPBORuGjvLxcx44dc5YdO3ZIkmbNmiVJevLJJ7Vq1SqtWbNG5eXlikQimjJlimpra7u+8k5wwoePrg8AANyWUet78cUXKxKJOMtvf/tbXXbZZZowYYJs29bq1av10EMPqaSkRCNGjND69etVX1+vTZs2dVf9HXL2Dqf0fAAA4LYO/+nf2NiojRs3av78+bIsSxUVFaqqqtLUqVOdfYLBoCZMmKA9e/ac833i8bhisViLpbv5k81Xu9DzAQCA6zrc+r744os6efKk5s2bJ0mqqqqSJOXn57fYLz8/39nWltLSUoXDYWcpLCzsaEntlp5wypwPAADc1+Hw8dxzz2n69OkqKChosd76WoNu23ardV+1bNky1dTUOEtlZWVHS2o3f5LwAQCAVwIdedHRo0e1c+dObd261VkXiUQkpXpAotGos766urpVb8hXBYNBBYPBjpTRYf7mm4wlGXYBAMB1HWp9y8rKlJeXpxkzZjjriouLFYlEnCtgpNS8kN27d2vs2LGdr7QLpe9wyoRTAADcl3HPRzKZVFlZmebOnatA4OzLLcvS4sWLtXLlSg0ZMkRDhgzRypUrlZ2drVtuuaVLi+6ss8Mu9HwAAOC2jMPHzp079fHHH2v+/Pmtti1ZskQNDQ1auHChTpw4odGjR2v79u3KycnpkmK7Cj0fAAB4J+PwMXXqVNnNjffXWZal5cuXa/ny5Z2tq1vR8wEAgHeMbH3TE065zwcAAO4zsvV1hl3EsAsAAG4zMnxwh1MAALxjZOvrS6Z7Pow8fAAAPGVk6+s81ZYJpwAAuM7I1tfffLEO4QMAAPcZ2fqm53wkCR8AALjOyNY3fbVLQn6PKwEAwDxGho8Awy4AAHjGyNbXucmYmYcPAICnjGx90xNOkxbDLgAAuM3I8BFofqAcPR8AALjPyNb37JwPej4AAHCbkeHDT88HAACeMbL17dP8QLkkl9oCAOA6M8OHLxU6GHYBAMB9ZoYPfyp08GA5AADcZ2TrG2wOH9zhFAAA9xkZPrICQUlSE+EDAADXGRk+glmp8MGEUwAA3Gdk+MgO9pXEsAsAAF4wMnz07ZsKH7blU31tzONqAAAwi5Hho1//XOfnk8c/97ASAADMY2T46N//Qufn2MnjHlYCAIB5zAwf4Qucn0/V13lXCAAABjIyfOSGL3J+PnWq1sNKAAAwj5HhIzsnV5adkCTF46c9rgYAALMYGT4kKaBU+GhoaPC4EgAAzGJs+PA3h4/TZ+IeVwIAgFmMDR++5vARTzR5XAkAAGYxNnykez7OED4AAHCVweEjKUk6k0h4XAkAAGbJOHx8+umnuu222zRgwABlZ2fryiuv1L59+5zt8+bNk2VZLZYxY8Z0adFdwd98tcsZ2/a4EgAAzBLIZOcTJ05o3LhxmjRpkl5++WXl5eXpT3/6ky644IIW+02bNk1lZWXO71lZWV1SbFdyhl1sej4AAHBTRuHjiSeeUGFhYYtgMWjQoFb7BYNBRSKRThfXnXzNwy7M+AAAwF0ZDbu89NJLGjVqlGbNmqW8vDxdddVVWrduXav9du3apby8PA0dOlQLFixQdXX1Od8zHo8rFou1WNyQHnZJiGEXAADclFH4+Oijj/TMM89oyJAh2rZtm+68807ddddd2rBhg7PP9OnT9fzzz+vVV1/VU089pfLyck2ePFnxeNv30ygtLVU4HHaWwsLCzh1RO6UnnDLoAgCAuyzbbv+My6ysLI0aNUp79uxx1t11110qLy/X3r1723zNsWPHVFRUpM2bN6ukpKTV9ng83iKYxGIxFRYWqqamRrm5uZkcS0bG7HhRRwKD9NM/vaxf/N/Luu1zAAAwQSwWUzgcblf7nVHPRzQa1RVXXNFi3eWXX66PP/74vK8pKirS4cOH29weDAaVm5vbYnFDesJpwrJc+TwAAJCSUfgYN26cPvjggxbrDh06pKKionO+5vjx46qsrFQ0Gu1Yhd3EZzcPu5A9AABwVUbh45577tHrr7+ulStX6sMPP9SmTZu0du1aLVq0SJJUV1en++67T3v37tWRI0e0a9cu3XDDDRo4cKBmzpzZLQfQUf7m8NFEzwcAAK7KKHxcc801euGFF/TLX/5SI0aM0N/93d9p9erVuvXWWyVJfr9fBw4c0I033qihQ4dq7ty5Gjp0qPbu3aucnJxuOYCOSk84TfoIHwAAuCmj+3xI0g9/+EP98Ic/bHNbKBTStm3bOl2UG9LDLkl6PgAAcJW5z3ZJD7vQ8wEAgKuMDR/0fAAA4A1jw0e65yNBzwcAAK4yPnzQ8wEAgLuMDR++5hu7JnzGfgUAAHjC2JbXGXah5wMAAFcZGz7SPR9Jy9ivAAAATxjb8jpzPphwCgCAq8wNH8n0sIuxXwEAAJ4wtuV1Jpwy5wMAAFcZGz64zwcAAN4wNnz4kqmeD5thFwAAXGVsy+t3hl2M/QoAAPCEsS2vjwmnAAB4wtiW1+/c54M5HwAAuMn48EHPBwAA7jK25fUnCR8AAHjB2JbXub26uV8BAACeMLblpecDAABvGNvyMucDAABvGNvy+lNX2iph+b0tBAAAwxgbPgLM+QAAwBPGtrzpA2fYBQAAdxnb8gZSHR9KiGEXAADcZGz48Ct1Z9MkPR8AALjK2Ja3j50KH/R8AADgLmPDR6D5kS4Jc78CAAA8YWzLG/ClejySXGoLAICrjA0fWb7UoTPsAgCAu4wNH338qdDBsAsAAO4ytuUNBvpIoucDAAC3ZRw+Pv30U912220aMGCAsrOzdeWVV2rfvn3Odtu2tXz5chUUFCgUCmnixIk6ePBglxbdFYKBoCQpoYDHlQAAYJaMwseJEyc0btw49enTRy+//LLee+89PfXUU7rgggucfZ588kmtWrVKa9asUXl5uSKRiKZMmaLa2tqurr1TgllZkri9OgAAbsvoz/4nnnhChYWFKisrc9YNGjTI+dm2ba1evVoPPfSQSkpKJEnr169Xfn6+Nm3apDvuuKNrqu4C2aFsSVLCCuh0Q4P6hkIeVwQAgBky+rP/pZde0qhRozRr1izl5eXpqquu0rp165ztFRUVqqqq0tSpU511wWBQEyZM0J49e7qu6i7QN+ts2Gioq/GwEgAAzJJR+Pjoo4/0zDPPaMiQIdq2bZvuvPNO3XXXXdqwYYMkqaqqSpKUn5/f4nX5+fnOtq+Lx+OKxWItFjf0D4edn09+We3KZwIAgAyHXZLJpEaNGqWVK1dKkq666iodPHhQzzzzjG6//XZnP8uyWrzOtu1W69JKS0v16KOPZlp3p/XPvVCqaZQk1cZOuv75AACYKqOej2g0qiuuuKLFussvv1wff/yxJCkSiUhSq16O6urqVr0hacuWLVNNTY2zVFZWZlJSh+WGL3J+bqirc+UzAQBAhuFj3Lhx+uCDD1qsO3TokIqKiiRJxcXFikQi2rFjh7O9sbFRu3fv1tixY9t8z2AwqNzc3BaLG0L9zw67nDpN+AAAwC0ZDbvcc889Gjt2rFauXKm/+Zu/0Ztvvqm1a9dq7dq1klLDLYsXL9bKlSs1ZMgQDRkyRCtXrlR2drZuueWWbjmAjuobCslvNylhBRSPx70uBwAAY2QUPq655hq98MILWrZsmR577DEVFxdr9erVuvXWW519lixZooaGBi1cuFAnTpzQ6NGjtX37duXk5HR58Z3lV0IJBdTQeNrrUgAAMIZl27btdRFfFYvFFA6HVVNT0+1DMMWv7lGDla1Vn/6nbrltUbd+FgAAvVkm7bfRt/f0KSFJako2eVwJAADmMDp8+JvDRzyR8LgSAADMYXj4SEqSziQJHwAAuMXs8GGnh12SHlcCAIA5zA4f6Tkf6lFzbgEA6NWMDh++5mEXppsCAOAeo8OHM+xCzwcAAK4xOnykez4SbT/zDgAAdAOjw4ffbg4fHtcBAIBJDA8fqdiRsOj6AADALUaHD2fYxehvAQAAdxnd7DrDLvR8AADgGsKHpCaf0V8DAACuMrrVTQ+72HR8AADgGqPDhzPs4iN9AADgFsKHmPMBAICbjA4fPid8GP01AADgKqNb3XTPR5JhFwAAXGN4+Eg904VhFwAA3GN0+HCGXbjUFgAA1xjd6vqSqZ6PJD0fAAC4xujw4WfCKQAArjO61U3P+WDCKQAA7jE6fKSHXej5AADAPUa3us6ltsz5AADANUaHD59NzwcAAG4zutX1p4dduNQWAADXGN3qOsMuYtgFAAC3GB0+mHAKAID7jG51z044NfprAADAVUa3uv5U9qDnAwAAFxnd6vq52gUAANdl1OouX75clmW1WCKRiLN93rx5rbaPGTOmy4vuKn7n2S6EDwAA3BLI9AXDhw/Xzp07nd/9fn+L7dOmTVNZWZnze1ZWVifK617OfT7M7gACAMBVGYePQCDQorfj64LB4Hm39yTOs10s/zfsCQAAukrGf/IfPnxYBQUFKi4u1uzZs/XRRx+12L5r1y7l5eVp6NChWrBggaqrq8/7fvF4XLFYrMXiFn8qe6iJng8AAFyTUas7evRobdiwQdu2bdO6detUVVWlsWPH6vjx45Kk6dOn6/nnn9err76qp556SuXl5Zo8ebLi8fg537O0tFThcNhZCgsLO3dEGUh3+zDnAwAA91i23Tz20AGnTp3SZZddpiVLlujee+9ttf3YsWMqKirS5s2bVVJS0uZ7xOPxFuEkFoupsLBQNTU1ys3N7Whp7fLE/3pc/3TZNBUkPtXb187o1s8CAKA3i8ViCofD7Wq/M57z8VX9+vXTyJEjdfjw4Ta3R6NRFRUVnXO7lJojEgwGO1NGh/maYxc9HwAAuKdTrW48Htf777+vaDTa5vbjx4+rsrLynNu91sdKPdMlISacAgDglozCx3333afdu3eroqJCb7zxhm6++WbFYjHNnTtXdXV1uu+++7R3714dOXJEu3bt0g033KCBAwdq5syZ3VV/pwSaD5/wAQCAezIadvnkk080Z84cffHFF7r44os1ZswYvf766yoqKlJDQ4MOHDigDRs26OTJk4pGo5o0aZK2bNminJyc7qq/U9I9Hwy7AADgnozCx+bNm8+5LRQKadu2bZ0uyE1ZgdTh0/MBAIB7jP6TP+BLhQ7ucAoAgHuMbnVD/tSt3xOdu+gHAABkwOjwEezbVxLDLgAAuMno8NE3K93zYfTXAACAq4xudbND2ZIk2/Krvta9Z8oAAGAyo8NH31A/5+dYzZceVgIAgDmMDh/9cy90fq45edzDSgAAMIfR4SN8wQDn51rCBwAArjA6fFwwIF/97VpJ0r4P/svjagAAMIPR4aNvKKRo0+eSpI98CY+rAQDADEaHD0mKnE5NNP08t9837AkAALqC8eEjvy417FKVHfa4EgAAzGB8+Cg41ShJ+jxrwDfsCQAAuoLx4eOqiy+RJH1u5avqkyPeFgMAgAGMDx+TrrtZIbteScuvl1950etyAADo9YwPH31DIUUTVZKkDxOnPa4GAIDez/jwIUn58dQVL1U52R5XAgBA70f4kBRpvuLl8365HlcCAEDvR/iQVFCXGm45ljXQ40oAAOj9CB+ShuemQsfnvnyd+J8qj6sBAKB3I3xImjb9R8qyT6vJ6qOXt/3K63IAAOjVCB+SsnNyFUmmnvHyQfyUx9UAANC7ET6aReLHJUnH+vf1uBIAAHo3wkezSF1MklTVnyteAADoToSPZtHmK16qgjzjBQCA7kT4aPadYI4kqcoXUX1tzONqAADovQgfzaZfd5P62I1qtIL6Py9v8bocAAB6LcJHswsvjigvWS1JOhj7wuNqAADovQgfXxFtTIWOz7jiBQCAbkP4+Ir8U+krXnI8rgQAgN6L8PEVkdp6SVzxAgBAdyJ8fMVQX0iSVOXP1+mGBo+rAQCgd8oofCxfvlyWZbVYIpGIs922bS1fvlwFBQUKhUKaOHGiDh482OVFd5frrr1RPjuhBitbv9/2a6/LAQCgV8q452P48OE6duyYsxw4cMDZ9uSTT2rVqlVas2aNysvLFYlENGXKFNXW1nZp0d0lcskg5dupZ7z88X8+8bgaAAB6p4zDRyAQUCQScZaLL75YUqrXY/Xq1XrooYdUUlKiESNGaP369aqvr9emTZu6vPDuEklf8dIvy+NKAADonTIOH4cPH1ZBQYGKi4s1e/ZsffTRR5KkiooKVVVVaerUqc6+wWBQEyZM0J49e875fvF4XLFYrMXipbNXvPCMFwAAukNG4WP06NHasGGDtm3bpnXr1qmqqkpjx47V8ePHVVVVJUnKz89v8Zr8/HxnW1tKS0sVDoedpbCwsAOH0XWitackSZ/3vdDTOgAA6K0yCh/Tp0/XTTfdpJEjR+raa6/V7373O0nS+vXrnX0sy2rxGtu2W637qmXLlqmmpsZZKisrMympyw1K+iVJnwW44gUAgO7QqUtt+/Xrp5EjR+rw4cPOVS9f7+Worq5u1RvyVcFgULm5uS0WL00dP1U+O6FTVo5+9at1ntYCAEBv1KnwEY/H9f777ysajaq4uFiRSEQ7duxwtjc2Nmr37t0aO3Zspwt1S/F3vqvhjf8tSdqWE/C4GgAAep+Mwsd9992n3bt3q6KiQm+88YZuvvlmxWIxzZ07V5ZlafHixVq5cqVeeOEFvfvuu5o3b56ys7N1yy23dFf93WLcJx9Lkt4Ij9BnRw57XA0AAL1LRuHjk08+0Zw5c/Sd73xHJSUlysrK0uuvv66ioiJJ0pIlS7R48WItXLhQo0aN0qeffqrt27crJ+fb9ayUu2/8iS6wv1Stlas1v9/qdTkAAPQqlm3bttdFfFUsFlM4HFZNTY2n8z/m/XqN/s+A8bq88b/1++tme1YHAADfBpm03zzb5Rz+r2RQlp3U+1nD9OtN/+Z1OQAA9BqEj3Mo+ZsFuvzMB5Kkl4JnPK4GAIDeg/BxHuM+OSpJeuPCEao+5u39RwAA6C0IH+ex6LrZyrVrVGNdoDX/3/NelwMAQK9A+DiPyCWDNObku5KkPX92qcfVAADQOxA+vsGM06lbwx/MGqYX//dzHlcDAMC3H+HjG/zoloUaduYD2ZZP/6+v3utyAAD41iN8tMNffnpEkvT6RcP14cH9ntYCAMC3HeGjHf52UokusE/ohHWR7j3yNk+7BQCgEwgf7VAwaIjm/+kN+eyE3sz+vu574V+9LgkAgG8twkc7LVnwgGZ+vluStDUyUf+w7nGPKwIA4NuJ8JGBp/76p7qm/o9KWn6tu+wv9but670uCQCAbx3CRwb6hkL6p0FXqTBRqZgV1t/n5OqzI4e9LgsAgG8VwkeG/nz4lVpa/Zn62XWqCBRr0bv/oRP/U+V1WQAAfGsQPjrg5lvu0Pw//UGWndDefldrxv492rTxaa/LAgDgW4Hw0UEPLVimeUd3KmTX66PAYD1Q8Bf62aanVF8b87o0AAB6NMJHJ5T+ZKn++eRhXd7432q0gvp19Ae6fu/L3IYdAIDzsGzbtr0u4qtisZjC4bBqamqUm5vrdTntUl8b07KX1uqF6Hg1Wn0VsM/oe6ff09jPPtPPbvp/FL5wgNclAgDQrTJpvwkfXWjTxn/RM3l5OtxniLPuouRxjT7xnibX25o1a4H6hkIeVggAQPcgfHjs3577R706MEdv5QzXKau/sz7HjmlQY6UGxb7Qn8cadN3I0bpy9CQPKwUAoGsQPnqIox++p3/7w0t6vaBIh/r8uZqsPq326WfXamDiSw1oOqmLGk7pgtMN6hdvUm5TUhf6AorkXKDBRX+uosGX68KLIx4cBQAA34zw0QN9duSwfr1jqz7o30dHwgNUEbxEX/oymwsSsM8oqNMK2o3qozMK2E2pRQkF7IT8dkJ+OylLtvx2Uj7bls9OypJkyZbPtmXZtizZsiTJTq1PSa2zvvZfw9nt52d97ffM/qP6+qtba+v9bOubX5fJ+7W9Xzs/w2r1g+yOl9fuz+3UcZzvI6xz/nLOz23/OW/f+7Xzpef8rixZLfZv97lsQ9vnsqvP0Tk+w5Lky7z2zhxv2+/X8c+wJfl8PmVlZWX+ue38Arv63/S53s/yZal/vyHn2JphLZ04tvYfb9t7Zlk+bbnysna+S/tk0n4HuvSTcU4Fg4borgVLW6w7+PZ/6vV33lBlIq4vsrP0RXY/xYIhnfKHdMoX0ilfP9Wpv85YqX+wTVYfNamPTnXt/6cAgDvOeF1AF2ms87qCTgt2INB2JcKHh4Z/f5yGf3/cefc53dCgLz//RJUVh/X5F1U62VCr2sa46pMJNfn76IxPapKtM5aU8FlKWJZsS0pISvosJS1LSUuSUuttpX63m/+istXy55TUf5R2y19brmuH9v6nbbWxd3t7XNr9uW28XVuf0e5/jm29n2W1eoP2fwdt/Unfifra/Iz28VmWLF8Hz8e5vpdWtXSsRy0Tfp9f/j4thzrb/J7b+bntPpft7JFr9/sFLPn6tvy/6rbr69rGpO37MLTvM9pq1/yBgMLh8De+W5d/f23s2d5O07Ze6/NlKTdnxNfer/v/u2qv9h6br8s/OTOEjx6ubyikgkFDVDDo/N18AAB8W3CTMQAA4CrCBwAAcBXhAwAAuIrwAQAAXEX4AAAAriJ8AAAAV3UqfJSWlsqyLC1evNhZN2/ePFmW1WIZM2ZMZ+sEAAC9RIfv81FeXq61a9fqu9/9bqtt06ZNU1lZmfN7R26pCwAAeqcO9XzU1dXp1ltv1bp163ThhRe22h4MBhWJRJzloosu6nShAACgd+hQ+Fi0aJFmzJiha6+9ts3tu3btUl5enoYOHaoFCxaourr6nO8Vj8cVi8VaLAAAoPfKeNhl8+bNevvtt1VeXt7m9unTp2vWrFkqKipSRUWFHnnkEU2ePFn79u1TMBhstX9paakeffTRzCsHAADfSpZtt/ehvlJlZaVGjRql7du363vf+54kaeLEibryyiu1evXqNl9z7NgxFRUVafPmzSopKWm1PR6PKx6PO7/HYjEVFha265G8AACgZ4jFYgqHw+1qvzPq+di3b5+qq6t19dVXO+sSiYT+4z/+Q2vWrFE8Hpff72/xmmg0qqKiIh0+fLjN9wwGg232iAAAgN4po/Dxgx/8QAcOHGix7ic/+YmGDRumpUuXtgoeknT8+HFVVlYqGo226zPSHTHM/QAA4Nsj3W63Z0Alo/CRk5OjESNGtFjXr18/DRgwQCNGjFBdXZ2WL1+um266SdFoVEeOHNGDDz6ogQMHaubMme36jNraWklSYWFhJqUBAIAeoLa2VuFw+Lz7dPg+H23x+/06cOCANmzYoJMnTyoajWrSpEnasmWLcnJy2vUeBQUFqqysVE5OjizL6srynPkklZWVzCfpATgfPQvno+fhnPQsnI/zs21btbW1Kigo+MZ9M5pw+m2XyWQYdD/OR8/C+eh5OCc9C+ej6/BsFwAA4CrCBwAAcJVR4SMYDOoXv/gFl/b2EJyPnoXz0fNwTnoWzkfXMWrOBwAA8J5RPR8AAMB7hA8AAOAqwgcAAHAV4QMAALjKmPDxr//6ryouLlbfvn119dVX6w9/+IPXJRmhtLRU11xzjXJycpSXl6e//uu/1gcffNBiH9u2tXz5chUUFCgUCmnixIk6ePCgRxWbpbS0VJZlafHixc46zof7Pv30U912220aMGCAsrOzdeWVV2rfvn3Ods6Je5qamvTwww+ruLhYoVBIgwcP1mOPPaZkMunsw/noArYBNm/ebPfp08det26d/d5779l333233a9fP/vo0aNel9brXXfddXZZWZn97rvv2vv377dnzJhhX3rppXZdXZ2zz+OPP27n5OTY//7v/24fOHDA/tGPfmRHo1E7Fot5WHnv9+abb9qDBg2yv/vd79p33323s57z4a4vv/zSLioqsufNm2e/8cYbdkVFhb1z5077ww8/dPbhnLjn7//+7+0BAwbYv/3tb+2Kigr7V7/6ld2/f3979erVzj6cj84zInz8xV/8hX3nnXe2WDds2DD7gQce8Kgic1VXV9uS7N27d9u2bdvJZNKORCL2448/7uxz+vRpOxwO288++6xXZfZ6tbW19pAhQ+wdO3bYEyZMcMIH58N9S5cutcePH3/O7ZwTd82YMcOeP39+i3UlJSX2bbfdZts256Or9Pphl8bGRu3bt09Tp05tsX7q1Knas2ePR1WZq6amRpJ00UUXSZIqKipUVVXV4vwEg0FNmDCB89ONFi1apBkzZujaa69tsZ7z4b6XXnpJo0aN0qxZs5SXl6errrpK69atc7ZzTtw1fvx4vfLKKzp06JAk6Z133tFrr72m66+/XhLno6t06VNte6IvvvhCiURC+fn5Ldbn5+erqqrKo6rMZNu27r33Xo0fP14jRoyQJOcctHV+jh496nqNJti8ebPefvttlZeXt9rG+XDfRx99pGeeeUb33nuvHnzwQb355pu66667FAwGdfvtt3NOXLZ06VLV1NRo2LBh8vv9SiQSWrFihebMmSOJfyNdpdeHjzTLslr8btt2q3XoXj/72c/0X//1X3rttddabeP8uKOyslJ33323tm/frr59+55zP86He5LJpEaNGqWVK1dKkq666iodPHhQzzzzjG6//XZnP86JO7Zs2aKNGzdq06ZNGj58uPbv36/FixeroKBAc+fOdfbjfHROrx92GThwoPx+f6tejurq6lbJFd3nb//2b/XSSy/p97//vS655BJnfSQSkSTOj0v27dun6upqXX311QoEAgoEAtq9e7f++Z//WYFAwPnOOR/uiUajuuKKK1qsu/zyy/Xxxx9L4t+I2+6//3498MADmj17tkaOHKkf//jHuueee1RaWiqJ89FVen34yMrK0tVXX60dO3a0WL9jxw6NHTvWo6rMYdu2fvazn2nr1q169dVXVVxc3GJ7cXGxIpFIi/PT2Nio3bt3c366wQ9+8AMdOHBA+/fvd5ZRo0bp1ltv1f79+zV48GDOh8vGjRvX6vLzQ4cOqaioSBL/RtxWX18vn69l0+j3+51LbTkfXcTDya6uSV9q+9xzz9nvvfeevXjxYrtfv372kSNHvC6t1/vpT39qh8Nhe9euXfaxY8ecpb6+3tnn8ccft8PhsL1161b7wIED9pw5c7hszUVfvdrFtjkfbnvzzTftQCBgr1ixwj58+LD9/PPP29nZ2fbGjRudfTgn7pk7d679Z3/2Z86ltlu3brUHDhxoL1myxNmH89F5RoQP27btf/mXf7GLiorsrKws+/vf/75zqSe6l6Q2l7KyMmefZDJp/+IXv7AjkYgdDAbtv/qrv7IPHDjgXdGG+Xr44Hy47ze/+Y09YsQIOxgM2sOGDbPXrl3bYjvnxD2xWMy+++677UsvvdTu27evPXjwYPuhhx6y4/G4sw/no/Ms27ZtL3teAACAWXr9nA8AANCzED4AAICrCB8AAMBVhA8AAOAqwgcAAHAV4QMAALiK8AEAAFxF+AAAAK4ifAAAAFcRPgAAgKsIHwAAwFWEDwAA4Kr/HyyGb+Ui0e61AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LEARNING_RATE = 0.5\n",
    "NUM_EPOCHS = 100\n",
    "cost = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    \n",
    "    for i, s in enumerate(x_train):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        # print(inp.shape)\n",
    "\n",
    "        hlayer_logits = np.dot(inp, weights_ih) + bias_ih\n",
    "        # print(\"hlayer_logits\",hlayer_logits)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "        # print(\"hlayer_output\",s, hlayer_output)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho) + bias_ho\n",
    "        # print(\"final_logits\",final_logits, '\\n')\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "\n",
    "        tot_loss += abs(final_output[0] - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output[0]) * final_output * (1 - final_output[0])\n",
    "        bias_ho += LEARNING_RATE * output_delta\n",
    "        # bias_ih += LEARNING_RATE * (output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        # weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "    cost.append(tot_loss[0])\n",
    "    print(f'Epoch {epoch} : loss {tot_loss}')\n",
    "    if epoch%10 == 0:\n",
    "        plt.plot([pl for pl in range(epoch+1)], cost)\n",
    "        plt.savefig('train.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Batches(Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(28)\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 2\n",
    "output_size = 1\n",
    "\n",
    "# weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ih = np.load('weights/weights_ih2.npy')\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)\n",
    "# bias_ih = np.random.rand(1, hidden_layer_size)\n",
    "bias_ih = np.load('weights/bias_ih2.npy')\n",
    "bias_ho = np.random.rand(1, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_ih = np.load('weights_ih2.npy')\n",
    "# weights_ho = np.load('weights_ho2.npy')\n",
    "# bias_ih = np.load('bias_ih2.npy')\n",
    "# bias_ho = np.load('bias_ho2.npy')\n",
    "# weights_ih = weights_ih[:, [1, 3]]\n",
    "# bias_ih = bias_ih[:, [1, 3]]\n",
    "# weights_ho = weights_ho[[1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [115.13603612]\n",
      "Epoch 1 : loss [66.51944244]\n",
      "Epoch 2 : loss [60.08567418]\n",
      "Epoch 3 : loss [57.13474675]\n",
      "Epoch 4 : loss [55.50307404]\n",
      "Epoch 5 : loss [54.54859544]\n",
      "Epoch 6 : loss [54.00382805]\n",
      "Epoch 7 : loss [53.73566043]\n",
      "Epoch 8 : loss [53.67019108]\n",
      "Epoch 9 : loss [53.76337493]\n",
      "Epoch 10 : loss [53.98776948]\n",
      "Epoch 11 : loss [54.32589949]\n",
      "Epoch 12 : loss [54.76666915]\n",
      "Epoch 13 : loss [55.30330331]\n",
      "Epoch 14 : loss [55.93210829]\n",
      "Epoch 15 : loss [56.65169264]\n",
      "Epoch 16 : loss [57.4624507]\n",
      "Epoch 17 : loss [58.36618944]\n",
      "Epoch 18 : loss [59.36581545]\n",
      "Epoch 19 : loss [60.46501204]\n",
      "Epoch 20 : loss [61.66783544]\n",
      "Epoch 21 : loss [62.97814858]\n",
      "Epoch 22 : loss [64.3987952]\n",
      "Epoch 23 : loss [65.93040444]\n",
      "Epoch 24 : loss [67.56972103]\n",
      "Epoch 25 : loss [69.30740598]\n",
      "Epoch 26 : loss [71.12538446]\n",
      "Epoch 27 : loss [72.99406781]\n",
      "Epoch 28 : loss [74.87014042]\n",
      "Epoch 29 : loss [76.69596968]\n",
      "Epoch 30 : loss [78.40181449]\n",
      "Epoch 31 : loss [79.91155777]\n",
      "Epoch 32 : loss [81.15155848]\n",
      "Epoch 33 : loss [82.0607907]\n",
      "Epoch 34 : loss [82.59951613]\n",
      "Epoch 35 : loss [82.7540033]\n",
      "Epoch 36 : loss [82.53621811]\n",
      "Epoch 37 : loss [81.97918369]\n",
      "Epoch 38 : loss [81.12991145]\n",
      "Epoch 39 : loss [80.04200989]\n",
      "Epoch 40 : loss [78.76949708]\n",
      "Epoch 41 : loss [77.36249788]\n",
      "Epoch 42 : loss [75.86481868]\n",
      "Epoch 43 : loss [74.31301745]\n",
      "Epoch 44 : loss [72.73648317]\n",
      "Epoch 45 : loss [71.15809332]\n",
      "Epoch 46 : loss [69.59513121]\n",
      "Epoch 47 : loss [68.06025869]\n",
      "Epoch 48 : loss [66.56242937]\n",
      "Epoch 49 : loss [65.10768821]\n",
      "Epoch 50 : loss [63.58841986]\n",
      "Epoch 51 : loss [62.0660664]\n",
      "Epoch 52 : loss [60.57742002]\n",
      "Epoch 53 : loss [59.15374675]\n",
      "Epoch 54 : loss [57.79408402]\n",
      "Epoch 55 : loss [56.49634602]\n",
      "Epoch 56 : loss [55.2580188]\n",
      "Epoch 57 : loss [54.07635301]\n",
      "Epoch 58 : loss [52.94849506]\n",
      "Epoch 59 : loss [51.87157805]\n",
      "Epoch 60 : loss [50.84278334]\n",
      "Epoch 61 : loss [49.8593811]\n",
      "Epoch 62 : loss [48.91875575]\n",
      "Epoch 63 : loss [48.01842061]\n",
      "Epoch 64 : loss [47.15602507]\n",
      "Epoch 65 : loss [46.32935649]\n",
      "Epoch 66 : loss [45.53633851]\n",
      "Epoch 67 : loss [44.775027]\n",
      "Epoch 68 : loss [44.04360457]\n",
      "Epoch 69 : loss [43.34037409]\n",
      "Epoch 70 : loss [42.66375185]\n",
      "Epoch 71 : loss [42.01226049]\n",
      "Epoch 72 : loss [41.38452204]\n",
      "Epoch 73 : loss [40.77925113]\n",
      "Epoch 74 : loss [40.19524847]\n",
      "Epoch 75 : loss [39.63139469]\n",
      "Epoch 76 : loss [39.08664453]\n",
      "Epoch 77 : loss [38.5600214]\n",
      "Epoch 78 : loss [38.05061229]\n",
      "Epoch 79 : loss [37.5575631]\n",
      "Epoch 80 : loss [37.08007428]\n",
      "Epoch 81 : loss [36.61739678]\n",
      "Epoch 82 : loss [36.16882834]\n",
      "Epoch 83 : loss [35.73371009]\n",
      "Epoch 84 : loss [35.31142338]\n",
      "Epoch 85 : loss [34.90138683]\n",
      "Epoch 86 : loss [34.50305372]\n",
      "Epoch 87 : loss [34.11590949]\n",
      "Epoch 88 : loss [33.73946946]\n",
      "Epoch 89 : loss [33.37327676]\n",
      "Epoch 90 : loss [33.0169004]\n",
      "Epoch 91 : loss [32.66993348]\n",
      "Epoch 92 : loss [32.33199157]\n",
      "Epoch 93 : loss [32.00271119]\n",
      "Epoch 94 : loss [31.68174843]\n",
      "Epoch 95 : loss [31.36877763]\n",
      "Epoch 96 : loss [31.06349024]\n",
      "Epoch 97 : loss [30.76559367]\n",
      "Epoch 98 : loss [30.47481028]\n",
      "Epoch 99 : loss [30.19087649]\n",
      "Epoch 100 : loss [29.88994977]\n",
      "Epoch 101 : loss [29.60167114]\n",
      "Epoch 102 : loss [29.29946015]\n",
      "Epoch 103 : loss [29.0040124]\n",
      "Epoch 104 : loss [28.71596864]\n",
      "Epoch 105 : loss [28.43508122]\n",
      "Epoch 106 : loss [28.16107639]\n",
      "Epoch 107 : loss [27.89369286]\n",
      "Epoch 108 : loss [27.63268261]\n",
      "Epoch 109 : loss [27.37781021]\n",
      "Epoch 110 : loss [27.12885197]\n",
      "Epoch 111 : loss [26.88559523]\n",
      "Epoch 112 : loss [26.64783768]\n",
      "Epoch 113 : loss [26.41538674]\n",
      "Epoch 114 : loss [26.18805892]\n",
      "Epoch 115 : loss [25.96567935]\n",
      "Epoch 116 : loss [25.74808125]\n",
      "Epoch 117 : loss [25.53510542]\n",
      "Epoch 118 : loss [25.32659986]\n",
      "Epoch 119 : loss [25.12241934]\n",
      "Epoch 120 : loss [24.92242501]\n",
      "Epoch 121 : loss [24.72648407]\n",
      "Epoch 122 : loss [24.53446941]\n",
      "Epoch 123 : loss [24.34625933]\n",
      "Epoch 124 : loss [24.16173722]\n",
      "Epoch 125 : loss [23.98079134]\n",
      "Epoch 126 : loss [23.8033145]\n",
      "Epoch 127 : loss [23.62920388]\n",
      "Epoch 128 : loss [23.45836077]\n",
      "Epoch 129 : loss [23.29069038]\n",
      "Epoch 130 : loss [23.12610165]\n",
      "Epoch 131 : loss [22.96450705]\n",
      "Epoch 132 : loss [22.80582239]\n",
      "Epoch 133 : loss [22.64996671]\n",
      "Epoch 134 : loss [22.49686208]\n",
      "Epoch 135 : loss [22.34643348]\n",
      "Epoch 136 : loss [22.19860864]\n",
      "Epoch 137 : loss [22.05331793]\n",
      "Epoch 138 : loss [21.91049424]\n",
      "Epoch 139 : loss [21.77007286]\n",
      "Epoch 140 : loss [21.63199136]\n",
      "Epoch 141 : loss [21.49618951]\n",
      "Epoch 142 : loss [21.36260917]\n",
      "Epoch 143 : loss [21.23119418]\n",
      "Epoch 144 : loss [21.10189032]\n",
      "Epoch 145 : loss [20.97464519]\n",
      "Epoch 146 : loss [20.84940815]\n",
      "Epoch 147 : loss [20.72613021]\n",
      "Epoch 148 : loss [20.60476402]\n",
      "Epoch 149 : loss [20.48526376]\n",
      "Epoch 150 : loss [20.35572751]\n",
      "Epoch 151 : loss [20.23213775]\n",
      "Epoch 152 : loss [20.10177947]\n",
      "Epoch 153 : loss [19.97311273]\n",
      "Epoch 154 : loss [19.84658918]\n",
      "Epoch 155 : loss [19.72218264]\n",
      "Epoch 156 : loss [19.59983993]\n",
      "Epoch 157 : loss [19.47950809]\n",
      "Epoch 158 : loss [19.36113585]\n",
      "Epoch 159 : loss [19.24467375]\n",
      "Epoch 160 : loss [19.13007399]\n",
      "Epoch 161 : loss [19.0172904]\n",
      "Epoch 162 : loss [18.90627835]\n",
      "Epoch 163 : loss [18.79699469]\n",
      "Epoch 164 : loss [18.68939768]\n",
      "Epoch 165 : loss [18.58344695]\n",
      "Epoch 166 : loss [18.47910342]\n",
      "Epoch 167 : loss [18.37632927]\n",
      "Epoch 168 : loss [18.27508787]\n",
      "Epoch 169 : loss [18.17534373]\n",
      "Epoch 170 : loss [18.07706248]\n",
      "Epoch 171 : loss [17.9802108]\n",
      "Epoch 172 : loss [17.88475638]\n",
      "Epoch 173 : loss [17.7906679]\n",
      "Epoch 174 : loss [17.69791499]\n",
      "Epoch 175 : loss [17.60646817]\n",
      "Epoch 176 : loss [17.51629884]\n",
      "Epoch 177 : loss [17.42737922]\n",
      "Epoch 178 : loss [17.33968238]\n",
      "Epoch 179 : loss [17.25318212]\n",
      "Epoch 180 : loss [17.16785302]\n",
      "Epoch 181 : loss [17.08367038]\n",
      "Epoch 182 : loss [17.0006102]\n",
      "Epoch 183 : loss [16.91864913]\n",
      "Epoch 184 : loss [16.8377645]\n",
      "Epoch 185 : loss [16.75793424]\n",
      "Epoch 186 : loss [16.67913691]\n",
      "Epoch 187 : loss [16.60135162]\n",
      "Epoch 188 : loss [16.52455808]\n",
      "Epoch 189 : loss [16.44873652]\n",
      "Epoch 190 : loss [16.37386772]\n",
      "Epoch 191 : loss [16.29993293]\n",
      "Epoch 192 : loss [16.22691394]\n",
      "Epoch 193 : loss [16.15479298]\n",
      "Epoch 194 : loss [16.08355275]\n",
      "Epoch 195 : loss [16.01317641]\n",
      "Epoch 196 : loss [15.94364753]\n",
      "Epoch 197 : loss [15.8749501]\n",
      "Epoch 198 : loss [15.80706854]\n",
      "Epoch 199 : loss [15.73998762]\n",
      "Epoch 200 : loss [15.66603551]\n",
      "Epoch 201 : loss [15.59505517]\n",
      "Epoch 202 : loss [15.52103864]\n",
      "Epoch 203 : loss [15.44772295]\n",
      "Epoch 204 : loss [15.37534982]\n",
      "Epoch 205 : loss [15.30391754]\n",
      "Epoch 206 : loss [15.23340783]\n",
      "Epoch 207 : loss [15.16380178]\n",
      "Epoch 208 : loss [15.09508093]\n",
      "Epoch 209 : loss [15.02722736]\n",
      "Epoch 210 : loss [14.96022363]\n",
      "Epoch 211 : loss [14.8940528]\n",
      "Epoch 212 : loss [14.8286984]\n",
      "Epoch 213 : loss [14.76414439]\n",
      "Epoch 214 : loss [14.70037519]\n",
      "Epoch 215 : loss [14.6373756]\n",
      "Epoch 216 : loss [14.57513086]\n",
      "Epoch 217 : loss [14.51362656]\n",
      "Epoch 218 : loss [14.45284871]\n",
      "Epoch 219 : loss [14.39278364]\n",
      "Epoch 220 : loss [14.33341804]\n",
      "Epoch 221 : loss [14.27473896]\n",
      "Epoch 222 : loss [14.21673374]\n",
      "Epoch 223 : loss [14.15939007]\n",
      "Epoch 224 : loss [14.10269593]\n",
      "Epoch 225 : loss [14.04663958]\n",
      "Epoch 226 : loss [13.9912096]\n",
      "Epoch 227 : loss [13.93639483]\n",
      "Epoch 228 : loss [13.88218436]\n",
      "Epoch 229 : loss [13.82856758]\n",
      "Epoch 230 : loss [13.7755341]\n",
      "Epoch 231 : loss [13.7230738]\n",
      "Epoch 232 : loss [13.67117678]\n",
      "Epoch 233 : loss [13.61983337]\n",
      "Epoch 234 : loss [13.56903414]\n",
      "Epoch 235 : loss [13.51876985]\n",
      "Epoch 236 : loss [13.46903151]\n",
      "Epoch 237 : loss [13.4198103]\n",
      "Epoch 238 : loss [13.37109762]\n",
      "Epoch 239 : loss [13.32288505]\n",
      "Epoch 240 : loss [13.27516436]\n",
      "Epoch 241 : loss [13.22792751]\n",
      "Epoch 242 : loss [13.18116664]\n",
      "Epoch 243 : loss [13.13487405]\n",
      "Epoch 244 : loss [13.08904221]\n",
      "Epoch 245 : loss [13.04366376]\n",
      "Epoch 246 : loss [12.99873151]\n",
      "Epoch 247 : loss [12.95423839]\n",
      "Epoch 248 : loss [12.91017751]\n",
      "Epoch 249 : loss [12.86654212]\n",
      "Epoch 250 : loss [12.8180095]\n",
      "Epoch 251 : loss [12.77087166]\n",
      "Epoch 252 : loss [12.72237093]\n",
      "Epoch 253 : loss [12.67425102]\n",
      "Epoch 254 : loss [12.62664022]\n",
      "Epoch 255 : loss [12.57954002]\n",
      "Epoch 256 : loss [12.53294219]\n",
      "Epoch 257 : loss [12.48683792]\n",
      "Epoch 258 : loss [12.44121857]\n",
      "Epoch 259 : loss [12.39607575]\n",
      "Epoch 260 : loss [12.35140124]\n",
      "Epoch 261 : loss [12.30718706]\n",
      "Epoch 262 : loss [12.2634254]\n",
      "Epoch 263 : loss [12.22010868]\n",
      "Epoch 264 : loss [12.17722945]\n",
      "Epoch 265 : loss [12.13478049]\n",
      "Epoch 266 : loss [12.09275472]\n",
      "Epoch 267 : loss [12.05114523]\n",
      "Epoch 268 : loss [12.00994527]\n",
      "Epoch 269 : loss [11.96914825]\n",
      "Epoch 270 : loss [11.92874773]\n",
      "Epoch 271 : loss [11.88873741]\n",
      "Epoch 272 : loss [11.84911112]\n",
      "Epoch 273 : loss [11.80986284]\n",
      "Epoch 274 : loss [11.77098668]\n",
      "Epoch 275 : loss [11.73247688]\n",
      "Epoch 276 : loss [11.6943278]\n",
      "Epoch 277 : loss [11.65653392]\n",
      "Epoch 278 : loss [11.61908983]\n",
      "Epoch 279 : loss [11.58199025]\n",
      "Epoch 280 : loss [11.54522999]\n",
      "Epoch 281 : loss [11.508804]\n",
      "Epoch 282 : loss [11.4727073]\n",
      "Epoch 283 : loss [11.43693502]\n",
      "Epoch 284 : loss [11.40148241]\n",
      "Epoch 285 : loss [11.3663448]\n",
      "Epoch 286 : loss [11.3315176]\n",
      "Epoch 287 : loss [11.29699634]\n",
      "Epoch 288 : loss [11.26277663]\n",
      "Epoch 289 : loss [11.22885415]\n",
      "Epoch 290 : loss [11.19522468]\n",
      "Epoch 291 : loss [11.16188408]\n",
      "Epoch 292 : loss [11.1288283]\n",
      "Epoch 293 : loss [11.09605335]\n",
      "Epoch 294 : loss [11.06355533]\n",
      "Epoch 295 : loss [11.0313304]\n",
      "Epoch 296 : loss [10.99937481]\n",
      "Epoch 297 : loss [10.96768487]\n",
      "Epoch 298 : loss [10.93625697]\n",
      "Epoch 299 : loss [10.90508755]\n",
      "Epoch 300 : loss [10.87038697]\n",
      "Epoch 301 : loss [10.83615918]\n",
      "Epoch 302 : loss [10.80133368]\n",
      "Epoch 303 : loss [10.76675318]\n",
      "Epoch 304 : loss [10.73248626]\n",
      "Epoch 305 : loss [10.69853423]\n",
      "Epoch 306 : loss [10.66489266]\n",
      "Epoch 307 : loss [10.63155677]\n",
      "Epoch 308 : loss [10.59852182]\n",
      "Epoch 309 : loss [10.5657832]\n",
      "Epoch 310 : loss [10.53333641]\n",
      "Epoch 311 : loss [10.50117705]\n",
      "Epoch 312 : loss [10.46930083]\n",
      "Epoch 313 : loss [10.43770355]\n",
      "Epoch 314 : loss [10.40638112]\n",
      "Epoch 315 : loss [10.37532951]\n",
      "Epoch 316 : loss [10.34454481]\n",
      "Epoch 317 : loss [10.31402318]\n",
      "Epoch 318 : loss [10.28376087]\n",
      "Epoch 319 : loss [10.25375419]\n",
      "Epoch 320 : loss [10.22399954]\n",
      "Epoch 321 : loss [10.19449341]\n",
      "Epoch 322 : loss [10.16523232]\n",
      "Epoch 323 : loss [10.1362129]\n",
      "Epoch 324 : loss [10.10743183]\n",
      "Epoch 325 : loss [10.07888585]\n",
      "Epoch 326 : loss [10.05057178]\n",
      "Epoch 327 : loss [10.02248649]\n",
      "Epoch 328 : loss [9.9946269]\n",
      "Epoch 329 : loss [9.96699002]\n",
      "Epoch 330 : loss [9.93957289]\n",
      "Epoch 331 : loss [9.91237261]\n",
      "Epoch 332 : loss [9.88538634]\n",
      "Epoch 333 : loss [9.8586113]\n",
      "Epoch 334 : loss [9.83204473]\n",
      "Epoch 335 : loss [9.80568397]\n",
      "Epoch 336 : loss [9.77952635]\n",
      "Epoch 337 : loss [9.7535693]\n",
      "Epoch 338 : loss [9.72781027]\n",
      "Epoch 339 : loss [9.70224675]\n",
      "Epoch 340 : loss [9.6768763]\n",
      "Epoch 341 : loss [9.65169649]\n",
      "Epoch 342 : loss [9.62670496]\n",
      "Epoch 343 : loss [9.60189938]\n",
      "Epoch 344 : loss [9.57727745]\n",
      "Epoch 345 : loss [9.55283693]\n",
      "Epoch 346 : loss [9.52857561]\n",
      "Epoch 347 : loss [9.50449131]\n",
      "Epoch 348 : loss [9.4805819]\n",
      "Epoch 349 : loss [9.45684527]\n",
      "Epoch 350 : loss [9.43056064]\n",
      "Epoch 351 : loss [9.40417845]\n",
      "Epoch 352 : loss [9.37755651]\n",
      "Epoch 353 : loss [9.35111022]\n",
      "Epoch 354 : loss [9.32487618]\n",
      "Epoch 355 : loss [9.29885505]\n",
      "Epoch 356 : loss [9.27304413]\n",
      "Epoch 357 : loss [9.2474405]\n",
      "Epoch 358 : loss [9.22204126]\n",
      "Epoch 359 : loss [9.19684358]\n",
      "Epoch 360 : loss [9.1718447]\n",
      "Epoch 361 : loss [9.14704193]\n",
      "Epoch 362 : loss [9.12243261]\n",
      "Epoch 363 : loss [9.09801418]\n",
      "Epoch 364 : loss [9.07378411]\n",
      "Epoch 365 : loss [9.04973991]\n",
      "Epoch 366 : loss [9.02587918]\n",
      "Epoch 367 : loss [9.00219952]\n",
      "Epoch 368 : loss [8.97869863]\n",
      "Epoch 369 : loss [8.95537422]\n",
      "Epoch 370 : loss [8.93222405]\n",
      "Epoch 371 : loss [8.90924594]\n",
      "Epoch 372 : loss [8.88643772]\n",
      "Epoch 373 : loss [8.8637973]\n",
      "Epoch 374 : loss [8.84132259]\n",
      "Epoch 375 : loss [8.81901157]\n",
      "Epoch 376 : loss [8.79686223]\n",
      "Epoch 377 : loss [8.77487262]\n",
      "Epoch 378 : loss [8.75304082]\n",
      "Epoch 379 : loss [8.73136492]\n",
      "Epoch 380 : loss [8.70984306]\n",
      "Epoch 381 : loss [8.68847343]\n",
      "Epoch 382 : loss [8.66725423]\n",
      "Epoch 383 : loss [8.64618368]\n",
      "Epoch 384 : loss [8.62526006]\n",
      "Epoch 385 : loss [8.60448165]\n",
      "Epoch 386 : loss [8.58384679]\n",
      "Epoch 387 : loss [8.56335381]\n",
      "Epoch 388 : loss [8.54300111]\n",
      "Epoch 389 : loss [8.52278707]\n",
      "Epoch 390 : loss [8.50271013]\n",
      "Epoch 391 : loss [8.48276874]\n",
      "Epoch 392 : loss [8.46296138]\n",
      "Epoch 393 : loss [8.44328656]\n",
      "Epoch 394 : loss [8.4237428]\n",
      "Epoch 395 : loss [8.40432865]\n",
      "Epoch 396 : loss [8.38504269]\n",
      "Epoch 397 : loss [8.36588351]\n",
      "Epoch 398 : loss [8.34684972]\n",
      "Epoch 399 : loss [8.32793997]\n",
      "Epoch 400 : loss [8.30720453]\n",
      "Epoch 401 : loss [8.28600705]\n",
      "Epoch 402 : loss [8.26473895]\n",
      "Epoch 403 : loss [8.24360575]\n",
      "Epoch 404 : loss [8.22262664]\n",
      "Epoch 405 : loss [8.20180172]\n",
      "Epoch 406 : loss [8.18112919]\n",
      "Epoch 407 : loss [8.16060709]\n",
      "Epoch 408 : loss [8.14023348]\n",
      "Epoch 409 : loss [8.1200065]\n",
      "Epoch 410 : loss [8.09992428]\n",
      "Epoch 411 : loss [8.07998502]\n",
      "Epoch 412 : loss [8.06018697]\n",
      "Epoch 413 : loss [8.04052839]\n",
      "Epoch 414 : loss [8.02100759]\n",
      "Epoch 415 : loss [8.00162291]\n",
      "Epoch 416 : loss [7.98237273]\n",
      "Epoch 417 : loss [7.96325545]\n",
      "Epoch 418 : loss [7.94426951]\n",
      "Epoch 419 : loss [7.92541338]\n",
      "Epoch 420 : loss [7.90668554]\n",
      "Epoch 421 : loss [7.88808453]\n",
      "Epoch 422 : loss [7.86960889]\n",
      "Epoch 423 : loss [7.85125719]\n",
      "Epoch 424 : loss [7.83302804]\n",
      "Epoch 425 : loss [7.81492005]\n",
      "Epoch 426 : loss [7.79693187]\n",
      "Epoch 427 : loss [7.77906217]\n",
      "Epoch 428 : loss [7.76130965]\n",
      "Epoch 429 : loss [7.743673]\n",
      "Epoch 430 : loss [7.72615098]\n",
      "Epoch 431 : loss [7.70874233]\n",
      "Epoch 432 : loss [7.69144583]\n",
      "Epoch 433 : loss [7.67426026]\n",
      "Epoch 434 : loss [7.65718445]\n",
      "Epoch 435 : loss [7.64021723]\n",
      "Epoch 436 : loss [7.62335743]\n",
      "Epoch 437 : loss [7.60660394]\n",
      "Epoch 438 : loss [7.58995563]\n",
      "Epoch 439 : loss [7.57341141]\n",
      "Epoch 440 : loss [7.55697019]\n",
      "Epoch 441 : loss [7.5406309]\n",
      "Epoch 442 : loss [7.5243925]\n",
      "Epoch 443 : loss [7.50825396]\n",
      "Epoch 444 : loss [7.49221424]\n",
      "Epoch 445 : loss [7.47627235]\n",
      "Epoch 446 : loss [7.4604273]\n",
      "Epoch 447 : loss [7.4446781]\n",
      "Epoch 448 : loss [7.42902381]\n",
      "Epoch 449 : loss [7.41346346]\n",
      "Epoch 450 : loss [7.39661553]\n",
      "Epoch 451 : loss [7.37906933]\n",
      "Epoch 452 : loss [7.36153148]\n",
      "Epoch 453 : loss [7.34410188]\n",
      "Epoch 454 : loss [7.32679015]\n",
      "Epoch 455 : loss [7.30959603]\n",
      "Epoch 456 : loss [7.29251819]\n",
      "Epoch 457 : loss [7.27555524]\n",
      "Epoch 458 : loss [7.25870582]\n",
      "Epoch 459 : loss [7.24196856]\n",
      "Epoch 460 : loss [7.22534216]\n",
      "Epoch 461 : loss [7.20882533]\n",
      "Epoch 462 : loss [7.19241681]\n",
      "Epoch 463 : loss [7.17611536]\n",
      "Epoch 464 : loss [7.15991977]\n",
      "Epoch 465 : loss [7.14382886]\n",
      "Epoch 466 : loss [7.12784146]\n",
      "Epoch 467 : loss [7.11195644]\n",
      "Epoch 468 : loss [7.09617266]\n",
      "Epoch 469 : loss [7.08048903]\n",
      "Epoch 470 : loss [7.06490447]\n",
      "Epoch 471 : loss [7.04941792]\n",
      "Epoch 472 : loss [7.03402833]\n",
      "Epoch 473 : loss [7.01873468]\n",
      "Epoch 474 : loss [7.00353595]\n",
      "Epoch 475 : loss [6.98843115]\n",
      "Epoch 476 : loss [6.97341931]\n",
      "Epoch 477 : loss [6.95849947]\n",
      "Epoch 478 : loss [6.94367068]\n",
      "Epoch 479 : loss [6.928932]\n",
      "Epoch 480 : loss [6.91428253]\n",
      "Epoch 481 : loss [6.89972136]\n",
      "Epoch 482 : loss [6.88524759]\n",
      "Epoch 483 : loss [6.87086036]\n",
      "Epoch 484 : loss [6.8565588]\n",
      "Epoch 485 : loss [6.84234207]\n",
      "Epoch 486 : loss [6.82820931]\n",
      "Epoch 487 : loss [6.81415972]\n",
      "Epoch 488 : loss [6.80019246]\n",
      "Epoch 489 : loss [6.78630675]\n",
      "Epoch 490 : loss [6.7725018]\n",
      "Epoch 491 : loss [6.75877681]\n",
      "Epoch 492 : loss [6.74513103]\n",
      "Epoch 493 : loss [6.73156369]\n",
      "Epoch 494 : loss [6.71807405]\n",
      "Epoch 495 : loss [6.70466136]\n",
      "Epoch 496 : loss [6.69132491]\n",
      "Epoch 497 : loss [6.67806398]\n",
      "Epoch 498 : loss [6.66487785]\n",
      "Epoch 499 : loss [6.65176583]\n",
      "Epoch 500 : loss [6.63777132]\n",
      "Epoch 501 : loss [6.62292601]\n",
      "Epoch 502 : loss [6.60812403]\n",
      "Epoch 503 : loss [6.59341145]\n",
      "Epoch 504 : loss [6.57879263]\n",
      "Epoch 505 : loss [6.56426708]\n",
      "Epoch 506 : loss [6.54983378]\n",
      "Epoch 507 : loss [6.5354917]\n",
      "Epoch 508 : loss [6.5212398]\n",
      "Epoch 509 : loss [6.50707706]\n",
      "Epoch 510 : loss [6.4930025]\n",
      "Epoch 511 : loss [6.47901515]\n",
      "Epoch 512 : loss [6.46511405]\n",
      "Epoch 513 : loss [6.4512983]\n",
      "Epoch 514 : loss [6.43756696]\n",
      "Epoch 515 : loss [6.42391916]\n",
      "Epoch 516 : loss [6.410354]\n",
      "Epoch 517 : loss [6.39687064]\n",
      "Epoch 518 : loss [6.38346822]\n",
      "Epoch 519 : loss [6.37014593]\n",
      "Epoch 520 : loss [6.35690293]\n",
      "Epoch 521 : loss [6.34373843]\n",
      "Epoch 522 : loss [6.33065164]\n",
      "Epoch 523 : loss [6.31764178]\n",
      "Epoch 524 : loss [6.30470809]\n",
      "Epoch 525 : loss [6.29184982]\n",
      "Epoch 526 : loss [6.27906623]\n",
      "Epoch 527 : loss [6.26635658]\n",
      "Epoch 528 : loss [6.25372017]\n",
      "Epoch 529 : loss [6.24115628]\n",
      "Epoch 530 : loss [6.22866422]\n",
      "Epoch 531 : loss [6.2162433]\n",
      "Epoch 532 : loss [6.20389285]\n",
      "Epoch 533 : loss [6.1916122]\n",
      "Epoch 534 : loss [6.17940069]\n",
      "Epoch 535 : loss [6.16725767]\n",
      "Epoch 536 : loss [6.15518251]\n",
      "Epoch 537 : loss [6.14317458]\n",
      "Epoch 538 : loss [6.13123325]\n",
      "Epoch 539 : loss [6.11935791]\n",
      "Epoch 540 : loss [6.10754796]\n",
      "Epoch 541 : loss [6.09580279]\n",
      "Epoch 542 : loss [6.08412183]\n",
      "Epoch 543 : loss [6.07250449]\n",
      "Epoch 544 : loss [6.06095019]\n",
      "Epoch 545 : loss [6.04945838]\n",
      "Epoch 546 : loss [6.03802848]\n",
      "Epoch 547 : loss [6.02665996]\n",
      "Epoch 548 : loss [6.01535226]\n",
      "Epoch 549 : loss [6.00410485]\n",
      "Epoch 550 : loss [5.99228235]\n",
      "Epoch 551 : loss [5.97951316]\n",
      "Epoch 552 : loss [5.96680053]\n",
      "Epoch 553 : loss [5.95416318]\n",
      "Epoch 554 : loss [5.94160262]\n",
      "Epoch 555 : loss [5.92911828]\n",
      "Epoch 556 : loss [5.91670933]\n",
      "Epoch 557 : loss [5.90437495]\n",
      "Epoch 558 : loss [5.89211434]\n",
      "Epoch 559 : loss [5.8799267]\n",
      "Epoch 560 : loss [5.86781126]\n",
      "Epoch 561 : loss [5.85576727]\n",
      "Epoch 562 : loss [5.84379397]\n",
      "Epoch 563 : loss [5.83189066]\n",
      "Epoch 564 : loss [5.8200566]\n",
      "Epoch 565 : loss [5.80829111]\n",
      "Epoch 566 : loss [5.79659349]\n",
      "Epoch 567 : loss [5.78496307]\n",
      "Epoch 568 : loss [5.77339918]\n",
      "Epoch 569 : loss [5.76190119]\n",
      "Epoch 570 : loss [5.75046843]\n",
      "Epoch 571 : loss [5.7391003]\n",
      "Epoch 572 : loss [5.72779616]\n",
      "Epoch 573 : loss [5.7165554]\n",
      "Epoch 574 : loss [5.70537744]\n",
      "Epoch 575 : loss [5.69426166]\n",
      "Epoch 576 : loss [5.6832075]\n",
      "Epoch 577 : loss [5.67221437]\n",
      "Epoch 578 : loss [5.66128172]\n",
      "Epoch 579 : loss [5.65040898]\n",
      "Epoch 580 : loss [5.63959561]\n",
      "Epoch 581 : loss [5.62884107]\n",
      "Epoch 582 : loss [5.61814481]\n",
      "Epoch 583 : loss [5.60750633]\n",
      "Epoch 584 : loss [5.59692508]\n",
      "Epoch 585 : loss [5.58640057]\n",
      "Epoch 586 : loss [5.57593229]\n",
      "Epoch 587 : loss [5.56551974]\n",
      "Epoch 588 : loss [5.55516243]\n",
      "Epoch 589 : loss [5.54485987]\n",
      "Epoch 590 : loss [5.53461159]\n",
      "Epoch 591 : loss [5.5244171]\n",
      "Epoch 592 : loss [5.51427594]\n",
      "Epoch 593 : loss [5.50418766]\n",
      "Epoch 594 : loss [5.49415179]\n",
      "Epoch 595 : loss [5.48416789]\n",
      "Epoch 596 : loss [5.47423551]\n",
      "Epoch 597 : loss [5.46435422]\n",
      "Epoch 598 : loss [5.45452357]\n",
      "Epoch 599 : loss [5.44474315]\n",
      "Epoch 600 : loss [5.43462223]\n",
      "Epoch 601 : loss [5.42349812]\n",
      "Epoch 602 : loss [5.412433]\n",
      "Epoch 603 : loss [5.40143216]\n",
      "Epoch 604 : loss [5.39049563]\n",
      "Epoch 605 : loss [5.37962281]\n",
      "Epoch 606 : loss [5.36881302]\n",
      "Epoch 607 : loss [5.35806561]\n",
      "Epoch 608 : loss [5.34737991]\n",
      "Epoch 609 : loss [5.33675529]\n",
      "Epoch 610 : loss [5.32619112]\n",
      "Epoch 611 : loss [5.3156868]\n",
      "Epoch 612 : loss [5.30524172]\n",
      "Epoch 613 : loss [5.29485529]\n",
      "Epoch 614 : loss [5.28452695]\n",
      "Epoch 615 : loss [5.27425612]\n",
      "Epoch 616 : loss [5.26404225]\n",
      "Epoch 617 : loss [5.25388479]\n",
      "Epoch 618 : loss [5.24378322]\n",
      "Epoch 619 : loss [5.23373699]\n",
      "Epoch 620 : loss [5.2237456]\n",
      "Epoch 621 : loss [5.21380853]\n",
      "Epoch 622 : loss [5.20392528]\n",
      "Epoch 623 : loss [5.19409536]\n",
      "Epoch 624 : loss [5.18431827]\n",
      "Epoch 625 : loss [5.17459355]\n",
      "Epoch 626 : loss [5.16492072]\n",
      "Epoch 627 : loss [5.15529932]\n",
      "Epoch 628 : loss [5.14572888]\n",
      "Epoch 629 : loss [5.13620895]\n",
      "Epoch 630 : loss [5.12673909]\n",
      "Epoch 631 : loss [5.11731886]\n",
      "Epoch 632 : loss [5.10794782]\n",
      "Epoch 633 : loss [5.09862555]\n",
      "Epoch 634 : loss [5.08935162]\n",
      "Epoch 635 : loss [5.08012562]\n",
      "Epoch 636 : loss [5.07094714]\n",
      "Epoch 637 : loss [5.06181576]\n",
      "Epoch 638 : loss [5.0527311]\n",
      "Epoch 639 : loss [5.04369275]\n",
      "Epoch 640 : loss [5.03470032]\n",
      "Epoch 641 : loss [5.02575344]\n",
      "Epoch 642 : loss [5.0168517]\n",
      "Epoch 643 : loss [5.00799475]\n",
      "Epoch 644 : loss [4.99918221]\n",
      "Epoch 645 : loss [4.99041371]\n",
      "Epoch 646 : loss [4.98168888]\n",
      "Epoch 647 : loss [4.97300738]\n",
      "Epoch 648 : loss [4.96436884]\n",
      "Epoch 649 : loss [4.95577291]\n",
      "Epoch 650 : loss [4.94701616]\n",
      "Epoch 651 : loss [4.93722765]\n",
      "Epoch 652 : loss [4.92749529]\n",
      "Epoch 653 : loss [4.91781833]\n",
      "Epoch 654 : loss [4.90819618]\n",
      "Epoch 655 : loss [4.89862824]\n",
      "Epoch 656 : loss [4.88911394]\n",
      "Epoch 657 : loss [4.87965274]\n",
      "Epoch 658 : loss [4.8702441]\n",
      "Epoch 659 : loss [4.86088748]\n",
      "Epoch 660 : loss [4.85158237]\n",
      "Epoch 661 : loss [4.84232826]\n",
      "Epoch 662 : loss [4.83312466]\n",
      "Epoch 663 : loss [4.82397108]\n",
      "Epoch 664 : loss [4.81486705]\n",
      "Epoch 665 : loss [4.80581209]\n",
      "Epoch 666 : loss [4.79680575]\n",
      "Epoch 667 : loss [4.78784757]\n",
      "Epoch 668 : loss [4.77893711]\n",
      "Epoch 669 : loss [4.77007394]\n",
      "Epoch 670 : loss [4.76125762]\n",
      "Epoch 671 : loss [4.75248773]\n",
      "Epoch 672 : loss [4.74376386]\n",
      "Epoch 673 : loss [4.73508559]\n",
      "Epoch 674 : loss [4.72645253]\n",
      "Epoch 675 : loss [4.71786427]\n",
      "Epoch 676 : loss [4.70932042]\n",
      "Epoch 677 : loss [4.7008206]\n",
      "Epoch 678 : loss [4.69236442]\n",
      "Epoch 679 : loss [4.68395152]\n",
      "Epoch 680 : loss [4.67558151]\n",
      "Epoch 681 : loss [4.66725404]\n",
      "Epoch 682 : loss [4.65896875]\n",
      "Epoch 683 : loss [4.65072527]\n",
      "Epoch 684 : loss [4.64252325]\n",
      "Epoch 685 : loss [4.63436236]\n",
      "Epoch 686 : loss [4.62624225]\n",
      "Epoch 687 : loss [4.61816257]\n",
      "Epoch 688 : loss [4.61012301]\n",
      "Epoch 689 : loss [4.60212322]\n",
      "Epoch 690 : loss [4.59416288]\n",
      "Epoch 691 : loss [4.58624167]\n",
      "Epoch 692 : loss [4.57835927]\n",
      "Epoch 693 : loss [4.57051537]\n",
      "Epoch 694 : loss [4.56270966]\n",
      "Epoch 695 : loss [4.55494182]\n",
      "Epoch 696 : loss [4.54721157]\n",
      "Epoch 697 : loss [4.5395186]\n",
      "Epoch 698 : loss [4.53186261]\n",
      "Epoch 699 : loss [4.5242433]\n",
      "Epoch 700 : loss [4.51660094]\n",
      "Epoch 701 : loss [4.50791835]\n",
      "Epoch 702 : loss [4.49928655]\n",
      "Epoch 703 : loss [4.49070288]\n",
      "Epoch 704 : loss [4.48216652]\n",
      "Epoch 705 : loss [4.47367695]\n",
      "Epoch 706 : loss [4.46523368]\n",
      "Epoch 707 : loss [4.45683625]\n",
      "Epoch 708 : loss [4.44848419]\n",
      "Epoch 709 : loss [4.44017708]\n",
      "Epoch 710 : loss [4.43191446]\n",
      "Epoch 711 : loss [4.42369591]\n",
      "Epoch 712 : loss [4.41552102]\n",
      "Epoch 713 : loss [4.40738937]\n",
      "Epoch 714 : loss [4.39930056]\n",
      "Epoch 715 : loss [4.39125419]\n",
      "Epoch 716 : loss [4.38324988]\n",
      "Epoch 717 : loss [4.37528725]\n",
      "Epoch 718 : loss [4.36736591]\n",
      "Epoch 719 : loss [4.35948551]\n",
      "Epoch 720 : loss [4.35164568]\n",
      "Epoch 721 : loss [4.34384605]\n",
      "Epoch 722 : loss [4.33608629]\n",
      "Epoch 723 : loss [4.32836604]\n",
      "Epoch 724 : loss [4.32068496]\n",
      "Epoch 725 : loss [4.31304272]\n",
      "Epoch 726 : loss [4.30543898]\n",
      "Epoch 727 : loss [4.29787342]\n",
      "Epoch 728 : loss [4.29034572]\n",
      "Epoch 729 : loss [4.28285555]\n",
      "Epoch 730 : loss [4.27540262]\n",
      "Epoch 731 : loss [4.26798659]\n",
      "Epoch 732 : loss [4.26060718]\n",
      "Epoch 733 : loss [4.25326408]\n",
      "Epoch 734 : loss [4.24595699]\n",
      "Epoch 735 : loss [4.23868561]\n",
      "Epoch 736 : loss [4.23144967]\n",
      "Epoch 737 : loss [4.22424887]\n",
      "Epoch 738 : loss [4.21708293]\n",
      "Epoch 739 : loss [4.20995156]\n",
      "Epoch 740 : loss [4.2028545]\n",
      "Epoch 741 : loss [4.19579148]\n",
      "Epoch 742 : loss [4.18876221]\n",
      "Epoch 743 : loss [4.18176644]\n",
      "Epoch 744 : loss [4.1748039]\n",
      "Epoch 745 : loss [4.16787433]\n",
      "Epoch 746 : loss [4.16097747]\n",
      "Epoch 747 : loss [4.15411308]\n",
      "Epoch 748 : loss [4.14728089]\n",
      "Epoch 749 : loss [4.14048067]\n",
      "Epoch 750 : loss [4.13376286]\n",
      "Epoch 751 : loss [4.12601091]\n",
      "Epoch 752 : loss [4.11830336]\n",
      "Epoch 753 : loss [4.1106378]\n",
      "Epoch 754 : loss [4.10301353]\n",
      "Epoch 755 : loss [4.09543009]\n",
      "Epoch 756 : loss [4.08788708]\n",
      "Epoch 757 : loss [4.08038409]\n",
      "Epoch 758 : loss [4.07292072]\n",
      "Epoch 759 : loss [4.0654966]\n",
      "Epoch 760 : loss [4.05811135]\n",
      "Epoch 761 : loss [4.0507646]\n",
      "Epoch 762 : loss [4.04345601]\n",
      "Epoch 763 : loss [4.0361852]\n",
      "Epoch 764 : loss [4.02895185]\n",
      "Epoch 765 : loss [4.0217556]\n",
      "Epoch 766 : loss [4.01459614]\n",
      "Epoch 767 : loss [4.00747312]\n",
      "Epoch 768 : loss [4.00038624]\n",
      "Epoch 769 : loss [3.99333516]\n",
      "Epoch 770 : loss [3.98631959]\n",
      "Epoch 771 : loss [3.97933921]\n",
      "Epoch 772 : loss [3.97239373]\n",
      "Epoch 773 : loss [3.96548284]\n",
      "Epoch 774 : loss [3.95860625]\n",
      "Epoch 775 : loss [3.95176369]\n",
      "Epoch 776 : loss [3.94495485]\n",
      "Epoch 777 : loss [3.93817946]\n",
      "Epoch 778 : loss [3.93143725]\n",
      "Epoch 779 : loss [3.92472794]\n",
      "Epoch 780 : loss [3.91805126]\n",
      "Epoch 781 : loss [3.91140694]\n",
      "Epoch 782 : loss [3.90479474]\n",
      "Epoch 783 : loss [3.89821437]\n",
      "Epoch 784 : loss [3.8916656]\n",
      "Epoch 785 : loss [3.88514817]\n",
      "Epoch 786 : loss [3.87866182]\n",
      "Epoch 787 : loss [3.87220632]\n",
      "Epoch 788 : loss [3.86578141]\n",
      "Epoch 789 : loss [3.85938687]\n",
      "Epoch 790 : loss [3.85302245]\n",
      "Epoch 791 : loss [3.84668791]\n",
      "Epoch 792 : loss [3.84038303]\n",
      "Epoch 793 : loss [3.83410757]\n",
      "Epoch 794 : loss [3.82786132]\n",
      "Epoch 795 : loss [3.82164403]\n",
      "Epoch 796 : loss [3.8154555]\n",
      "Epoch 797 : loss [3.80929551]\n",
      "Epoch 798 : loss [3.80316383]\n",
      "Epoch 799 : loss [3.79706026]\n",
      "Epoch 800 : loss [3.79111952]\n",
      "Epoch 801 : loss [3.7841613]\n",
      "Epoch 802 : loss [3.77724072]\n",
      "Epoch 803 : loss [3.77035693]\n",
      "Epoch 804 : loss [3.76350947]\n",
      "Epoch 805 : loss [3.75669798]\n",
      "Epoch 806 : loss [3.74992211]\n",
      "Epoch 807 : loss [3.74318149]\n",
      "Epoch 808 : loss [3.73647579]\n",
      "Epoch 809 : loss [3.72980469]\n",
      "Epoch 810 : loss [3.72316784]\n",
      "Epoch 811 : loss [3.71656495]\n",
      "Epoch 812 : loss [3.70999569]\n",
      "Epoch 813 : loss [3.70345976]\n",
      "Epoch 814 : loss [3.69695686]\n",
      "Epoch 815 : loss [3.69048669]\n",
      "Epoch 816 : loss [3.68404897]\n",
      "Epoch 817 : loss [3.67764341]\n",
      "Epoch 818 : loss [3.67126974]\n",
      "Epoch 819 : loss [3.66492767]\n",
      "Epoch 820 : loss [3.65861695]\n",
      "Epoch 821 : loss [3.65233729]\n",
      "Epoch 822 : loss [3.64608845]\n",
      "Epoch 823 : loss [3.63987015]\n",
      "Epoch 824 : loss [3.63368216]\n",
      "Epoch 825 : loss [3.62752421]\n",
      "Epoch 826 : loss [3.62139606]\n",
      "Epoch 827 : loss [3.61529747]\n",
      "Epoch 828 : loss [3.6092282]\n",
      "Epoch 829 : loss [3.60318801]\n",
      "Epoch 830 : loss [3.59717666]\n",
      "Epoch 831 : loss [3.59119392]\n",
      "Epoch 832 : loss [3.58523958]\n",
      "Epoch 833 : loss [3.5793134]\n",
      "Epoch 834 : loss [3.57341515]\n",
      "Epoch 835 : loss [3.56754463]\n",
      "Epoch 836 : loss [3.56170161]\n",
      "Epoch 837 : loss [3.55588588]\n",
      "Epoch 838 : loss [3.55009723]\n",
      "Epoch 839 : loss [3.54433545]\n",
      "Epoch 840 : loss [3.53860033]\n",
      "Epoch 841 : loss [3.53289167]\n",
      "Epoch 842 : loss [3.52720927]\n",
      "Epoch 843 : loss [3.52155292]\n",
      "Epoch 844 : loss [3.51592244]\n",
      "Epoch 845 : loss [3.51031762]\n",
      "Epoch 846 : loss [3.50473827]\n",
      "Epoch 847 : loss [3.4991842]\n",
      "Epoch 848 : loss [3.49365522]\n",
      "Epoch 849 : loss [3.48815115]\n",
      "Epoch 850 : loss [3.48287068]\n",
      "Epoch 851 : loss [3.47659707]\n",
      "Epoch 852 : loss [3.47035439]\n",
      "Epoch 853 : loss [3.46414398]\n",
      "Epoch 854 : loss [3.45796577]\n",
      "Epoch 855 : loss [3.45181948]\n",
      "Epoch 856 : loss [3.4457048]\n",
      "Epoch 857 : loss [3.43962143]\n",
      "Epoch 858 : loss [3.43356906]\n",
      "Epoch 859 : loss [3.4275474]\n",
      "Epoch 860 : loss [3.42155618]\n",
      "Epoch 861 : loss [3.41559511]\n",
      "Epoch 862 : loss [3.40966391]\n",
      "Epoch 863 : loss [3.40376232]\n",
      "Epoch 864 : loss [3.39789008]\n",
      "Epoch 865 : loss [3.39204693]\n",
      "Epoch 866 : loss [3.38623261]\n",
      "Epoch 867 : loss [3.38044688]\n",
      "Epoch 868 : loss [3.37468949]\n",
      "Epoch 869 : loss [3.3689602]\n",
      "Epoch 870 : loss [3.36325877]\n",
      "Epoch 871 : loss [3.35758497]\n",
      "Epoch 872 : loss [3.35193856]\n",
      "Epoch 873 : loss [3.34631933]\n",
      "Epoch 874 : loss [3.34072705]\n",
      "Epoch 875 : loss [3.3351615]\n",
      "Epoch 876 : loss [3.32962247]\n",
      "Epoch 877 : loss [3.32410973]\n",
      "Epoch 878 : loss [3.31862308]\n",
      "Epoch 879 : loss [3.31316232]\n",
      "Epoch 880 : loss [3.30772723]\n",
      "Epoch 881 : loss [3.30231761]\n",
      "Epoch 882 : loss [3.29693326]\n",
      "Epoch 883 : loss [3.29157399]\n",
      "Epoch 884 : loss [3.2862396]\n",
      "Epoch 885 : loss [3.2809299]\n",
      "Epoch 886 : loss [3.2756447]\n",
      "Epoch 887 : loss [3.27038381]\n",
      "Epoch 888 : loss [3.26514704]\n",
      "Epoch 889 : loss [3.25993421]\n",
      "Epoch 890 : loss [3.25474514]\n",
      "Epoch 891 : loss [3.24957965]\n",
      "Epoch 892 : loss [3.24443756]\n",
      "Epoch 893 : loss [3.2393187]\n",
      "Epoch 894 : loss [3.2342229]\n",
      "Epoch 895 : loss [3.22914997]\n",
      "Epoch 896 : loss [3.22409976]\n",
      "Epoch 897 : loss [3.21907209]\n",
      "Epoch 898 : loss [3.2140668]\n",
      "Epoch 899 : loss [3.20908373]\n",
      "Epoch 900 : loss [3.20436957]\n",
      "Epoch 901 : loss [3.1986921]\n",
      "Epoch 902 : loss [3.19303904]\n",
      "Epoch 903 : loss [3.18741432]\n",
      "Epoch 904 : loss [3.18181829]\n",
      "Epoch 905 : loss [3.17625077]\n",
      "Epoch 906 : loss [3.17071148]\n",
      "Epoch 907 : loss [3.16520016]\n",
      "Epoch 908 : loss [3.15971654]\n",
      "Epoch 909 : loss [3.15426037]\n",
      "Epoch 910 : loss [3.14883139]\n",
      "Epoch 911 : loss [3.14342936]\n",
      "Epoch 912 : loss [3.13805403]\n",
      "Epoch 913 : loss [3.13270517]\n",
      "Epoch 914 : loss [3.12738254]\n",
      "Epoch 915 : loss [3.12208592]\n",
      "Epoch 916 : loss [3.11681507]\n",
      "Epoch 917 : loss [3.11156979]\n",
      "Epoch 918 : loss [3.10634986]\n",
      "Epoch 919 : loss [3.10115505]\n",
      "Epoch 920 : loss [3.09598516]\n",
      "Epoch 921 : loss [3.09083999]\n",
      "Epoch 922 : loss [3.08571933]\n",
      "Epoch 923 : loss [3.08062298]\n",
      "Epoch 924 : loss [3.07555074]\n",
      "Epoch 925 : loss [3.07050242]\n",
      "Epoch 926 : loss [3.06547783]\n",
      "Epoch 927 : loss [3.06047678]\n",
      "Epoch 928 : loss [3.05549908]\n",
      "Epoch 929 : loss [3.05054455]\n",
      "Epoch 930 : loss [3.04561301]\n",
      "Epoch 931 : loss [3.04070427]\n",
      "Epoch 932 : loss [3.03581816]\n",
      "Epoch 933 : loss [3.03095451]\n",
      "Epoch 934 : loss [3.02611314]\n",
      "Epoch 935 : loss [3.02129389]\n",
      "Epoch 936 : loss [3.01649658]\n",
      "Epoch 937 : loss [3.01172104]\n",
      "Epoch 938 : loss [3.00696712]\n",
      "Epoch 939 : loss [3.00223465]\n",
      "Epoch 940 : loss [2.99752347]\n",
      "Epoch 941 : loss [2.99283343]\n",
      "Epoch 942 : loss [2.98816435]\n",
      "Epoch 943 : loss [2.9835161]\n",
      "Epoch 944 : loss [2.97888851]\n",
      "Epoch 945 : loss [2.97428143]\n",
      "Epoch 946 : loss [2.96969472]\n",
      "Epoch 947 : loss [2.96512823]\n",
      "Epoch 948 : loss [2.9605818]\n",
      "Epoch 949 : loss [2.95605529]\n",
      "Epoch 950 : loss [2.95183077]\n",
      "Epoch 951 : loss [2.94667663]\n",
      "Epoch 952 : loss [2.94154067]\n",
      "Epoch 953 : loss [2.93642957]\n",
      "Epoch 954 : loss [2.93134417]\n",
      "Epoch 955 : loss [2.92628435]\n",
      "Epoch 956 : loss [2.92124988]\n",
      "Epoch 957 : loss [2.91624053]\n",
      "Epoch 958 : loss [2.91125607]\n",
      "Epoch 959 : loss [2.90629626]\n",
      "Epoch 960 : loss [2.90136088]\n",
      "Epoch 961 : loss [2.8964497]\n",
      "Epoch 962 : loss [2.89156252]\n",
      "Epoch 963 : loss [2.88669912]\n",
      "Epoch 964 : loss [2.88185929]\n",
      "Epoch 965 : loss [2.87704283]\n",
      "Epoch 966 : loss [2.87224954]\n",
      "Epoch 967 : loss [2.86747922]\n",
      "Epoch 968 : loss [2.86273168]\n",
      "Epoch 969 : loss [2.85800674]\n",
      "Epoch 970 : loss [2.85330419]\n",
      "Epoch 971 : loss [2.84862386]\n",
      "Epoch 972 : loss [2.84396557]\n",
      "Epoch 973 : loss [2.83932914]\n",
      "Epoch 974 : loss [2.8347144]\n",
      "Epoch 975 : loss [2.83012116]\n",
      "Epoch 976 : loss [2.82554927]\n",
      "Epoch 977 : loss [2.82099854]\n",
      "Epoch 978 : loss [2.81646882]\n",
      "Epoch 979 : loss [2.81195995]\n",
      "Epoch 980 : loss [2.80747175]\n",
      "Epoch 981 : loss [2.80300407]\n",
      "Epoch 982 : loss [2.79855675]\n",
      "Epoch 983 : loss [2.79412965]\n",
      "Epoch 984 : loss [2.78972259]\n",
      "Epoch 985 : loss [2.78533544]\n",
      "Epoch 986 : loss [2.78096803]\n",
      "Epoch 987 : loss [2.77662023]\n",
      "Epoch 988 : loss [2.77229189]\n",
      "Epoch 989 : loss [2.76798286]\n",
      "Epoch 990 : loss [2.76369299]\n",
      "Epoch 991 : loss [2.75942216]\n",
      "Epoch 992 : loss [2.75517021]\n",
      "Epoch 993 : loss [2.750937]\n",
      "Epoch 994 : loss [2.74672241]\n",
      "Epoch 995 : loss [2.7425263]\n",
      "Epoch 996 : loss [2.73834853]\n",
      "Epoch 997 : loss [2.73418897]\n",
      "Epoch 998 : loss [2.73004749]\n",
      "Epoch 999 : loss [2.72592396]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming input_size, x, y, weights_ih, weights_ho, bias_ih, bias_ho, and sigmoid function are defined somewhere\n",
    "\n",
    "LEARNING_RATE = 1\n",
    "NUM_EPOCHS = 1000\n",
    "BATCH_SIZE = 4  # Set your desired batch size\n",
    "cost = []\n",
    "initial_lr = LEARNING_RATE\n",
    "lr_schedule = lambda epoch: initial_lr * 1.15 ** (epoch // 50)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    \n",
    "    current_lr = lr_schedule(epoch)\n",
    "\n",
    "    for batch_start in range(0, len(x_train), BATCH_SIZE):\n",
    "        batch_end = batch_start + BATCH_SIZE\n",
    "        x_batch = x_train[batch_start:batch_end]\n",
    "        y_batch = y_train[batch_start:batch_end]\n",
    "\n",
    "        batch_gradients_ih = np.zeros_like(weights_ih)\n",
    "        batch_gradients_ho = np.zeros_like(weights_ho)\n",
    "        batch_bias_ih = np.zeros_like(bias_ih)\n",
    "        batch_bias_ho = np.zeros_like(bias_ho)\n",
    "\n",
    "        for i, s in enumerate(x_batch):\n",
    "            inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "\n",
    "            hlayer_logits = np.dot(inp, weights_ih) + bias_ih\n",
    "            hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "            final_logits = np.dot(hlayer_output, weights_ho) + bias_ho\n",
    "            final_output = sigmoid(final_logits)\n",
    "\n",
    "            tot_loss += abs(final_output[0] - y_batch[i])\n",
    "\n",
    "            output_delta = (y_batch[i] - final_output[0]) * final_output * (1 - final_output[0])\n",
    "            batch_bias_ho += output_delta\n",
    "            batch_bias_ih += (output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "            batch_gradients_ho += hlayer_output.T.dot(output_delta)\n",
    "            batch_gradients_ih += inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "        # Update weights and biases after the batch\n",
    "        bias_ho += current_lr * (batch_bias_ho / BATCH_SIZE)\n",
    "        bias_ih += current_lr * (batch_bias_ih / BATCH_SIZE)\n",
    "        weights_ho += current_lr * (batch_gradients_ho / BATCH_SIZE)\n",
    "        weights_ih += current_lr * (batch_gradients_ih / BATCH_SIZE)\n",
    "\n",
    "    cost.append(tot_loss)\n",
    "    print(f'Epoch {epoch} : loss {tot_loss}')\n",
    "    if epoch % 10 == 0:\n",
    "        plt.plot([pl for pl in range(epoch + 1)], cost, 'b')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        # plt.ylim(0, 5)\n",
    "        plt.xlim(0, NUM_EPOCHS)\n",
    "        plt.savefig('train.png')\n",
    "        # if tot_loss < min_loss:       # IMP: Don't save weights\n",
    "        #     np.save('weights_ih2.npy', weights_ih)\n",
    "        #     np.save('weights_ho2.npy', weights_ho)\n",
    "        #     np.save('bias_ih2', bias_ih)\n",
    "        #     np.save(\"bias_ho2\", bias_ho)\n",
    "        #     min_loss = tot_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-36.32898164]] [[1.42919837 1.41105113]]\n"
     ]
    }
   ],
   "source": [
    "print(bias_ho, bias_ih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 1 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[1.5548482  1.56274481]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.82561286 0.82674686]]\n",
      "\n",
      "Logit 2: \n",
      " [[3.33825599]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.96571815]]\n",
      "[[0.96571815]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 1 0 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-12.18510083  14.5847765 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[5.10594028e-06 9.99999537e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98735332]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22237092e-06]]\n",
      "[[6.22237092e-06]]\n"
     ]
    }
   ],
   "source": [
    "x_test1 = '1100110011'\n",
    "x_test2 = '1100110010'\n",
    "def test(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "    print('-'*25, '\\nInput: \\n', inp)\n",
    "    print('\\nLogit 1: \\n', np.dot(inp, weights_ih)+ bias_ih)\n",
    "    print('\\nHidden layer 1 Output: \\n', sigmoid(np.dot(inp, weights_ih)+ bias_ih))\n",
    "    print('\\nLogit 2: \\n', np.dot(sigmoid(np.dot(inp, weights_ih)+ bias_ih), weights_ho)+bias_ho)\n",
    "    print('\\nHidded layer 2 Output: \\n', sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)+ bias_ih), weights_ho)+bias_ho))\n",
    "    return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)+ bias_ih), weights_ho)+bias_ho)\n",
    "\n",
    "print(test(x_test1))\n",
    "print(test(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-13.64451992,  13.10791043],\n",
       "       [-31.28386241,  29.83290423],\n",
       "       [  7.81569815,  -7.43273003],\n",
       "       [-15.61822693,  14.95223693],\n",
       "       [-11.66058964,  11.17985818],\n",
       "       [ 11.70231234, -11.11225394],\n",
       "       [ 15.6725756 , -14.89920306],\n",
       "       [ -7.75956284,   7.47994736],\n",
       "       [ 31.27236043, -29.83469353],\n",
       "       [ 13.73994903, -13.02203169]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.save('weights_ih2.npy', weights_ih)\n",
    "# np.save('weights_ho.npy', weights_ho)\n",
    "# np.save('bias_ih2', bias_ih)\n",
    "# np.save(\"bias_ho\", bias_ho)\n",
    "# weights_ih = np.load('weights_ih2.npy')\n",
    "# weights_ho = np.load('weights_ho2.npy')\n",
    "# bias_ih = np.load('bias_ih2.npy')\n",
    "# bias_ho = np.load('bias_ho2.npy')\n",
    "weights_ih"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test1 = '1100110011'\n",
    "# x_test2 = '0011111011'\n",
    "# def test(x):\n",
    "#     inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "#     print('-'*25, '\\nInput: \\n', inp)\n",
    "#     print('\\nLogit 1: \\n', np.dot(inp, weights_ih[:, [1, 3]])+ bias_ih[:, [1, 3]])\n",
    "#     print('\\nHidden layer 1 Output: \\n', sigmoid(np.dot(inp, weights_ih[:, [1, 3]])+ bias_ih[:, [1, 3]]))\n",
    "#     print('\\nLogit 2: \\n', np.dot(sigmoid(np.dot(inp, weights_ih[:, [1, 3]])+ bias_ih[:, [1, 3]]), weights_ho[[1, 3]])+bias_ho)\n",
    "#     print('\\nHidded layer 2 Output: \\n', sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih[:, [1, 3]])+ bias_ih[:, [1, 3]]), weights_ho[[1, 3]])+bias_ho))\n",
    "#     return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih[:, [1, 3]])+ bias_ih[:, [1, 3]]), weights_ho[[1, 3]])+bias_ho)\n",
    "\n",
    "# test(x_test1)\n",
    "# test(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 1 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 44.45821981 -39.48286247]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 7.12542381e-18]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 1 0 0 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 7.39644924 -4.13587378]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.99938695 0.01573707]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.28957251]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[4.5994349e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 1 0 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 19.16963139 -15.33211474]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999995e-01 2.19455808e-07]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.6581201]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18160974e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 0 1 0 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-39.43106268  40.67973825]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[7.50424599e-18 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 1 1 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[1.62069885 1.61756799]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.83489149 0.83445945]]\n",
      "\n",
      "Logit 2: \n",
      " [[3.74562517]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.97692421]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 0 0 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-59.06127557  59.35132005]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.23879292e-26 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 1 1 0 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-4.35790071  7.15383577]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.01264334 0.99921875]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.70720099]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[8.23424219e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 1 1 0 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-64.79761434  64.94187658]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[7.2235994e-29 1.0000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 0 1 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 30.81369989 -26.37495203]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 3.51159055e-12]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 0 0 0 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-21.94353678  23.89710407]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.95150188e-10 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9874629]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22168914e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 0 0 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 3.49494727 -0.3162777 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.97054366 0.42158317]]\n",
      "\n",
      "Logit 2: \n",
      " [[-3.09340752]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.04338001]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 1 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 27.07570403 -22.73283467]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.34046459e-10]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159311e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 0 0 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-35.59311132  36.95114586]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.48424078e-16 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 1 0 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 36.71354476 -32.14298727]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.09768567e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 0 1 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 28.88107332 -24.49778067]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 2.29482217e-11]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 0 0 0 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-6.38483238  8.92876873]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.00168411 0.9998675 ]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.95082391]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.45387155e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 1 1 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 56.23155525 -50.68797125]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 9.69379405e-23]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 0 0 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-21.98461721  23.8642592 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.83270963e-10 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9874629]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22168913e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 1 0 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-8.20333559 10.79961669]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.73664051e-04 9.99979593e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98148178]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.25901309e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 1 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 36.69865698 -32.0029151 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.26273019e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 0 1 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 81.63209393 -74.88986112]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 2.99051899e-33]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 0 0 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 34.72961448 -30.21493502]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 7.54780113e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 1 0 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 42.59661634 -37.69854594]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 4.24355196e-17]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 1 1 0 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-37.61547012  38.83106649]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[4.61114622e-17 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 1 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 19.16624557 -15.19025327]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999995e-01 2.52904594e-07]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65811929]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18161232e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 0 1 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-25.91191454  27.61164877]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[5.57954137e-12 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 0 0 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-6.33036447  8.89099849]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.00177822 0.9998624 ]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.94872047]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.46746112e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 1 0 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-4.30547299  7.08659522]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.01331482 0.99916446]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.69262795]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[8.35511772e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 0 1 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 3.40329548 -0.32306031]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.96780737 0.41993011]]\n",
      "\n",
      "Logit 2: \n",
      " [[-3.19841588]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.03922538]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 1 1 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-29.70245735  31.4118108 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.2600468e-13 1.0000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 1 0 0 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-51.20439812  51.88484703]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[5.78378907e-23 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 0 0 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 25.03742507 -20.85781629]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 8.74108776e-10]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812531]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159316e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 1 0 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 36.80897387 -32.05710853]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.19611975e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 0 0 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-6.36639028  8.91202227]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.0017154  0.99986526]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.95013764]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.45830214e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 0 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-49.17938741  49.98963965]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[4.38190972e-22 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 0 1 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 26.91609308 -22.67780647]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.41629521e-10]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159311e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 0 0 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-6.24643733  8.97508794]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.0019336  0.99987349]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.94477236]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.49304568e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 0 1 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-41.53014146  42.56388571]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.19790097e-19 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 1 0 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[11.31275394 -7.86564171]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99987784e-01 3.83555841e-04]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.64907816]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.21050802e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 1 1 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 46.5375792  -41.32503597]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.12918451e-18]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 0 1 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 21.13995258 -17.03457976]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999999e-01 3.99922639e-08]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812437]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159614e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 0 1 0 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[13.34080962 -9.65693433]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99998392e-01 6.39762708e-05]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.6566061]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18643032e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 0 0 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-8.24466818 10.84222751]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.62586291e-04 9.99980444e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98172328]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.25750174e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 0 0 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-29.79852872  31.29117269]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.14462548e-13 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 1 0 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 3.56469307 -0.38390504]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.97247348 0.40518539]]\n",
      "\n",
      "Logit 2: \n",
      " [[-3.44687366]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.03086223]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 1 0 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 5.59274875 -2.17519767]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.99628905 0.10199996]]\n",
      "\n",
      "Logit 2: \n",
      " [[-10.26313277]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.48949769e-05]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 0 0 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 17.14640732 -13.4427239 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999964e-01 1.45177248e-06]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65809084]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18170284e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 1 1 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-8.17842164 10.88701867]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.80565809e-04 9.99981301e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98127684]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.26029595e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 0 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 7.46393324 -4.07799932]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.99942693 0.0166591 ]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.26618258]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[4.70828289e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 0 0 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-0.4421394   3.32272061]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.39123131 0.96520009]]\n",
      "\n",
      "Logit 2: \n",
      " [[-3.57376545]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.0272847]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 1 0 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[13.25688248 -9.74102378]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99998252e-01 5.88168256e-05]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65673502]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18601955e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 1 0 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-25.69805378  27.67624232]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[6.90998411e-12 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 1 1 0 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 32.7432815  -28.35603816]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 4.84316315e-13]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 0 0 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 17.25333839 -13.35505585]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999968e-01 1.58479193e-06]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65808752]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18171341e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 1 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-21.80449947  23.97818265]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.39176849e-10 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9874629]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22168914e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 1 1 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 17.18813001 -13.37511966]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999966e-01 1.55331188e-06]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65808833]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18171081e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 0 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-47.24676083  48.11246828]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.02686103e-21 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 0 1 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 52.3149984  -46.88274763]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 4.35593518e-21]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 1 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-37.47707507  38.8773857 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[5.29557471e-17 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 1 0 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 34.83526687 -30.21278203]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 7.56406899e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 0 1 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 21.04263797 -17.0480541 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999999e-01 3.94570089e-08]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812439]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815961e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 1 0 1 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-55.17466139  55.67179614]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.09131222e-24 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 1 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 42.69393096 -37.6850716 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 4.30111798e-17]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 1 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 50.43860601 -45.02494679]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 2.79199129e-20]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 0 1 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-27.79019243  29.54185402]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[8.52850237e-13 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 0 0 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 24.91747212 -20.92088196]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 8.20684834e-10]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812531]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159316e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 1 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 17.18118989 -13.35658389]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999965e-01 1.58237215e-06]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65808763]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18171304e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 1 0 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-2.2413915   5.27427882]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.09609461 0.99490445]]\n",
      "\n",
      "Logit 2: \n",
      " [[-9.83685471]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[5.34422911e-05]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 0 1 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-16.0866028   18.40437258]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.03199389e-07 9.99999990e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746071]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22170276e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 0 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[1.62360949 1.59539178]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.83529232 0.83137334]]\n",
      "\n",
      "Logit 2: \n",
      " [[3.67999254]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.97539739]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 34.89140218 -30.1655647 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.0000000e+00 7.9297904e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 0 0 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-37.5598782   38.77693659]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[4.87474786e-17 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 0 0 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 30.83022103 -26.51197292]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 3.06193845e-12]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 0 1 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 28.88801344 -24.51631643]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 2.25267769e-11]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 0 1 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 19.07587109 -15.22226337]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999995e-01 2.44937292e-07]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65811949]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18161167e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 1 1 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 7.41528145 -4.04240518]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.99939838 0.01725233]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.2524183]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[4.77353676e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 0 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-25.79348288  27.59036358]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[6.2810567e-12 1.0000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 1 0 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-41.40476969  42.52406474]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.04264629e-18 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 1 0 0 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-0.40607954  3.38363312]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.39985255 0.9671891 ]]\n",
      "\n",
      "Logit 2: \n",
      " [[-3.32127799]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.0348484]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 0 0 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-23.91724378  25.74143057]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[4.10084167e-11 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 1 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 34.7660304  -30.12574374]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 8.25193374e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 1 1 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-17.8526783   20.20797999]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.76473833e-08 9.99999998e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746253]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22169144e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 0 1 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-10.23933893  12.71244572]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.57351890e-05 9.99996987e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98669037]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22649738e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 0 0 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 9.28774322 -5.97043433]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.99990746 0.00254663]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.59832706]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.37764974e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 1 0 1 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-2.40278909  5.33512356]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.08296026 0.9952038 ]]\n",
      "\n",
      "Logit 2: \n",
      " [[-10.14046927]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.94487294e-05]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 0 1 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[11.29786615 -7.72556954]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99987601e-01 4.41200631e-04]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.64767934]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.21500208e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 0 0 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-31.73294194  33.1741606 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.65408728e-14 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 1 1 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-45.37503295  46.31101386]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.9673135e-20 1.0000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 0 1 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 73.81639577 -67.45713109]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 5.05522166e-30]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 1 1 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 38.77801637 -33.84508861]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.0000000e+00 2.0010815e-15]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 0 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 48.52569883 -43.18974938]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.74956535e-19]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 1 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 29.04941104 -24.57716116]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 2.11970061e-11]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 0 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 26.97838941 -22.746309  ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.32252386e-10]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159311e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 0 0 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 23.08216017 -19.03023625]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 5.43592434e-09]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.6581252]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159351e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 0 0 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-6.18058669  9.02991111]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.00206494 0.99988024]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9414991]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.51433374e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 1 1 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 62.21194145 -56.23005557]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 3.79836896e-25]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 0 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[1.48354704 1.464085  ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.81510774 0.81215667]]\n",
      "\n",
      "Logit 2: \n",
      " [[2.73444342]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.93902874]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 1 1 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 30.87194373 -26.44436868]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 3.27609589e-12]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 1 1 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-6.2361786   9.08404101]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.0019535  0.99988655]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.94398348]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.49816987e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 1 0 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-10.07982685  12.72400539]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[4.19149176e-05 9.99997021e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98654325]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2274135e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 9.24489652 -6.0216789 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.99990341 0.00241972]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.60151203]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.36690918e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 0 0 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 15.15764543 -11.61276986]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999739e-01 9.04970035e-06]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65791123]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18227434e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 1 1 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 32.83871061 -28.27015941]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 5.27746989e-13]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 1 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-0.35122152  3.45607794]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.41308624 0.96941188]]\n",
      "\n",
      "Logit 2: \n",
      " [[-2.95391918]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.04955161]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 1 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 17.2274238  -13.33645825]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999967e-01 1.61454099e-06]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65808681]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18171565e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 0 1 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 36.73973741 -31.97007023]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.30489303e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 0 0 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 32.79698791 -28.33776365]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 4.93248321e-13]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 0 0 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-35.58617119  36.9326101 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.50850596e-16 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 1 1 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 30.8650036  -26.42583292]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 3.33738711e-12]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 0 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 24.99634464 -20.89066116]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 8.45865154e-10]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812531]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159316e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 1 1 1 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-29.66316356  31.45047221]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.31054443e-13 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 1 0 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-10.17525596  12.63812664]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.81000846e-05 9.99996754e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98664005]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22681071e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 0 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 28.91101599 -24.62348037]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 2.02375693e-11]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 1 0 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-17.84117633  20.20976929]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.78515349e-08 9.99999998e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746253]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22169147e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 1 0 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-31.58112536  33.23180098]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.92526947e-14 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 1 1 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 30.93958102 -26.39536205]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.0000000e+00 3.4406454e-12]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 1 1 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-14.10267252  16.47632033]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[7.50389622e-07 9.99999930e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98744685]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22178903e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 0 1 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 3.482168   -0.29283951]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.97017611 0.42730885]]\n",
      "\n",
      "Logit 2: \n",
      " [[-2.96273586]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.04913802]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 0 1 0 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-39.5994004   40.75911874]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[6.34160109e-18 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 1 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 23.08091692 -18.92307248]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 6.05081729e-09]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812519]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159356e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 1 0 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-41.460905    42.47684741]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.85729473e-19 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 1 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-51.2170241   51.89941739]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[5.71122216e-23 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 0 1 1 0 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-4.36940268  7.15204647]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.01250056 0.99921735]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.71061481]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[8.20618012e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 0 1 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 19.1547436  -15.19204257]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999995e-01 2.52452476e-07]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.6581193]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18161229e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 1 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 54.35327736 -48.75776601]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.0000000e+00 6.6799202e-22]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 1 1 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 25.05462393 -20.76739898]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 9.56826558e-10]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812531]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159317e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 1 0 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-27.72095597  29.45481572]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.13990723e-13 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 1 1 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 9.32946592 -5.90283009]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.99991124 0.00272426]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.59391375]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.39258924e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 1 0 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-12.10966917  14.52111455]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[5.50598609e-06 9.99999506e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9873446]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22242523e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 1 1 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 7.49415396 -4.01218438]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.99944398 0.01777226]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.23868295]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[4.83955496e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 0 1 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 21.08548467 -16.99680953]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999999e-01 4.15316699e-08]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812434]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159626e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 0 1 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-2.3351518   5.38413019]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.08825325 0.99543213]]\n",
      "\n",
      "Logit 2: \n",
      " [[-10.00962188]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[4.49631701e-05]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 1 1 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 25.07914777 -20.79021205]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 9.35245503e-10]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812531]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159317e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 1 0 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 15.30946201 -11.55512947]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999776e-01 9.58664992e-06]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65789729]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18231871e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 0 0 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 9.33070916 -6.00999387]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.99991135 0.0024481 ]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.60063343]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.36986862e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 0 1 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 60.13258206 -54.38788207]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 2.39686148e-24]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 1 1 0 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-14.15880784  16.429103  ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[7.09426780e-07 9.99999927e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9874479]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22178248e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 0 0 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-21.84622216  23.91057841]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.25316629e-10 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9874629]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22168914e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 0 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-31.646976    33.17697781]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.80257338e-14 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 0 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-2.36134445  5.21121315]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.08616827 0.99457454]]\n",
      "\n",
      "Logit 2: \n",
      " [[-10.07985001]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[4.19139467e-05]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 0 0 1 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-10.24122444  12.78485012]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.56678759e-05 9.99997197e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98668685]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22651936e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 0 1 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-16.07510083  18.40616188]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.04393238e-07 9.99999990e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746068]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22170294e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 1 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-10.24627906  12.73098148]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.54880496e-05 9.99997042e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98669488]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22646934e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 0 1 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-2.42364078  5.27971569]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.08138764 0.99493194]]\n",
      "\n",
      "Logit 2: \n",
      " [[-10.18431207]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.77566165e-05]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 0 1 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-23.88385886  25.82035615]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[4.24005893e-11 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 0 1 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-23.9268248   25.85991569]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[4.06173908e-11 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 0 0 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 48.46956351 -43.23696671]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.66887552e-19]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 1 1 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-6.13886399  9.09751535]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.00215273 0.99988807]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.93923055]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.52912856e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 0 1 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 66.05683294 -59.97718372]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.0000000e+00 8.9585984e-27]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 0 1 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 44.46000646 -39.48867901]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 7.08409878e-18]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 0 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-15.9744004   18.27777475]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.15453208e-07 9.99999988e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746046]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22170435e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 0 0 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-6.2779013   9.01643677]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.00187382 0.99987862]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.94606267]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.48467309e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 0 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 30.8232809  -26.49343716]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 3.11922308e-12]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 0 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 54.3545206  -48.86492978]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 6.00109687e-22]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 0 1 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 58.14382017 -52.55792803]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.0000000e+00 1.4941076e-23]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 1 0 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 7.45258455 -4.08865645]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.9994204  0.01648541]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.27056504]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[4.68769423e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 0 0 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 46.49764315 -41.39845676]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.04924926e-18]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 1 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 3.48747477 -0.31442656]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.97032928 0.42203464]]\n",
      "\n",
      "Logit 2: \n",
      " [[-3.08749268]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.04362613]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 1 1 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-29.75680602  31.35877693]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.19339261e-13 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 1 1 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 15.25550344 -11.49794829]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999763e-01 1.01507959e-05]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65788385]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18236147e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 0 1 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 21.09698664 -16.99502023]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999999e-01 4.16060491e-08]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812434]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159627e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 0 0 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 40.61457157 -35.84289809]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 2.71410811e-16]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 0 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 32.9074719  -28.23751245]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 5.45260656e-13]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 1 0 0 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 15.22349607 -11.55794669]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999755e-01 9.55968055e-06]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65789843]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1823151e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-29.85466404  31.24395535]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.08214174e-13 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 0 1 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-8.21822338 10.93968886]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.69621068e-04 9.99982260e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98151256]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.25882046e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 1 0 0 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-57.13348061  57.37605047]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.53902134e-25 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 0 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-8.21483756 10.79782739]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.70535255e-04 9.99979557e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98155673]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.25854399e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 1 1 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 19.15311025 -15.19509385]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999995e-01 2.51683346e-07]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65811932]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18161223e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 0 1 1 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[1.61098352 1.60996214]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.83354789 0.83340613]]\n",
      "\n",
      "Logit 2: \n",
      " [[3.68818164]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.97559315]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 0 1 1 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-6.22923848  9.06550525]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.00196708 0.99988443]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.94371374]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.49992293e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 1 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-10.03698015  12.77524996]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[4.37497833e-05 9.99997170e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9864962]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22770654e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 1 1 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 15.32135409 -11.44312511]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999778e-01 1.07228258e-05]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65786957]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18240692e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 0 0 0 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 7.35511665 -4.09326296]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.9993611  0.01641089]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.2737827]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[4.67263513e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 0 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-41.41982457  42.50969228]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.02706693e-18 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 0 1 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-8.28407403 10.88486568]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.52442641e-04 9.99981261e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98194352]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.25612375e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 0 0 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-31.67680662  33.22137793]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.74959561e-14 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 1 0 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 50.45349379 -45.16501896]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 2.42706546e-20]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 0 1 1 1 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-14.04493663  16.49823528]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[7.94989106e-07 9.99999932e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98744575]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22179582e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 1 0 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-31.63547403  33.17876711]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.82342622e-14 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 1 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 3.60753978 -0.33266047]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.97359751 0.41759343]]\n",
      "\n",
      "Logit 2: \n",
      " [[-3.1182365]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.04236125]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 0 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 62.17021875 -56.29765981]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 3.55007068e-25]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 1 1 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 3.53666996 -0.24867346]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.97171332 0.43815003]]\n",
      "\n",
      "Logit 2: \n",
      " [[-2.66245794]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[0.06522531]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 0 1 0 0 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-21.86466426  23.92732487]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.19372091e-10 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9874629]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22168914e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 0 0 0 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[11.26145023 -7.81476083]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99987141e-01 4.03568437e-04]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.64860625]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.21202346e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 1 0 1 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-35.48051881  36.93476309]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.89947792e-16 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 1 1 0 0 0 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-17.93849094  20.19629496]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.61961714e-08 9.99999998e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746256]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22169123e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 0 0 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-8.22014434 10.81941443]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.69103773e-04 9.99979993e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98157999]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.25839844e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 1 1 1 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 34.77133718 -30.14733078]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 8.07570781e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 1 0 0 1 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 25.09177375 -20.80478242]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 9.21717428e-10]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812531]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18159317e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 0 0 0 1 0 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 36.6443083  -32.05594898]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.19750751e-14]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 1 0 0 1 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-12.06503583  14.56654259]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[5.75730207e-06 9.99999528e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98733811]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22246557e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 1 1 1 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-21.89992857  23.8923039 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.08305922e-10 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.9874629]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22168914e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 0 1 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-2.4797761   5.23249835]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[0.07728817 0.9946882 ]]\n",
      "\n",
      "Logit 2: \n",
      " [[-10.28728309]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.40623752e-05]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 0 1 0 0 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 28.85666731 -24.67651425]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[1.00000000e+00 1.91922561e-11]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812533]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.1815931e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 0 0 0 1 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 15.15956639 -11.49249544]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999739e-01 1.02062973e-05]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65788307]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18236397e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 0 1 0 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-35.53486748  36.88172921]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[3.69320264e-16 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 0 1 0 0 0 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-12.15918624  14.5661789 ]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[5.23998732e-06 9.99999528e-01]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98735036]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22238935e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 1 0 1 1 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-23.77692918  25.79728165]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[4.71857499e-11 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 0 1 1 1 1 0 1 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 15.2537168  -11.49213175]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999763e-01 1.02100099e-05]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65788242]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.18236602e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 0 1 0 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-27.71916933  29.44899918]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.15625157e-13 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 0 1 1 0 1 1 0 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[ 21.00155753 -17.08089897]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[9.99999999e-01 3.81821003e-08]]\n",
      "\n",
      "Logit 2: \n",
      " [[-12.65812442]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[3.181596e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 0 0 0 1 0 1]]\n",
      "\n",
      "Logit 1: \n",
      " [[-45.32132654  46.32928836]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.07585957e-20 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[1 1 1 1 0 0 0 0 1 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-20.0293523   22.03667916]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.00153329e-09 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746287]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.22168935e-06]]\n",
      "------------------------- \n",
      "Input: \n",
      " [[0 1 1 1 0 1 0 1 0 0]]\n",
      "\n",
      "Logit 1: \n",
      " [[-33.71444331  35.13115567]]\n",
      "\n",
      "Hidden layer 1 Output: \n",
      " [[2.28035945e-15 1.00000000e+00]]\n",
      "\n",
      "Logit 2: \n",
      " [[-11.98746291]]\n",
      "\n",
      "Hidded layer 2 Output: \n",
      " [[6.2216891e-06]]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(x_test)):\n",
    "    y_p = 1 if test(x_test[i])>0.5 else 0\n",
    "    if y_test[i]!=y_p:\n",
    "        count+=1\n",
    "        print(x[i])\n",
    "print('Accuracy: ', (len(x_test) - count)/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "palindromes = []\n",
    "for i in range(1024):\n",
    "    binary_string = format(i, '010b')\n",
    "    x.append(binary_string)\n",
    "    if binary_string == binary_string[::-1]:\n",
    "        palindromes.append(binary_string)\n",
    "x = np.array(x)\n",
    "palindromes = np.array(palindromes)\n",
    "\n",
    "y = []\n",
    "for binary_string in x:\n",
    "    y.append(binary_string == binary_string[::-1])\n",
    "y = np.array(y)\n",
    "permutation_index = np.random.permutation(len(x))\n",
    "x = x[permutation_index]\n",
    "y = y[permutation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(28)\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 2\n",
    "output_size = 1\n",
    "global weights_ih\n",
    "\n",
    "# weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ih = np.load('weights/weights_ih2.npy')\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)\n",
    "# bias_ih = np.random.rand(1, hidden_layer_size)\n",
    "bias_ih = np.load('weights/bias_ih2.npy')\n",
    "bias_ho = np.random.rand(1, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(predicted, target):\n",
    "    if len(target)!=len(predicted):\n",
    "        raise ValueError(\"Both predicted and target vectors should be same size!\")\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(len(target)):\n",
    "        if target[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(target)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train,y_train, x_val, y_val, lr=1, epochs=1000, batch_size=4):\n",
    "    global weights_ih, weights_ho, bias_ih, bias_ho\n",
    "    LEARNING_RATE = lr\n",
    "    NUM_EPOCHS = epochs\n",
    "    BATCH_SIZE = batch_size  # Set your desired batch size\n",
    "    cost = []\n",
    "    cost_val = []\n",
    "    initial_lr = LEARNING_RATE\n",
    "    lr_schedule = lambda epoch: initial_lr * 0.95 ** (epoch // 50)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        tot_loss = 0\n",
    "        tot_loss_valid = 0\n",
    "        current_lr = lr_schedule(epoch)\n",
    "\n",
    "        for batch_start in range(0, len(x_train), BATCH_SIZE):\n",
    "            batch_end = batch_start + BATCH_SIZE\n",
    "            x_batch = x_train[batch_start:batch_end]\n",
    "            y_batch = y_train[batch_start:batch_end]\n",
    "\n",
    "            batch_gradients_ih = np.zeros_like(weights_ih)\n",
    "            batch_gradients_ho = np.zeros_like(weights_ho)\n",
    "            batch_bias_ih = np.zeros_like(bias_ih)\n",
    "            batch_bias_ho = np.zeros_like(bias_ho)\n",
    "\n",
    "            for i, s in enumerate(x_batch):\n",
    "                inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "\n",
    "                hlayer_logits = np.dot(inp, weights_ih) + bias_ih\n",
    "                hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "                final_logits = np.dot(hlayer_output, weights_ho) + bias_ho\n",
    "                final_output = sigmoid(final_logits)\n",
    "\n",
    "                tot_loss += abs(final_output[0] - y_batch[i])\n",
    "\n",
    "                output_delta = (y_batch[i] - final_output[0]) * final_output * (1 - final_output[0])\n",
    "                batch_bias_ho += output_delta\n",
    "                batch_bias_ih += (output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "                batch_gradients_ho += hlayer_output.T.dot(output_delta)\n",
    "                batch_gradients_ih += inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "            # Update weights and biases after the batch\n",
    "            bias_ho += current_lr * (batch_bias_ho / BATCH_SIZE)\n",
    "            bias_ih += current_lr * (batch_bias_ih / BATCH_SIZE)\n",
    "            weights_ho += current_lr * (batch_gradients_ho / BATCH_SIZE)\n",
    "            weights_ih += current_lr * (batch_gradients_ih / BATCH_SIZE)\n",
    "        \n",
    "        cost.append(tot_loss)\n",
    "        # print(f'Epoch {epoch} : loss {tot_loss}')\n",
    "        for i, s in enumerate(x_val):\n",
    "                inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "\n",
    "                hlayer_logits = np.dot(inp, weights_ih) + bias_ih\n",
    "                hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "                final_logits = np.dot(hlayer_output, weights_ho) + bias_ho\n",
    "                final_output = sigmoid(final_logits)\n",
    "\n",
    "                tot_loss_valid += abs(final_output[0] - y_val[i])\n",
    "    cost_val.append(tot_loss_valid)\n",
    "    print(\"Done!\")\n",
    "    return cost, cost_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(X:np.ndarray, y:np.ndarray, k_folds:int = 4, epochs_per_fold:int = 250):\n",
    "        fold_size = len(X) // k_folds\n",
    "        losses = []\n",
    "        losses_val = []\n",
    "        for i in range(k_folds):\n",
    "            start, end = i * fold_size, (i + 1) * fold_size\n",
    "            X_test_fold, y_test_fold = X[start:end], y[start:end]\n",
    "            X_train_fold = np.concatenate([X[:start], X[end:]])\n",
    "            y_train_fold = np.concatenate([y[:start], y[end:]])\n",
    "            print(f\"Training Fold {i+1}\\n\")\n",
    "            loss_train, loss_val = train(X_train_fold, y_train_fold, X_test_fold, y_test_fold, epochs=epochs_per_fold)\n",
    "            losses.extend(loss_train)\n",
    "            losses_val.extend(loss_val)\n",
    "            print(\"\\n\"+10*\"----\"+\"\\n\")\n",
    "\n",
    "        return losses, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1\n",
      "\n",
      "Done!\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 2\n",
      "\n",
      "Done!\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 3\n",
      "\n",
      "Done!\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 4\n",
      "\n",
      "Done!\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses, loss_val = k_fold_cross_validation(x, y, epochs_per_fold = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( np.arange(0, len(losses)),losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABBR0lEQVR4nO3deXhU5cH+8Xsme0IWspAQsrAvARIRhIRFRSqCimzWVgWx/b21brXWVgUVxRXoovYtLda3VlvA2ipLUYogVnYCsoSwhzUJSwgBspN1zu+P4HRSFpOQ5Mzy/VzXXJc558zk5lxH5mae88xjMQzDEAAAgIuymh0AAADgWlBmAACAS6PMAAAAl0aZAQAALo0yAwAAXBplBgAAuDTKDAAAcGneZgdoaTabTSdPnlRwcLAsFovZcQAAQAMYhqGSkhLFxsbKar36Zy9uX2ZOnjyp+Ph4s2MAAIAmyM3NVVxc3FWPcfsyExwcLKnuZISEhJicBgAANERxcbHi4+Pt7+NX4/Zl5puhpZCQEMoMAAAupiG3iHADMAAAcGmUGQAA4NIoMwAAwKVRZgAAgEujzAAAAJdGmQEAAC6NMgMAAFwaZQYAALg0ygwAAHBplBkAAODSKDMAAMClUWYAAIBLo8xcgw2HCnShqtbsGAAAeDTKTBPNXL5P9/9ps95elWV2FAAAPBplpoluSAyXJP3fuiPKPF5obhgAADwYZaaJvpMUrTEpsbIZ0jOfZKq61mZ2JAAAPBJl5hq8NCZJYYE+2p9XonfXHjE7DgAAHokycw0i2/jpxTuTJEm//fKgDp8pNTkRAACehzJzjcb366Abu0epqsamqQszZbMZZkcCAMCjUGaukcVi0Rvj+yjQ10tfHzuvBVtyzI4EAIBHocw0g7i2gXr6th6SpNnL9+tU0QWTEwEA4DkoM83kgbSO6pcQptLKGr2weLcMg+EmAABaA2WmmXhZLZo9MVk+XhZ9uT9fn2aeMjsSAAAegTLTjLpHB+vx4d0kSS8v3aNzZVUmJwIAwP1RZprZIzd3UY/oYJ0tq9Krn+01Ow4AAG6PMtPMfL2tmjWxrywWafGOE1p9IN/sSAAAuDXKTAvol9BWPxjcSZL0/OLdKq2sMTkRAADuizLTQn5xW3fFtQ3QicIL+vWKA2bHAQDAbVFmWkigr7feGN9XkvSXTce0Lfu8yYkAAHBPlJkWdGP3KE28Pk6GIT27MFOVNbVmRwIAwO1QZlrY9Dt7KbKNrw7ll+r3Xx02Ow4AAG6HMtPCwgJ99fJdfSRJc1cf0v68YpMTAQDgXigzreD2vjG6NSla1bWGnl24S7WsrA0AQLOhzLQCi8WiV8f2UbCft3bmFur9DUfNjgQAgNugzLSSmFB/Tbu9lyTpNyuzlHuu3OREAAC4B8pMK/r+DfEa1ClcF6prNW3RLlbWBgCgGVBmWpHVatGsicny87Zq/aECfbLtuNmRAABweZSZVtYpMkhPfqe7JOm1Zft0pqTS5EQAALg2yowJfjSsk3rHhqjoQrVmLN1jdhwAAFwaZcYE3l5WzZ6YLC+rRct2ndKKPXlmRwIAwGWZWmbWrl2rMWPGKDY2VhaLRUuWLLnkmH379umuu+5SaGiogoODlZqaqpycnNYP28z6dAjVQzd2liRNX7JbRReqTU4EAIBrMrXMlJWVKSUlRXPmzLns/sOHD2vo0KHq2bOnVq9erZ07d2r69Ony9/dv5aQt46cjuqlTZJDySyo1a/k+s+MAAOCSLIaTzA+2WCxavHixxo0bZ9/2/e9/Xz4+Ppo3b16TX7e4uFihoaEqKipSSEhIMyRtXpuPnNX33k2XJP3tR6lK6xJhciIAAMzXmPdvp71nxmazadmyZerevbtuu+02tWvXToMGDbrsUJSjyspKFRcX13s4s0GdI3TfoARJ0rRFmaqoZmVtAAAaw2nLTH5+vkpLSzVr1iyNGjVKK1eu1Pjx4zVhwgStWbPmis+bOXOmQkND7Y/4+PhWTN00U0f3VHSIn46dLddbq7LMjgMAgEtx2jJjs9kkSWPHjtXPfvYzXXfddZo6daruvPNOvfPOO1d83rRp01RUVGR/5ObmtlbkJgvx99Fr4/pKkv607qh2nygyOREAAK7DactMZGSkvL29lZSUVG97r169rjqbyc/PTyEhIfUeruDWpGjdkdxetTZDz3ySqepam9mRAABwCU5bZnx9fXXDDTfowIED9bZnZWUpMTHRpFQta8aY3goL9NHeU8X6v3VHzI4DAIBL8Dbzl5eWlurQoUP2n48ePaqMjAyFh4crISFBTz/9tL73ve/pxhtv1PDhw/X555/r008/1erVq80L3YKigv00/Y4k/fzjnXp71UHd1jtGXaLamB0LAACnZurU7NWrV2v48OGXbJ8yZYo++OADSdKf//xnzZw5U8ePH1ePHj308ssva+zYsQ3+Hc4+Nfu/GYahB/68ResOFmhgx3B99FCqrFaL2bEAAGhVjXn/dprvmWkprlZmJCn3XLlue3utyqtq9dq4PpqU6p7DagAAXIlbfM+MJ4sPD9QvRvaQJM1avl+nii6YnAgAAOdFmXFSUwZ31HXxYSqtrNH0Jbvl5h+gAQDQZJQZJ+VlteiXdyfLx8uiVfvy9VnmKbMjAQDglCgzTqx7dLAevbmrJGnG0j06X1ZlciIAAJwPZcbJPTq8i7pHt9HZsiq9umyv2XEAAHA6lBkn5+ftpVkTk2WxSIu2n9CarDNmRwIAwKlQZlzA9Qlt9eDgjpKk5xbtUllljbmBAABwIpQZF/GLkT3UISxAJwov6FcrDnz7EwAA8BCUGRcR5OetmRPqVtb+y6Zj2pZ93uREAAA4B8qMC7mxe5QmXN9BhiFNXZipyppasyMBAGA6yoyLmX5HkiKCfHUwv1R/+Oqw2XEAADAdZcbFtA3y1Yy7ekuS/rD6kLJOl5icCAAAc1FmXNCdye31nV7Rqq419Mwnmaq1sdQBAMBzUWZckMVi0Wvj+ijYz1sZuYX6y8ZjZkcCAMA0lBkXFRPqr6m395Qk/WrFAeWeKzc5EQAA5qDMuLB7b0jQwE7hulBdq+cW72JlbQCAR6LMuDCr1aJZE/rK19uqdQcLtHD7CbMjAQDQ6igzLq5zVBs9+Z1ukqRXP9urMyWVJicCAKB1UWbcwI+GdVZS+xAVXajWjE/3mB0HAIBWRZlxAz5eVv3y7mR5WS1alnlKX+w9bXYkAABaDWXGTfTpEKr/GdZJkvTCkl0qrqg2OREAAK2DMuNGfvad7uoYEajTxZWatXy/2XEAAGgVlBk34u/jpVkTkyVJH27OUfqRsyYnAgCg5VFm3Exq5wjdOzBBUt3K2hXVrKwNAHBvlBk3NO32nooO8dOxs+V6e9VBs+MAANCiKDNuKMTfR6+O7SNJ+r91R7T7RJHJiQAAaDmUGTc1sneM7ujbXrU2Q88uzFRNrc3sSAAAtAjKjBubcVdvhQb4aM/JYv3fuqNmxwEAoEVQZtxYVLCfXrijlyTp7VVZOlpQZnIiAACaH2XGzd3dP07DukWqssamqQszZbOxsjYAwL1QZtycxWLRG+P7KsDHS5uPntPfvs4xOxIAAM2KMuMB4sMD9YvbekiSZv1rv/KKKkxOBABA86HMeIgHB3fUdfFhKqms0QtLdsswGG4CALgHyoyH8LJaNHtisny8LFq177SW7TpldiQAAJoFZcaD9IgJ1iM3d5UkzVi6R+fLqkxOBADAtaPMeJjHhndR13ZtVFBapdeW7TM7DgAA14wy42H8vL00e2KyLBZp4fbjWpt1xuxIAABcE8qMB+qf2FZT0jpKkp5bvEtllTXmBgIA4BpQZjzU07f1UIewAB0/f0G/WZlldhwAAJqMMuOhgvy89caEvpKk9zce1fac8yYnAgCgaSgzHuym7lGa0K+DDEOaujBTVTWsrA0AcD2UGQ83/c4kRQT5Kut0qf6w+pDZcQAAaDTKjIdrG+Srl+7qLUn6/VeHlHW6xOREAAA0DmUGGpPcXiN6tlN1raFnF2aqlpW1AQAuhDIDWSwWvTa+j9r4eWtHTqH+uumY2ZEAAGgwygwkSe1DAzR1dE9J0q9WHNDx8+UmJwIAoGEoM7C7b2CCBnYKV3lVrZ5bzMraAADXQJmBndVq0awJfeXrbdXarDNatP2E2ZEAAPhWlBnU0zmqjX46opsk6dVle1VQWmlyIgAAro4yg0s8dGNnJbUPUWF5tWYs3WN2HAAArsrUMrN27VqNGTNGsbGxslgsWrJkyRWP/fGPfyyLxaK333671fJ5Kh8vq2ZPTJbVIn2WeUqr9p42OxIAAFdkapkpKytTSkqK5syZc9XjlixZos2bNys2NraVkqFvXKh+NKyzJOmFJbtVXFFtciIAAC7P28xfPnr0aI0ePfqqx5w4cUKPP/64VqxYoTvuuONbX7OyslKVlf+5z6O4uPiac3qqJ7/TXZ/vyVP22XLNXr5fr4/va3YkAAAu4dT3zNhsNk2ePFlPP/20evfu3aDnzJw5U6GhofZHfHx8C6d0XwG+Xpp5cWXtBZtztPnIWZMTAQBwKacuM7Nnz5a3t7eeeOKJBj9n2rRpKioqsj9yc3NbMKH7G9wlUvcOrCuEUxftUkV1rcmJAACoz2nLzLZt2/Tb3/5WH3zwgSwWS4Of5+fnp5CQkHoPXJupo3upXbCfjhaU6bdfHjQ7DgAA9ThtmVm3bp3y8/OVkJAgb29veXt7Kzs7Wz//+c/VsWNHs+N5lNAAH706ro8k6d21R7T7RJHJiQAA+A+nLTOTJ09WZmamMjIy7I/Y2Fg9/fTTWrFihdnxPM5tvWN0e98Y1doMTV2UqZpam9mRAACQZPJsptLSUh06dMj+89GjR5WRkaHw8HAlJCQoIiKi3vE+Pj6KiYlRjx49WjsqJM24q7c2HDqr3SeK9af1R/XwTV3MjgQAgLmfzGzdulX9+vVTv379JElPPfWU+vXrpxdffNHMWLiCdsH+ev6OXpKkt77I0tGCMpMTAQAgWQw3Xxq5uLhYoaGhKioq4mbgZmAYhia/t0XrDxUotXO4/vaj1EbdoA0AQEM05v3bae+ZgXOyWCx6Y3xfBfh4Kf3IOX30NVPfAQDmosyg0RIiAvXzkd0lSW/8a59OF1eYnAgA4MkoM2iSHwzppJT4MJVU1OiFJbvl5qOVAAAnRplBk3hZLZo9sa+8rRZ9sfe0/rUrz+xIAAAPRZlBk/WMCdGjN9dNz35p6W4VlleZnAgA4IkoM7gmj93SVV3btVFBaZVeW7bP7DgAAA9EmcE18fP20uyJfWWxSJ9sO651B8+YHQkA4GEoM7hm/RPD9UBqoiRp2qJdKq+qMTkRAMCTUGbQLJ4e1VMdwgJ0/PwF/WZlltlxAAAehDKDZtHGz1uvj69bWfv9DUeVkVtobiAAgMegzKDZ3Nyjncb36yCbIT37SaaqalhZGwDQ8igzaFbT70xSeJCvDpwu0dzVh82OAwDwAJQZNKvwIF+9NCZJkjTnq4M6eLrE5EQAAHdHmUGzuyslVrf0bKfqWkPPLsxUrY2lDgAALYcyg2ZnsVj02rg+auPnre05hZq36ZjZkQAAbowygxYRGxagZ0f1kCT9csUBHT9fbnIiAIC7osygxdw/KFE3dGyr8qpaPb+YlbUBAC2DMoMWY7VaNGtisny9rVqTdUZLMk6YHQkA4IYoM2hRXaLa6KcjukmSXvl0rwpKK01OBABwN5QZtLiHbuysXu1DdL68Wi9/utfsOAAAN0OZQYvz8bJq9sS+slqkT3ee1Jf7TpsdCQDgRigzaBXJcWH6n2GdJUkvLNmtkopqkxMBANwFZQat5mff6a7EiECdKqrQ7M/3mx0HAOAmKDNoNQG+Xpo5vq8kaX56jrYcPWdyIgCAO6DMoFUN7hqp7w2IlyRNXZipiupakxMBAFwdZQat7rk7eqldsJ+OFJTpd/8+aHYcAICLo8yg1YUG+OiVsX0kSX9cc0R7ThaZnAgA4MooMzDFqD4xGt0nRjW2upW1a2ptZkcCALgoygxM8/LY3grx99buE8V6b/1Rs+MAAFwUZQamaRfsrxfuSJIkvflFlo4VlJmcCADgiigzMNV3B8RpSNcIVdbYNG3RLlbWBgA0GmUGprJYLJo5Pln+PlZtOnJWf/861+xIAAAXQ5mB6RIiAvXzW3tIkl7/1z6dLq4wOREAwJVQZuAUfjCko1LiQlVSUaMX/7nb7DgAABdCmYFT8PayatbEZHlbLVqx57SW7zpldiQAgIugzMBp9Gofokdu7iJJmv7PPSoqZ2VtAMC3o8zAqTx+S1d1iQpSQWmlXlu21+w4AAAXQJmBU/Hz9tLsicmyWKSPtx3X+oMFZkcCADg5ygyczoCO4ZqcmihJmrY4U+VVNSYnAgA4M8oMnNIzo3oqNtRfuecu6M2VWWbHAQA4McoMnFIbP2+9Pr6vJOnPG45qZ26huYEAAE6LMgOnNbxnO427LlY2Q3p2YaaqalhZGwBwKcoMnNqLY3orPMhX+/NK9Mc1h82OAwBwQpQZOLXwIF+9NKZuZe3f/fuQDuWXmJwIAOBsKDNwenelxGp4jyhV1dr07MJdstlYWRsA8B+UGTg9i8Wi18b3VZCvl7Zln9e89GyzIwEAnAhlBi6hQ1iAnh3dU5L0y8/360ThBZMTAQCcBWUGLmPSoEQNSGyrsqpaPb94lwyD4SYAAGUGLsRqtWjWxGT5elm1+sAZ/TPjpNmRAABOwNQys3btWo0ZM0axsbGyWCxasmSJfV91dbWeffZZ9e3bV0FBQYqNjdUDDzygkyd5A/NkXdu10RMjukqSXv50j86WVpqcCABgNlPLTFlZmVJSUjRnzpxL9pWXl2v79u2aPn26tm/frkWLFikrK0t33XWXCUnhTH58Uxf1jAnW+fJqvfIZK2sDgKezGE5y44HFYtHixYs1bty4Kx7z9ddfa+DAgcrOzlZCQkKDXre4uFihoaEqKipSSEhIM6WF2TKPF2rc7zfIZkh/fnCAbukZbXYkAEAzasz7t0vdM1NUVCSLxaKwsLArHlNZWani4uJ6D7if5Lgw/b+hnSRJzy/erZKKapMTAQDM4jJlpqKiQlOnTtV999131YY2c+ZMhYaG2h/x8fGtmBKt6albeyghPFCniir0y88PmB0HAGASlygz1dXV+v73vy+bzaY//OEPVz122rRpKioqsj9yc3NbKSVaW4Cvl2ZOqFtZe156tr4+ds7kRAAAMzh9mamurtY999yjo0eP6osvvvjWcTM/Pz+FhITUe8B9DekaqXsGxEmqW1m7orrW5EQAgNbm1GXmmyJz8OBBrVq1ShEREWZHghN6/vYkRQX76ciZMs359yGz4wAAWpmpZaa0tFQZGRnKyMiQJB09elQZGRnKyclRTU2N7r77bm3dulULFixQbW2t8vLylJeXp6qqKjNjw8mEBvro1bG9JUnvrDmsfae46RsAPImpU7NXr16t4cOHX7J9ypQpmjFjhjp16nTZ53311Ve6+eabG/Q7mJrtOR6et02f78lTclyoFj0yWN5eTv3BIwDgKhrz/u3dlF+Qm5sri8WiuLi6exW2bNmiDz/8UElJSXrooYca/Do333zzVdfXcZKvwIGLeGVsb208XKDM40V6f8Mx/ejGzmZHAgC0gib90/W+++7TV199JUnKy8vTrbfeqi1btui5557TK6+80qwBgYZqF+Kv5+/oJUn6zRcHlH22zOREAIDW0KQys3v3bg0cOFCS9I9//EN9+vTRxo0b9eGHH+qDDz5oznxAo9wzIF6Du0SootqmaYtYWRsAPEGTykx1dbX8/PwkSatWrbKvl9SzZ0+dOnWq+dIBjWSxWDRzQl/5+1i18fBZ/WMr3zMEAO6uSWWmd+/eeuedd7Ru3Tp98cUXGjVqlCTp5MmTTJ+G6RIjgvTUrd0lSa8t26f84gqTEwEAWlKTyszs2bP1xz/+UTfffLPuvfdepaSkSJKWLl1qH34CzPTDIZ3Ut0OoSipq9OI/95gdBwDQgpo8Nbu2tlbFxcVq27atfduxY8cUGBiodu3aNVvAa8XUbM+192Sx7pqzXjU2Q+9Mul6j+rQ3OxIAoIFafNXsCxcuqLKy0l5ksrOz9fbbb+vAgQNOVWTg2ZJiQ/TwTV0kSdP/uUdF5aysDQDuqEllZuzYsfrrX/8qSSosLNSgQYP0m9/8RuPGjdPcuXObNSBwLR6/pas6RwXpTEml3vjXPrPjAABaQJPKzPbt2zVs2DBJ0ieffKLo6GhlZ2frr3/9q/73f/+3WQMC18Lfx0uzJyZLkv6+NVcbDhWYnAgA0NyaVGbKy8sVHBwsSVq5cqUmTJggq9Wq1NRUZWdnN2tA4Frd0DFck1MTJUnTFu3ShSpW1gYAd9KkMtO1a1ctWbJEubm5WrFihUaOHClJys/P5yZbOKVnRvVQ+1B/5Zwr15tfHDA7DgCgGTWpzLz44ov6xS9+oY4dO2rgwIFKS0uTVPcpTb9+/Zo1INAcgv199Pr4PpKk99Yf1c7cQnMDAQCaTZOnZufl5enUqVNKSUmR1VrXibZs2aKQkBD17NmzWUNeC6Zmw9ETf9uhpTtPqmdMsD79yVD5sLI2ADilFp+aLUkxMTHq16+fTp48qRMnTkiSBg4c6FRFBvhvL41JUttAH+3PK9Ef1xw2Ow4AoBk0qczYbDa98sorCg0NVWJiohISEhQWFqZXX31VNputuTMCzSaijZ9eGtNbkvS/Xx7SofxSkxMBAK5Vk8rM888/rzlz5mjWrFnasWOHtm/frjfeeEO/+93vNH369ObOCDSrsdfF6uYeUaqqtWnaokzZbKysDQCurEn3zMTGxuqdd96xr5b9jX/+85969NFH7cNOzoB7ZnA5JwovaOSba1RWVatXx/bW5LSOZkcCADho8Xtmzp07d9l7Y3r27Klz58415SWBVtUhLEDPjKq7hmct368ThRdMTgQAaKomlZmUlBTNmTPnku1z5sxRcnLyNYcCWsPk1ET1T2yrsqpavbB4l5o4sQ8AYDLvpjzpl7/8pe644w6tWrVKaWlpslgs2rhxo3Jzc/Wvf/2ruTMCLcJqtWj2xL66/bfr9dWBM1q686TGXtfB7FgAgEZq0iczN910k7KysjR+/HgVFhbq3LlzmjBhgvbs2aP333+/uTMCLaZru2A9fktXSdLLn+7VubIqkxMBABqryV+adzk7d+7U9ddfr9pa51n7hhuA8W2qamwa87v1OnC6ROOui9Xb3+dbrAHAbK3ypXmAu/D1tmr23cmyWqQlGSf11YF8syMBABqBMgNIui4+TD8c0kmS9PyiXSqtrDE5EQCgoSgzwEVPjeyu+PAAnSyq0K8+3292HABAAzVqNtOECROuur+wsPBasgCmCvT11szxyZr03mb9NT1bY1JiNaBjuNmxAADfolGfzISGhl71kZiYqAceeKClsgItbmi3SH23f5wMQ3p2YaYqqp3nZnYAwOU162wmZ8RsJjRWUXm1Rry5RgWllfrJLV3185E9zI4EAB6H2UzANQgN9NErY+tW1p67+rD2nSo2OREA4GooM8BljO4To5FJ0aqxGZq6MFO1rKwNAE6LMgNchsVi0avj+ijY31s7jxfp/Q1HzY4EALgCygxwBdEh/nr+9l6SpF+vPKCcs+UmJwIAXA5lBriK790Qr7TOEaqotuk5VtYGAKdEmQGuwmKxaOaEvvLztmr9oQJ9vO242ZEAAP+FMgN8i46RQXrq1u6SpNc+26v84gqTEwEAHFFmgAb4f0M7qW+HUBVX1OilpXvMjgMAcECZARrA28uqWRP7ystq0fLdefp8d57ZkQAAF1FmgAbqHRuqH9/YWZL04j93q+hCtcmJAAASZQZolCdGdFPnyCDll1Rq5r/2mR0HACDKDNAo/j5emjUxWZL00de52ni4wOREAADKDNBIAzuFa1JqgiRp2qJdulDFytoAYCbKDNAEz47qqfah/so+W663V2WZHQcAPBplBmiCYH8fvTaujyTp/9YdUebxQnMDAYAHo8wATTSiV7TGpMTKZkjPfJKp6lqb2ZEAwCNRZoBr8NKYJIUF+mh/XoneXXvE7DgA4JEoM8A1iGzjpxfvTJIk/fbLgzp8ptTkRADgeSgzwDUa36+Dbuoepaoam6YuzJTNxsraANCaKDPANbJYLHp9fB8F+nrp62PntWBLjtmRAMCjUGaAZhDXNlDP3NZDkjR7+X6dKrpgciIA8Bymlpm1a9dqzJgxio2NlcVi0ZIlS+rtNwxDM2bMUGxsrAICAnTzzTdrzx5WLIZzmpzWUdcnhKm0skbPL94tw2C4CQBag6llpqysTCkpKZozZ85l9//yl7/Um2++qTlz5ujrr79WTEyMbr31VpWUlLRyUuDbeVktmj0xWb5eVv17f76W7jxpdiQA8AimlpnRo0frtdde04QJEy7ZZxiG3n77bT3//POaMGGC+vTpo7/85S8qLy/Xhx9+aEJa4Nt1iw7WY8O7SpJe/nSvzpVVmZwIANyf094zc/ToUeXl5WnkyJH2bX5+frrpppu0cePGKz6vsrJSxcXF9R5Aa3rk5i7qER2sc2VVevWzvWbHAQC357RlJi8vT5IUHR1db3t0dLR93+XMnDlToaGh9kd8fHyL5gT+m6+3VbMm9pXFIi3ecUKrD+SbHQkA3JrTlplvWCyWej8bhnHJNkfTpk1TUVGR/ZGbm9vSEYFL9Etoqx8O6SRJen7xbpVW1picCADcl9OWmZiYGEm65FOY/Pz8Sz6tceTn56eQkJB6D8AMPx/ZXfHhATpReEG/XnHA7DgA4Lactsx06tRJMTEx+uKLL+zbqqqqtGbNGg0ePNjEZEDDBPp6a+b4ZEnSXzYd07bs8yYnAgD3ZGqZKS0tVUZGhjIyMiTV3fSbkZGhnJwcWSwWPfnkk3rjjTe0ePFi7d69Ww8++KACAwN13333mRkbaLCh3SJ1d/84GYb07MJMVdbUmh0JANyOt5m/fOvWrRo+fLj956eeekqSNGXKFH3wwQd65plndOHCBT366KM6f/68Bg0apJUrVyo4ONisyECjvXBHL60+cEaH8kv1+38f0lMje5gdCQDcisVw868pLS4uVmhoqIqKirh/BqZZlnlKj324Xd5Wiz57Yqh6xnAtAsDVNOb922nvmQHcye19Y3RrUrRqbIaeXbhLtaysDQDNhjIDtAKLxaJXx/ZRsJ+3duYW6v0NR82OBABugzIDtJKYUH89d0cvSdJvVmYp91y5yYkAwD1QZoBW9P0b4pXaOVwXqms1bdEuVtYGgGZAmQFakcVi0awJyfLztmr9oQJ9su242ZEAwOVRZoBW1jEySD+7tbsk6bVl+3SmpNLkRADg2igzgAn+Z2gn9ekQoqIL1ZqxdI/ZcQDApVFmABN4e1k1e2KyvKwWLdt1Siv2XHkleADA1VFmAJP0jg3VQzd2liRNX7JbRReqTU4EAK6JMgOY6KcjuqlTZJDySyo1a/k+s+MAgEuizAAm8vfx0qwJfSVJf9uSq02Hz5qcCABcD2UGMNmgzhG6f1CCJGnaokxVVLOyNgA0BmUGcAJTR/dUTIi/jp0t11urssyOAwAuhTIDOIFgfx+9Nq6PJOlP645q94kikxMBgOugzABO4jtJ0bozub1qbYam/HmL3lx5QKeKLpgdCwCcnsVw88VhiouLFRoaqqKiIoWEhJgdB7iqgtJK3T13o46drVuE0mqRvtMrWpPTEjWkS6SsVovJCQGgdTTm/ZsyAziZ6lqbVu45rXnpx5R+5Jx9e6fIIN0/KEHf7R+v0EAfExMCQMujzDigzMCVHTxdogWbc7Rw23GVVNZIkvy8rborJVaT0xKVHBdmbkAAaCGUGQeUGbiDssoa/TPjpOalZ2vfqWL79pS4UN2fmqi7UmLl7+NlYkIAaF6UGQeUGbgTwzC0PadQ89OztSzzlKpqbZKk0AAffbd/nO5PTVSnyCCTUwLAtaPMOKDMwF2dLa3UP7Ye14LN2Tp+/j+znoZ1i9Sk1ESN6NlO3l5MWATgmigzDigzcHe1NkNrs85oXnq2vjqQr2/+j24f6q/7BiboewPj1S7Y39yQANBIlBkHlBl4ktxz5VqwOUf/2Jqrc2VVkiRvq0Wj+sRoUmqiBnUKl8XC9G4Azo8y44AyA09UWVOr5bvyNC89W9uyz9u3d2vXRpPTEjW+XwcF+zO9G4Dzosw4oMzA0+05WaT56TlasuOELlxcxDLQ10vj+nXQ5NRE9WrP/xcAnA9lxgFlBqhTXFGtRduOa/7mHB3KL7VvH5DYVpPTEjWqT4z8vJneDcA5UGYcUGaA+gzDUPqRc5qfnq0Ve/JUY6v7KyAiyFf33BCv+wYmKD480OSUADwdZcYBZQa4stPFFfpoS67+tiVHecUVkiSLRbqlRztNSkvUTd2iWA8KgCkoMw4oM8C3q6m1adW+fM1Pz9b6QwX27fHhAbp/UKLuGRCv8CBfExMC8DSUGQeUGaBxDp8p1YL0HH2yLVfFFXXrQfl6W3Vn3/aalJaofvFhTO8G0OIoMw4oM0DTXKiq1ac7T+qv6ce0+8R/1oNKah+iyWmJGntdrAJ9vU1MCMCdUWYcUGaAa2MYhnYeL9L89Gx9uvOkKmvq1oMK9vfWxOvjNCk1UV3btTE5JQB3Q5lxQJkBms/5sip9su245m/OVvbZcvv2tM4RmpyWqFuTouXDelAAmgFlxgFlBmh+NpuhdYcKND89W1/uO62Ls7vVLthP9w5M0L0DExQTynpQAJqOMuOAMgO0rBOFF/S3zTn66OscFZTWrQflZbXo1l7RmpyWqMFdIrhhGECjUWYcUGaA1lFVY9Pne/I0Pz1bW46es2/vHBWkSYMSNbF/nEIDWA8KQMNQZhxQZoDWdyCvRPPTs7Vo+3GVVdWtB+XvY9XYlA6anJaoPh1CTU4IwNlRZhxQZgDzlFbWaPGOE1qQnq39eSX27dfFh2lyaqLuSG4vfx/WgwJwKcqMA8oMYD7DMLQ1+7zmbcrW8t2nVF1b99dOWKCP7hkQr/sHJSgxIsjklACcCWXGAWUGcC5nSir1j625+nBzjk4UXrBvv6l7lCanJmp4z3byYj0owONRZhxQZgDnVGsz9NX+fM1Lz9aarDP27R3CAnTfoATdMyBeUcF+JiYEYCbKjAPKDOD8ss+W6cPNOfr71lwVlldLkny8LBrdp70mpSbqho5tmd4NeBjKjAPKDOA6KqprtSzzlOalZysjt9C+vUd0sCalJWp8vw5q48d6UIAnoMw4oMwArmn3ibr1oJZknFBFdd16UEG+XppwcT2oHjHBJicE0JIoMw4oM4BrK7pQrYXbjmt+eraOFJTZtw/sGK5JaYka1TtGvt6sBwW4G8qMA8oM4B4Mw9DGw2c1Pz1bK/eeVu3FBaEi2/jq+zck6N5BCeoQFmBySgDNhTLjgDIDuJ+8ogr9bUuO/rYlR/kllZIkq0W6pWfdelDDukbKyvRuwKVRZhxQZgD3VV1r06q9pzUvPVsbD5+1b0+MCNSkQYm6u3+c2gb5mpgQQFNRZhxQZgDPcCi/RPPTc7Rw23GVVNZIkny9rRqTHKvJaYlKiQtlejfgQigzDigzgGcpr6rR0oyT+uumbO09VWzf3rdDqCalJuiulA4K8GU9KMDZuU2Zqamp0YwZM7RgwQLl5eWpffv2evDBB/XCCy/Iam3Y7AXKDOCZDMPQjtxCzd+Urc8yT6mqtm56d4i/t+7uH69JqQnqHNXG5JQArsRtyszrr7+ut956S3/5y1/Uu3dvbd26VT/4wQ/02muv6ac//WmDXoMyA+BcWZU+3pqr+ZuzlXvuP+tBDe0aqUmpCfpOr2h5ezG9G3AmblNm7rzzTkVHR+u9996zb5s4caICAwM1b968yz6nsrJSlZWV9p+Li4sVHx9PmQEgm83QmoNnNH9Ttv59IF/f/O0XE+Kvewcm6N6B8WoX4m9uSACSGldmnPqfIkOHDtWXX36prKwsSdLOnTu1fv163X777Vd8zsyZMxUaGmp/xMfHt1ZcAE7OarVoeI92eu/BG7T26eF69OYuigjyVV5xhd5alaXBs/6txxZs18bDBXLif+cB+C9O/cmMYRh67rnnNHv2bHl5eam2tlavv/66pk2bdsXn8MkMgMaorKnV57vzNG9TtrZmn7dv79qujSYNStCE/nEK8fcxMSHgmdxmmOmjjz7S008/rV/96lfq3bu3MjIy9OSTT+rNN9/UlClTGvQa3DMDoKH2nSrW/PRsLd5xQuVVtZKkAB8vjevXQZNSE9Q7NtTkhIDncJsyEx8fr6lTp+qxxx6zb3vttdc0f/587d+/v0GvQZkB0FglFdVavOOE5m3K1sH8Uvv26xPCNDktUaP7tJe/D9O7gZbUmPdv71bK1CTl5eWXTMH28vKSzWYzKREATxDs76MH0jpqcmqithw9p3np2fp8d5625xRqe06hXv1sn+4ZEK/7ByUoPjzQ7LiAx3PqMjNmzBi9/vrrSkhIUO/evbVjxw69+eab+uEPf2h2NAAewGKxaFDnCA3qHKH8kgr9fUuuPtySo1NFFXpnzWH9ce1h3dw9SpPTEnVT93byYj0owBROPcxUUlKi6dOna/HixcrPz1dsbKzuvfdevfjii/L1bdh6KwwzAWhONbU2/Xt/vualZ2vdwQL79ri2AbpvUIK+NyBeEW38TEwIuAe3uWemOVBmALSUowVlWpCerY+3HVfRhWpJkq+XVbf3jdHktERdn9CW9aCAJqLMOKDMAGhpFdW1+nTnSc1Pz9bO40X27b3ah2hSaoLGXddBQX5OPaoPOB3KjAPKDIDWtDO3UPPTs7V050lV1tRNVmjj562J13fQpNREdYsONjkh4BooMw4oMwDMUFhepU+2Hdf89GwdO1tu357aOVyTUhM1MilGvt5O/SXsgKkoMw4oMwDMZLMZ2nC4QPM2ZWvVvtOyXfwbNyrYT/feEK97ByWofWiAuSEBJ0SZcUCZAeAsThZe0EdbcvThllwVlNYtu+Jlteg7vdppUmqihnSJlJXp3YAkykw9lBkAzqaqxqaVe+vWg9p89Jx9e6fIIN0/KEHf7R+v0EDWg4Jno8w4oMwAcGZZp0u0ID1bC7efUGlljSTJ38eqMcmxmpyWqOS4MHMDAiahzDigzABwBWWVNVqSUbce1P68Evv2lLhQTUpN1JiUWNaDgkehzDigzABwJYZhaHvOec3blK1/7cpTVW3d9O7QAB99t3+c7k9NVKfIIJNTAi2PMuOAMgPAVRWUVuofW3O1ID1HJwov2LcP6xapyamJuqVnO3l7Mb0b7oky44AyA8DV1doMrcnK17xN2VqddUbf/K0dG+qvewcm6HsD49Uu2N/ckEAzo8w4oMwAcCc5Z8u1YEu2/vF1rs6X160H5W21aFSfGE1OTdTATuGsBwW3QJlxQJkB4I4qqmu1fPcpzduUre05hfbt3aPbaFJqosb366Bgf6Z3w3VRZhxQZgC4u90nirRgc7aW7DipC9W1kqRAXy+N71e3HlSv9vzdB9dDmXFAmQHgKYorqrVo23HNS8/W4TNl9u0DEttqclqiRvWJkZ8307vhGigzDigzADyNYRjadOSs5qdna8We06q9uCBUaICPhnaN1NBukRrWLVJxbQNNTgpcGWXGAWUGgCc7XVyhj7bk6sMt2TpdXFlvX+fIoIvFJkqpncO5xwZOhTLjgDIDAFJNrU07jxdp3cEzWn+wQDtyC+2f2Eh1M6L6JYRpWLcoDe0WqeQOoXyHDUxFmXFAmQGASxVXVGvT4bNaf7BA6w6e0bGz5fX2h/h7a8jFIakbu0UpPpwhKbQuyowDygwAfLvcc+Vad7HYbDhUoOKKmnr7EyMCNezikFRalwiFMCSFFkaZcUCZAYDGqbUZyjxeePFTmwJtzzmvGochKS+rRdfFh2lo10jd2D1SKXFhDEmh2VFmHFBmAODalFbWKP3wWa07eEbrDhXoiMO0b0kK9vNWWpcIDesepRu7RSoxgoUwce0oMw4oMwDQvI6fL6/71OZQgTYcKlDhxWUVvhEfHqBh3aI0rGukBneJVGggQ1JoPMqMA8oMALScWpuhPSeLtO5ggdZmndH2nPOqrv3P24rVIiXHhenGbpEa2i1K/RLC5MOQFBqAMuOAMgMAraesskabj569eDNxgQ7ll9bb38bPW6mdIy7eTBypTpFBLIyJy6LMOKDMAIB5ThVdsBebDYcKdK6sqt7+DmEB9llSQ7pGKCzQ16SkcDaUGQeUGQBwDjabob2nirX24hf3bT12XlW1Nvt+i0VK7hBq/+K+6xPaytebISlPRZlxQJkBAOdUXlWjLUfP2b/fJut0/SGpQF8vhyGpKHWJYkjKk1BmHFBmAMA15BVVaP2hAq0/eEbrDxWooLT+kFT7UH+HIalIhQcxJOXOKDMOKDMA4HpsNkP78ortX9y35dg5VdXUH5LqExtqXwG8f2Jb+Xl7mZgYzY0y44AyAwCur6K69uKQ1BmtO1ig/Xkl9fYH+HhpUOfwuu+36Rapbu3aMCTl4igzDigzAOB+8ksqtOFQgdZl1X1535mSynr7o0P8NLRrlG7sHqkhXSMV2cbPpKRoKsqMA8oMALg3wzB04HSJvdhsPnJWlQ5DUpKU1D5Ew7pHaljXKA3o2Fb+PgxJOTvKjAPKDAB4lorqWm3LPq+1B89oXVaB9p4qrrffz9uqQZ0jNKxrpIZ1j1SP6GCGpJwQZcYBZQYAPFtBaaU2HCrQ2qwCrT90RqeL6w9JRQX72YvNkK6Rahfsb1JSOKLMOKDMAAC+YRiGDuaX2r/bJv3IWVVU1x+S6hkTbJ8CPrBTOENSJqHMOKDMAACupLKmbkhq3cECrT9YoN0ni+T4rujrbdXAjuH2ctMzJlhWK0NSrYEy44AyAwBoqHNlVXWzpC5OAT9VVFFvf2QbXw3tWrcC+LBukYoOYUiqpVBmHFBmAABNYRiGDp8psxeb9CNnVV5VW++Y7tFt7N9tM6hThAJ8GZJqLpQZB5QZAEBzqKqxaXvO+YvfSnxGmSf+a0jKy6oBHdvay01S+xCGpK4BZcYBZQYA0BLOl1Vp4+Gz9k9uThReqLc/PMhXQ7pGXrzfJlLtQwNMSuqaKDMOKDMAgJZmGIaOFpRdnCVVoE2HC1T2X0NSXdu1sRebQZ0iFOTnbVJa10CZcUCZAQC0tupamzJyC7Uu64zWHSrQztxC2RzebX28LOqf+J8hqd6xofJiSKoeyowDygwAwGxF5dXaeLhuuYW1WWd0/Hz9IamwQB8N6RqpG7vVzZTqEMaQFGXGAWUGAOBMDMNQ9tlyrTtUoHVZZ7Tp8FmVVNbUO6ZzVFDdtxJ3i1Jqlwi18cAhKcqMA8oMAMCZ1dTatPN4of1+m4zcQtU6jEl5Wy26PqGthnWL1NBukUqOC/OIISnKjAPKDADAlRRXVGvTxVlS6w8W6NjZ8nr7QwN8NKRrhIZ2rbvfJj480KSkLYsy44AyAwBwZTlny7XuUF2x2XCoQMUV9YekOkYEali3KA3tFqm0LhEK8fcxKWnzosw4oMwAANxFTa1Nu04U2RfK3JFTqBqHISkvq0X94sM09OJaUilxofL2spqYuOncqsycOHFCzz77rJYvX64LFy6oe/fueu+999S/f/8GPZ8yAwBwVyUV1Uo/cs4+JHWkoKze/mB/bw3uEmGfAp4YEWRS0sZrzPu3U98eff78eQ0ZMkTDhw/X8uXL1a5dOx0+fFhhYWFmRwMAwHTB/j66NSlatyZFS5KOny+/uNxCgTYcLlBhebVW7DmtFXtOS5ISwgPtX9yX1iVSoQHuMSTl1J/MTJ06VRs2bNC6desa/JzKykpVVlbafy4uLlZ8fDyfzAAAPEqtzdDuE0X25Ra2ZZ+vNyRltUgp8WEa1i1KN3aLVEp8mHycaEjKbYaZkpKSdNttt+n48eNas2aNOnTooEcffVQ/+tGPrvicGTNm6OWXX75kO2UGAODJSitrtPnIWfv9NofP1B+SauPnrbQuERc/uYlSx4hAWSzmTQF3mzLj7+8vSXrqqaf03e9+V1u2bNGTTz6pP/7xj3rggQcu+xw+mQEA4NudLLyg9QcLtPbgGW04VKDz5dX19se1DbAXm8FdIhQW6Nuq+dymzPj6+mrAgAHauHGjfdsTTzyhr7/+Wps2bWrQa3ADMAAAV2ezGdpzsljrDp3RuqwCbc0+p+ra+kNSfePC6pZb6Bqpfglt5evdskNSbnMDcPv27ZWUlFRvW69evbRw4UKTEgEA4H6sVov6xoWqb1yoHr25q8qrarT56DmtyyrQ+kNnlHW6VDtzC7Uzt1C/+/chBfl6KbXzxSGp7lHqHBlk6pCUU5eZIUOG6MCBA/W2ZWVlKTEx0aREAAC4v0Bfbw3v0U7De7STJOUVVWj9oQL7FPCzZVX6cn++vtyfL0n6/g3xmjUx2bS8Tl1mfvazn2nw4MF64403dM8992jLli1699139e6775odDQAAjxET6q+7+8fp7v5xstkM7csrtt9I/PWx8+obF2pqPqe+Z0aSPvvsM02bNk0HDx5Up06d9NRTT111NtN/454ZAABazoWqWhkyFOjbvJ+PuM0NwM2BMgMAgOtpzPu383w7DgAAQBNQZgAAgEujzAAAAJdGmQEAAC6NMgMAAFwaZQYAALg0ygwAAHBplBkAAODSKDMAAMClUWYAAIBLo8wAAACXRpkBAAAujTIDAABcWvOu1+2EvlkUvLi42OQkAACgob553/7mffxq3L7MlJSUSJLi4+NNTgIAABqrpKREoaGhVz3GYjSk8rgwm82mkydPKjg4WBaLpVlfu7i4WPHx8crNzVVISEizvra74Vw1HOeq4ThXDce5ajjOVcO15LkyDEMlJSWKjY2V1Xr1u2Lc/pMZq9WquLi4Fv0dISEhXPANxLlqOM5Vw3GuGo5z1XCcq4ZrqXP1bZ/IfIMbgAEAgEujzAAAAJdGmbkGfn5+eumll+Tn52d2FKfHuWo4zlXDca4ajnPVcJyrhnOWc+X2NwADAAD3xiczAADApVFmAACAS6PMAAAAl0aZAQAALo0ycxV/+MMf1KlTJ/n7+6t///5at27dVY9fs2aN+vfvL39/f3Xu3FnvvPNOKyV1Do05X6tXr5bFYrnksX///lZM3PrWrl2rMWPGKDY2VhaLRUuWLPnW53jyddXY8+Wp19XMmTN1ww03KDg4WO3atdO4ceN04MCBb32eJ15bTTlXnnpdzZ07V8nJyfYvxEtLS9Py5cuv+hyzrinKzBX8/e9/15NPPqnnn39eO3bs0LBhwzR69Gjl5ORc9vijR4/q9ttv17Bhw7Rjxw4999xzeuKJJ7Rw4cJWTm6Oxp6vbxw4cECnTp2yP7p169ZKic1RVlamlJQUzZkzp0HHe/p11djz9Q1Pu67WrFmjxx57TOnp6friiy9UU1OjkSNHqqys7IrP8dRrqynn6huedl3FxcVp1qxZ2rp1q7Zu3apbbrlFY8eO1Z49ey57vKnXlIHLGjhwoPHwww/X29azZ09j6tSplz3+mWeeMXr27Flv249//GMjNTW1xTI6k8aer6+++sqQZJw/f74V0jknScbixYuveoynX1eOGnK+uK7q5OfnG5KMNWvWXPEYrq06DTlXXFf/0bZtW+NPf/rTZfeZeU3xycxlVFVVadu2bRo5cmS97SNHjtTGjRsv+5xNmzZdcvxtt92mrVu3qrq6usWyOoOmnK9v9OvXT+3bt9eIESP01VdftWRMl+TJ19W18PTrqqioSJIUHh5+xWO4tuo05Fx9w5Ovq9raWn300UcqKytTWlraZY8x85qizFxGQUGBamtrFR0dXW97dHS08vLyLvucvLy8yx5fU1OjgoKCFsvqDJpyvtq3b693331XCxcu1KJFi9SjRw+NGDFCa9eubY3ILsOTr6um4LqqW2n4qaee0tChQ9WnT58rHse11fBz5cnX1a5du9SmTRv5+fnp4Ycf1uLFi5WUlHTZY828ptx+1exrYbFY6v1sGMYl277t+Mttd1eNOV89evRQjx497D+npaUpNzdXv/71r3XjjTe2aE5X4+nXVWNwXUmPP/64MjMztX79+m891tOvrYaeK0++rnr06KGMjAwVFhZq4cKFmjJlitasWXPFQmPWNcUnM5cRGRkpLy+vSz5VyM/Pv6R1fiMmJuayx3t7eysiIqLFsjqDppyvy0lNTdXBgwebO55L8+Trqrl40nX1k5/8REuXLtVXX32luLi4qx7r6ddWY87V5XjKdeXr66uuXbtqwIABmjlzplJSUvTb3/72sseaeU1RZi7D19dX/fv31xdffFFv+xdffKHBgwdf9jlpaWmXHL9y5UoNGDBAPj4+LZbVGTTlfF3Ojh071L59++aO59I8+bpqLp5wXRmGoccff1yLFi3Sv//9b3Xq1Olbn+Op11ZTztXleMJ1dTmGYaiysvKy+0y9plr8FmMX9dFHHxk+Pj7Ge++9Z+zdu9d48sknjaCgIOPYsWOGYRjG1KlTjcmTJ9uPP3LkiBEYGGj87Gc/M/bu3Wu89957ho+Pj/HJJ5+Y9UdoVY09X2+99ZaxePFiIysry9i9e7cxdepUQ5KxcOFCs/4IraKkpMTYsWOHsWPHDkOS8eabbxo7duwwsrOzDcPguvpvjT1fnnpdPfLII0ZoaKixevVq49SpU/ZHeXm5/RiurTpNOVeeel1NmzbNWLt2rXH06FEjMzPTeO655wyr1WqsXLnSMAznuqYoM1fx+9//3khMTDR8fX2N66+/vt7UvSlTphg33XRTveNXr15t9OvXz/D19TU6duxozJ07t5UTm6sx52v27NlGly5dDH9/f6Nt27bG0KFDjWXLlpmQunV9M8Xzvx9TpkwxDIPr6r819nx56nV1uXMkyXj//fftx3Bt1WnKufLU6+qHP/yh/e/0qKgoY8SIEfYiYxjOdU1ZDOPi3TkAAAAuiHtmAACAS6PMAAAAl0aZAQAALo0yAwAAXBplBgAAuDTKDAAAcGmUGQAA4NIoMwAAwKVRZgB4BIvFoiVLlpgdA0ALoMwAaHEPPvigLBbLJY9Ro0aZHQ2AG/A2OwAAzzBq1Ci9//779bb5+fmZlAaAO+GTGQCtws/PTzExMfUebdu2lVQ3BDR37lyNHj1aAQEB6tSpkz7++ON6z9+1a5duueUWBQQEKCIiQg899JBKS0vrHfPnP/9ZvXv3lp+fn9q3b6/HH3+83v6CggKNHz9egYGB6tatm5YuXWrfd/78ed1///2KiopSQECAunXrdkn5AuCcKDMAnML06dM1ceJE7dy5U5MmTdK9996rffv2SZLKy8s1atQotW3bVl9//bU+/vhjrVq1ql5ZmTt3rh577DE99NBD2rVrl5YuXaquXbvW+x0vv/yy7rnnHmVmZur222/X/fffr3Pnztl//969e7V8+XLt27dPc+fOVWRkZOudAABN1yprcwPwaFOmTDG8vLyMoKCgeo9XXnnFMAzDkGQ8/PDD9Z4zaNAg45FHHjEMwzDeffddo23btkZpaal9/7Jlywyr1Wrk5eUZhmEYsbGxxvPPP3/FDJKMF154wf5zaWmpYbFYjOXLlxuGYRhjxowxfvCDHzTPHxhAq+KeGQCtYvjw4Zo7d269beHh4fb/TktLq7cvLS1NGRkZkqR9+/YpJSVFQUFB9v1DhgyRzWbTgQMHZLFYdPLkSY0YMeKqGZKTk+3/HRQUpODgYOXn50uSHnnkEU2cOFHbt2/XyJEjNW7cOA0ePLhJf1YArYsyA6BVBAUFXTLs820sFoskyTAM+39f7piAgIAGvZ6Pj88lz7XZbJKk0aNHKzs7W8uWLdOqVas0YsQIPfbYY/r1r3/dqMwAWh/3zABwCunp6Zf83LNnT0lSUlKSMjIyVFZWZt+/YcMGWa1Wde/eXcHBwerYsaO+/PLLa8oQFRWlBx98UPPnz9fbb7+td99995peD0Dr4JMZAK2isrJSeXl59bZ5e3vbb7L9+OOPNWDAAA0dOlQLFizQli1b9N5770mS7r//fr300kuaMmWKZsyYoTNnzugnP/mJJk+erOjoaEnSjBkz9PDDD6tdu3YaPXq0SkpKtGHDBv3kJz9pUL4XX3xR/fv3V+/evVVZWanPPvtMvXr1asYzAKClUGYAtIrPP/9c7du3r7etR48e2r9/v6S6mUYfffSRHn30UcXExGjBggVKSkqSJAUGBmrFihX66U9/qhtuuEGBgYGaOHGi3nzzTftrTZkyRRUVFXrrrbf0i1/8QpGRkbr77rsbnM/X11fTpk3TsWPHFBAQoGHDhumjjz5qhj85gJZmMQzDMDsEAM9msVi0ePFijRs3zuwoAFwQ98wAAACXRpkBAAAujXtmAJiO0W4A14JPZgAAgEujzAAAAJdGmQEAAC6NMgMAAFwaZQYAALg0ygwAAHBplBkAAODSKDMAAMCl/X9hh8Y4PWoM5gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( np.arange(0, len(loss_val)),loss_val)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "    return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)+ bias_ih), weights_ho)+bias_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0101010111  - predicted:  1\n",
      "0001010101  - predicted:  1\n",
      "0100011101  - predicted:  1\n",
      "Accuracy:  0.9970703125\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(x)):\n",
    "    y_p = 1 if predict(x[i])>0.5 else 0\n",
    "    if y[i]!=y_p:\n",
    "        count+=1\n",
    "        print(x[i], ' - predicted: ', y_p)\n",
    "print('Accuracy: ', (len(x) - count)/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
