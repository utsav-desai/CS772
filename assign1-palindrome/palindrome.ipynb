{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from faker import Faker\n",
    "import random\n",
    "np.random.seed()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "palindromes = []\n",
    "for i in range(1024):\n",
    "    binary_string = format(i, '010b')\n",
    "    x.append(binary_string)\n",
    "    if binary_string == binary_string[::-1]:\n",
    "        palindromes.append(binary_string)\n",
    "x = np.array(x)\n",
    "palindromes = np.array(palindromes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0000000000', '0000110000', '0001001000', '0001111000',\n",
       "       '0010000100', '0010110100', '0011001100', '0011111100',\n",
       "       '0100000010', '0100110010', '0101001010', '0101111010',\n",
       "       '0110000110', '0110110110', '0111001110', '0111111110',\n",
       "       '1000000001', '1000110001', '1001001001', '1001111001',\n",
       "       '1010000101', '1010110101', '1011001101', '1011111101',\n",
       "       '1100000011', '1100110011', '1101001011', '1101111011',\n",
       "       '1110000111', '1110110111', '1111001111', '1111111111'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0110110110', '1101001011', '0010110100', '0001001000',\n",
       "       '0110000110', '1011111101', '0100000010', '1010110101',\n",
       "       '0000000000', '0011111100', '1001001001', '0011001100',\n",
       "       '0111001110', '1011001101', '1001111001', '1000110001',\n",
       "       '1000000001', '0101001010', '1110110111', '0001111000',\n",
       "       '0111111110', '1110000111', '0010000100', '1101111011',\n",
       "       '0101111010', '1100110011', '1111001111', '0100110010',\n",
       "       '0000110000', '1100000011', '1111111111', '1010000101'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(palindromes)\n",
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = np.concatenate((x, palindromes))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for binary_string in x:\n",
    "    y.append(binary_string == binary_string[::-1])\n",
    "y = np.array(y)\n",
    "permutation_index = np.random.permutation(len(x))\n",
    "x = x[permutation_index]\n",
    "y = y[permutation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   6, -12])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.array([1, 2, -3])\n",
    "# b = np.array([2, 3, 4])\n",
    "# a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 20\n",
    "output_size = 1\n",
    "\n",
    "weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[991.61380209]]\n",
      "Epoch 100 : loss [[989.2316454]]\n",
      "Epoch 200 : loss [[319.53270712]]\n",
      "Epoch 300 : loss [[319.57421463]]\n",
      "Epoch 400 : loss [[319.61364199]]\n",
      "Epoch 500 : loss [[319.6512102]]\n",
      "Epoch 600 : loss [[319.6870946]]\n",
      "Epoch 700 : loss [[319.72143354]]\n",
      "Epoch 800 : loss [[319.75433739]]\n",
      "Epoch 900 : loss [[319.78589815]]\n",
      "Epoch 1000 : loss [[319.81620019]]\n",
      "Epoch 1100 : loss [[319.84533201]]\n",
      "Epoch 1200 : loss [[319.87339917]]\n",
      "Epoch 1300 : loss [[319.90053773]]\n",
      "Epoch 1400 : loss [[319.92692755]]\n",
      "Epoch 1500 : loss [[319.9528046]]\n",
      "Epoch 1600 : loss [[319.97847091]]\n",
      "Epoch 1700 : loss [[320.00430116]]\n",
      "Epoch 1800 : loss [[320.03074492]]\n",
      "Epoch 1900 : loss [[320.05832377]]\n",
      "Epoch 2000 : loss [[320.08762303]]\n",
      "Epoch 2100 : loss [[320.11927799]]\n",
      "Epoch 2200 : loss [[320.15395461]]\n",
      "Epoch 2300 : loss [[320.19232432]]\n",
      "Epoch 2400 : loss [[320.23503171]]\n",
      "Epoch 2500 : loss [[320.28265285]]\n",
      "Epoch 2600 : loss [[320.33564028]]\n",
      "Epoch 2700 : loss [[320.39424877]]\n",
      "Epoch 2800 : loss [[320.45843371]]\n",
      "Epoch 2900 : loss [[320.52771224]]\n",
      "Epoch 3000 : loss [[320.60097475]]\n",
      "Epoch 3100 : loss [[320.67623404]]\n",
      "Epoch 3200 : loss [[320.75029944]]\n",
      "Epoch 3300 : loss [[320.81836663]]\n",
      "Epoch 3400 : loss [[320.87352024]]\n",
      "Epoch 3500 : loss [[320.90615562]]\n",
      "Epoch 3600 : loss [[320.90333478]]\n",
      "Epoch 3700 : loss [[320.84808857]]\n",
      "Epoch 3800 : loss [[320.71864462]]\n",
      "Epoch 3900 : loss [[320.48748889]]\n",
      "Epoch 4000 : loss [[320.12009745]]\n",
      "Epoch 4100 : loss [[319.57321731]]\n",
      "Epoch 4200 : loss [[318.79283617]]\n",
      "Epoch 4300 : loss [[317.71237063]]\n",
      "Epoch 4400 : loss [[316.25183063]]\n",
      "Epoch 4500 : loss [[314.31860957]]\n",
      "Epoch 4600 : loss [[311.81032712]]\n",
      "Epoch 4700 : loss [[308.62023224]]\n",
      "Epoch 4800 : loss [[304.64616066]]\n",
      "Epoch 4900 : loss [[299.80425637]]\n",
      "Epoch 5000 : loss [[294.04706493]]\n",
      "Epoch 5100 : loss [[287.38122968]]\n",
      "Epoch 5200 : loss [[279.87587872]]\n",
      "Epoch 5300 : loss [[271.65535658]]\n",
      "Epoch 5400 : loss [[262.87946312]]\n",
      "Epoch 5500 : loss [[253.72091432]]\n",
      "Epoch 5600 : loss [[244.34743878]]\n",
      "Epoch 5700 : loss [[234.9103267]]\n",
      "Epoch 5800 : loss [[225.53835093]]\n",
      "Epoch 5900 : loss [[216.33570851]]\n",
      "Epoch 6000 : loss [[207.38289088]]\n",
      "Epoch 6100 : loss [[198.73939359]]\n",
      "Epoch 6200 : loss [[190.44717023]]\n",
      "Epoch 6300 : loss [[182.53397393]]\n",
      "Epoch 6400 : loss [[175.01614429]]\n",
      "Epoch 6500 : loss [[167.90077537]]\n",
      "Epoch 6600 : loss [[161.18740928]]\n",
      "Epoch 6700 : loss [[154.86944061]]\n",
      "Epoch 6800 : loss [[148.93536325]]\n",
      "Epoch 6900 : loss [[143.36991774]]\n",
      "Epoch 7000 : loss [[138.15514523]]\n",
      "Epoch 7100 : loss [[133.27133094]]\n",
      "Epoch 7200 : loss [[128.69781856]]\n",
      "Epoch 7300 : loss [[124.41368476]]\n",
      "Epoch 7400 : loss [[120.39827326]]\n",
      "Epoch 7500 : loss [[116.6315961]]\n",
      "Epoch 7600 : loss [[113.09461596]]\n",
      "Epoch 7700 : loss [[109.76942693]]\n",
      "Epoch 7800 : loss [[106.6393526]]\n",
      "Epoch 7900 : loss [[103.68898013]]\n",
      "Epoch 8000 : loss [[100.90414718]]\n",
      "Epoch 8100 : loss [[98.27189634]]\n",
      "Epoch 8200 : loss [[95.78040878]]\n",
      "Epoch 8300 : loss [[93.41892608]]\n",
      "Epoch 8400 : loss [[91.1776669]]\n",
      "Epoch 8500 : loss [[89.04774305]]\n",
      "Epoch 8600 : loss [[87.02107814]]\n",
      "Epoch 8700 : loss [[85.09033038]]\n",
      "Epoch 8800 : loss [[83.24882098]]\n",
      "Epoch 8900 : loss [[81.49046816]]\n",
      "Epoch 9000 : loss [[79.80972729]]\n",
      "Epoch 9100 : loss [[78.20153656]]\n",
      "Epoch 9200 : loss [[76.66126823]]\n",
      "Epoch 9300 : loss [[75.18468479]]\n",
      "Epoch 9400 : loss [[73.7678998]]\n",
      "Epoch 9500 : loss [[72.40734284]]\n",
      "Epoch 9600 : loss [[71.09972829]]\n",
      "Epoch 9700 : loss [[69.84202742]]\n",
      "Epoch 9800 : loss [[68.63144352]]\n",
      "Epoch 9900 : loss [[67.46538972]]\n"
     ]
    }
   ],
   "source": [
    "# LEARNING_RATE = 1e-7\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[0.70983834]]\n",
      "Epoch 100 : loss [[0.7091767]]\n",
      "Epoch 200 : loss [[0.70852412]]\n",
      "Epoch 300 : loss [[0.70787714]]\n",
      "Epoch 400 : loss [[0.70723423]]\n",
      "Epoch 500 : loss [[0.70659466]]\n",
      "Epoch 600 : loss [[0.70595803]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m hlayer_output \u001b[38;5;241m=\u001b[39m sigmoid(hlayer_logits)\n\u001b[1;32m      9\u001b[0m final_logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(hlayer_output, weights_ho)\n\u001b[0;32m---> 10\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tot_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(final_output \u001b[38;5;241m-\u001b[39m y[i])\n\u001b[1;32m     14\u001b[0m output_delta \u001b[38;5;241m=\u001b[39m (y[i] \u001b[38;5;241m-\u001b[39m final_output) \u001b[38;5;241m*\u001b[39m final_output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m final_output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99802693]]\n",
      "[[9.87927878e-05]]\n"
     ]
    }
   ],
   "source": [
    "x_test1 = '1100110011'\n",
    "x_test2 = '1100110000'\n",
    "def test(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "    return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)), weights_ho))\n",
    "\n",
    "print(test(x_test1))\n",
    "print(test(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('weights_ih.npy', weights_ih)\n",
    "# np.save('weights_ho.npy', weights_ho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/screa/Desktop/Sem8/CS772/assign1-palindrome/utils/dataset.py:29: UserWarning: you are shuffling a 'flatiter' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(x.flat)\n"
     ]
    }
   ],
   "source": [
    "from utils import activation, dataset, losses\n",
    "from model import *\n",
    "import numpy as np\n",
    "np.random.seed(69)\n",
    "Dataset = dataset.Palindrome_Dataset(n_bits=10)\n",
    "x,y = Dataset.get_data(shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Palindrome_Model(input_size=10, output_size=1,hidden_layer_sizes=[4],activation='sigmoid')\n",
    "model.set_optimizer(lr=0.05,loss=\"bce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
       "  'weights': array([[-0.66671244,  0.27584906,  0.45746696,  0.34142165],\n",
       "         [-0.59328423,  0.33506782,  0.6972347 ,  0.00571596],\n",
       "         [ 0.16764539, -0.27528718, -0.02836811, -0.35491832],\n",
       "         [ 0.40034717, -0.4723468 , -0.03012224,  0.8823068 ],\n",
       "         [ 0.20490132, -0.32070796,  0.51737629,  0.0434112 ],\n",
       "         [ 0.67059023, -0.55523346, -0.35980269, -0.64517725],\n",
       "         [-0.33813533,  0.27334062, -0.15238505, -0.31374416],\n",
       "         [-0.50290407, -0.63334161,  0.36329252, -0.46156737],\n",
       "         [ 0.20827329,  0.27135127,  0.02282076,  0.63659534],\n",
       "         [-0.19128657,  0.57028767,  0.1844029 ,  0.06498939]]),\n",
       "  'biases': array([-0.43185221,  1.09176892,  0.36026298,  0.16690494]),\n",
       "  'activation': 'linear'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[ 0.9549052 ],\n",
       "         [-0.03173784],\n",
       "         [-0.29071454],\n",
       "         [-0.22821522]]),\n",
       "  'biases': array([0.57417091]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1024/1024 [00:01<00:00, 925.03sample/s, loss=0.0462]   \n",
      "Epoch 2/10: 100%|██████████| 1024/1024 [00:01<00:00, 853.99sample/s, loss=0.0241]  \n",
      "Epoch 3/10: 100%|██████████| 1024/1024 [00:01<00:00, 955.67sample/s, loss=0.0163]  \n",
      "Epoch 4/10: 100%|██████████| 1024/1024 [00:00<00:00, 1109.23sample/s, loss=0.0124]  \n",
      "Epoch 5/10: 100%|██████████| 1024/1024 [00:00<00:00, 1115.90sample/s, loss=0.00996] \n",
      "Epoch 6/10: 100%|██████████| 1024/1024 [00:00<00:00, 1127.81sample/s, loss=0.00834] \n",
      "Epoch 7/10: 100%|██████████| 1024/1024 [00:00<00:00, 1053.85sample/s, loss=0.00716] \n",
      "Epoch 8/10: 100%|██████████| 1024/1024 [00:00<00:00, 1065.52sample/s, loss=0.00628] \n",
      "Epoch 9/10: 100%|██████████| 1024/1024 [00:00<00:00, 1107.72sample/s, loss=0.00559] \n",
      "Epoch 10/10: 100%|██████████| 1024/1024 [00:00<00:00, 1086.26sample/s, loss=0.00503]\n"
     ]
    }
   ],
   "source": [
    "model.train(x,y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sem8",
   "language": "python",
   "name": "env_sem8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
