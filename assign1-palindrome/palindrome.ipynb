{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from faker import Faker\n",
    "import random\n",
    "np.random.seed()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "palindromes = []\n",
    "for i in range(1024):\n",
    "    binary_string = format(i, '010b')\n",
    "    x.append(binary_string)\n",
    "    if binary_string == binary_string[::-1]:\n",
    "        palindromes.append(binary_string)\n",
    "x = np.array(x)\n",
    "palindromes = np.array(palindromes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0000000000', '0000110000', '0001001000', '0001111000',\n",
       "       '0010000100', '0010110100', '0011001100', '0011111100',\n",
       "       '0100000010', '0100110010', '0101001010', '0101111010',\n",
       "       '0110000110', '0110110110', '0111001110', '0111111110',\n",
       "       '1000000001', '1000110001', '1001001001', '1001111001',\n",
       "       '1010000101', '1010110101', '1011001101', '1011111101',\n",
       "       '1100000011', '1100110011', '1101001011', '1101111011',\n",
       "       '1110000111', '1110110111', '1111001111', '1111111111'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0110110110', '1101001011', '0010110100', '0001001000',\n",
       "       '0110000110', '1011111101', '0100000010', '1010110101',\n",
       "       '0000000000', '0011111100', '1001001001', '0011001100',\n",
       "       '0111001110', '1011001101', '1001111001', '1000110001',\n",
       "       '1000000001', '0101001010', '1110110111', '0001111000',\n",
       "       '0111111110', '1110000111', '0010000100', '1101111011',\n",
       "       '0101111010', '1100110011', '1111001111', '0100110010',\n",
       "       '0000110000', '1100000011', '1111111111', '1010000101'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(palindromes)\n",
    "print(len(palindromes))\n",
    "palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = np.concatenate((x, palindromes))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for binary_string in x:\n",
    "    y.append(binary_string == binary_string[::-1])\n",
    "y = np.array(y)\n",
    "permutation_index = np.random.permutation(len(x))\n",
    "x = x[permutation_index]\n",
    "y = y[permutation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   6, -12])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.array([1, 2, -3])\n",
    "# b = np.array([2, 3, 4])\n",
    "# a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "input_size = 10\n",
    "hidden_layer_size = 20\n",
    "output_size = 1\n",
    "\n",
    "weights_ih = np.random.rand(input_size, hidden_layer_size)\n",
    "weights_ho = np.random.rand(hidden_layer_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[991.61380209]]\n",
      "Epoch 100 : loss [[989.2316454]]\n",
      "Epoch 200 : loss [[319.53270712]]\n",
      "Epoch 300 : loss [[319.57421463]]\n",
      "Epoch 400 : loss [[319.61364199]]\n",
      "Epoch 500 : loss [[319.6512102]]\n",
      "Epoch 600 : loss [[319.6870946]]\n",
      "Epoch 700 : loss [[319.72143354]]\n",
      "Epoch 800 : loss [[319.75433739]]\n",
      "Epoch 900 : loss [[319.78589815]]\n",
      "Epoch 1000 : loss [[319.81620019]]\n",
      "Epoch 1100 : loss [[319.84533201]]\n",
      "Epoch 1200 : loss [[319.87339917]]\n",
      "Epoch 1300 : loss [[319.90053773]]\n",
      "Epoch 1400 : loss [[319.92692755]]\n",
      "Epoch 1500 : loss [[319.9528046]]\n",
      "Epoch 1600 : loss [[319.97847091]]\n",
      "Epoch 1700 : loss [[320.00430116]]\n",
      "Epoch 1800 : loss [[320.03074492]]\n",
      "Epoch 1900 : loss [[320.05832377]]\n",
      "Epoch 2000 : loss [[320.08762303]]\n",
      "Epoch 2100 : loss [[320.11927799]]\n",
      "Epoch 2200 : loss [[320.15395461]]\n",
      "Epoch 2300 : loss [[320.19232432]]\n",
      "Epoch 2400 : loss [[320.23503171]]\n",
      "Epoch 2500 : loss [[320.28265285]]\n",
      "Epoch 2600 : loss [[320.33564028]]\n",
      "Epoch 2700 : loss [[320.39424877]]\n",
      "Epoch 2800 : loss [[320.45843371]]\n",
      "Epoch 2900 : loss [[320.52771224]]\n",
      "Epoch 3000 : loss [[320.60097475]]\n",
      "Epoch 3100 : loss [[320.67623404]]\n",
      "Epoch 3200 : loss [[320.75029944]]\n",
      "Epoch 3300 : loss [[320.81836663]]\n",
      "Epoch 3400 : loss [[320.87352024]]\n",
      "Epoch 3500 : loss [[320.90615562]]\n",
      "Epoch 3600 : loss [[320.90333478]]\n",
      "Epoch 3700 : loss [[320.84808857]]\n",
      "Epoch 3800 : loss [[320.71864462]]\n",
      "Epoch 3900 : loss [[320.48748889]]\n",
      "Epoch 4000 : loss [[320.12009745]]\n",
      "Epoch 4100 : loss [[319.57321731]]\n",
      "Epoch 4200 : loss [[318.79283617]]\n",
      "Epoch 4300 : loss [[317.71237063]]\n",
      "Epoch 4400 : loss [[316.25183063]]\n",
      "Epoch 4500 : loss [[314.31860957]]\n",
      "Epoch 4600 : loss [[311.81032712]]\n",
      "Epoch 4700 : loss [[308.62023224]]\n",
      "Epoch 4800 : loss [[304.64616066]]\n",
      "Epoch 4900 : loss [[299.80425637]]\n",
      "Epoch 5000 : loss [[294.04706493]]\n",
      "Epoch 5100 : loss [[287.38122968]]\n",
      "Epoch 5200 : loss [[279.87587872]]\n",
      "Epoch 5300 : loss [[271.65535658]]\n",
      "Epoch 5400 : loss [[262.87946312]]\n",
      "Epoch 5500 : loss [[253.72091432]]\n",
      "Epoch 5600 : loss [[244.34743878]]\n",
      "Epoch 5700 : loss [[234.9103267]]\n",
      "Epoch 5800 : loss [[225.53835093]]\n",
      "Epoch 5900 : loss [[216.33570851]]\n",
      "Epoch 6000 : loss [[207.38289088]]\n",
      "Epoch 6100 : loss [[198.73939359]]\n",
      "Epoch 6200 : loss [[190.44717023]]\n",
      "Epoch 6300 : loss [[182.53397393]]\n",
      "Epoch 6400 : loss [[175.01614429]]\n",
      "Epoch 6500 : loss [[167.90077537]]\n",
      "Epoch 6600 : loss [[161.18740928]]\n",
      "Epoch 6700 : loss [[154.86944061]]\n",
      "Epoch 6800 : loss [[148.93536325]]\n",
      "Epoch 6900 : loss [[143.36991774]]\n",
      "Epoch 7000 : loss [[138.15514523]]\n",
      "Epoch 7100 : loss [[133.27133094]]\n",
      "Epoch 7200 : loss [[128.69781856]]\n",
      "Epoch 7300 : loss [[124.41368476]]\n",
      "Epoch 7400 : loss [[120.39827326]]\n",
      "Epoch 7500 : loss [[116.6315961]]\n",
      "Epoch 7600 : loss [[113.09461596]]\n",
      "Epoch 7700 : loss [[109.76942693]]\n",
      "Epoch 7800 : loss [[106.6393526]]\n",
      "Epoch 7900 : loss [[103.68898013]]\n",
      "Epoch 8000 : loss [[100.90414718]]\n",
      "Epoch 8100 : loss [[98.27189634]]\n",
      "Epoch 8200 : loss [[95.78040878]]\n",
      "Epoch 8300 : loss [[93.41892608]]\n",
      "Epoch 8400 : loss [[91.1776669]]\n",
      "Epoch 8500 : loss [[89.04774305]]\n",
      "Epoch 8600 : loss [[87.02107814]]\n",
      "Epoch 8700 : loss [[85.09033038]]\n",
      "Epoch 8800 : loss [[83.24882098]]\n",
      "Epoch 8900 : loss [[81.49046816]]\n",
      "Epoch 9000 : loss [[79.80972729]]\n",
      "Epoch 9100 : loss [[78.20153656]]\n",
      "Epoch 9200 : loss [[76.66126823]]\n",
      "Epoch 9300 : loss [[75.18468479]]\n",
      "Epoch 9400 : loss [[73.7678998]]\n",
      "Epoch 9500 : loss [[72.40734284]]\n",
      "Epoch 9600 : loss [[71.09972829]]\n",
      "Epoch 9700 : loss [[69.84202742]]\n",
      "Epoch 9800 : loss [[68.63144352]]\n",
      "Epoch 9900 : loss [[67.46538972]]\n"
     ]
    }
   ],
   "source": [
    "# LEARNING_RATE = 1e-7\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss [[0.70983834]]\n",
      "Epoch 100 : loss [[0.7091767]]\n",
      "Epoch 200 : loss [[0.70852412]]\n",
      "Epoch 300 : loss [[0.70787714]]\n",
      "Epoch 400 : loss [[0.70723423]]\n",
      "Epoch 500 : loss [[0.70659466]]\n",
      "Epoch 600 : loss [[0.70595803]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m hlayer_output \u001b[38;5;241m=\u001b[39m sigmoid(hlayer_logits)\n\u001b[1;32m      9\u001b[0m final_logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(hlayer_output, weights_ho)\n\u001b[0;32m---> 10\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tot_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(final_output \u001b[38;5;241m-\u001b[39m y[i])\n\u001b[1;32m     14\u001b[0m output_delta \u001b[38;5;241m=\u001b[39m (y[i] \u001b[38;5;241m-\u001b[39m final_output) \u001b[38;5;241m*\u001b[39m final_output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m final_output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i, s in enumerate(x):\n",
    "        inp = np.reshape(np.array([int(char) for char in s]), (1, input_size))\n",
    "        hlayer_logits = np.dot(inp, weights_ih)\n",
    "        hlayer_output = sigmoid(hlayer_logits)\n",
    "\n",
    "        final_logits = np.dot(hlayer_output, weights_ho)\n",
    "        final_output = sigmoid(final_logits)\n",
    "\n",
    "        tot_loss += abs(final_output - y[i])\n",
    "\n",
    "        output_delta = (y[i] - final_output) * final_output * (1 - final_output)\n",
    "\n",
    "        weights_ho += LEARNING_RATE * hlayer_output.T.dot(output_delta)\n",
    "        weights_ih += LEARNING_RATE * inp.T.dot(output_delta.dot(weights_ho.T) * hlayer_output * (1 - hlayer_output))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} : loss {tot_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99802693]]\n",
      "[[9.87927878e-05]]\n"
     ]
    }
   ],
   "source": [
    "x_test1 = '1100110011'\n",
    "x_test2 = '1100110000'\n",
    "def test(x):\n",
    "    inp = np.reshape(np.array([int(char) for char in x]), (1, input_size))\n",
    "    return sigmoid(np.dot(sigmoid(np.dot(inp, weights_ih)), weights_ho))\n",
    "\n",
    "print(test(x_test1))\n",
    "print(test(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('weights_ih.npy', weights_ih)\n",
    "# np.save('weights_ho.npy', weights_ho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/screa/Desktop/Sem8/CS772/assign1-palindrome/utils/dataset.py:29: UserWarning: you are shuffling a 'flatiter' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(x.flat)\n"
     ]
    }
   ],
   "source": [
    "from utils import activation, dataset, losses\n",
    "from model import *\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "Dataset = dataset.Palindrome_Dataset(n_bits=10)\n",
    "x,y = Dataset.get_data(shuffle=True, biasing_factor=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Palindrome_Model(input_size=10, output_size=1,hidden_layer_sizes=[5],activation='sigmoid')\n",
    "model.set_optimizer(lr=0.001,loss=\"bce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
       "  'weights': array([[ 0.93264673,  0.97459294, -0.12848894,  0.58921758, -0.61967231],\n",
       "         [-0.26271703, -0.26330762, -0.93215773,  0.19383003, -1.06437594],\n",
       "         [ 0.40447317, -0.24151142, -0.44076791, -0.58080072, -0.21027712],\n",
       "         [-0.61963486, -0.21196891, -0.25251799, -0.36971576, -0.07134193],\n",
       "         [-0.01738654,  0.49040936, -0.42500098, -0.1270861 , -0.82970687],\n",
       "         [ 0.77321702,  0.29156391, -0.54454293,  0.42967041, -0.02238592],\n",
       "         [-0.17803028,  0.43492721,  0.39676217, -0.09361975,  0.69012828],\n",
       "         [ 0.31874703,  0.4822464 ,  0.3571908 ,  0.47563312,  0.07272139],\n",
       "         [-0.3682124 , -0.29333473, -0.16815552,  0.40137652,  0.59679054],\n",
       "         [-0.80576963,  0.08172214, -0.04323667,  1.08809504, -0.63949919]]),\n",
       "  'biases': array([ 0.94157707, -0.80524722, -0.18663932, -0.45803375,  0.63432525]),\n",
       "  'activation': 'linear'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[-0.03617254],\n",
       "         [ 0.32353074],\n",
       "         [-0.37830158],\n",
       "         [-0.51640216],\n",
       "         [-0.58137544]]),\n",
       "  'biases': array([-1.98126497]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolving Bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_palindromes = np.array([np.reshape(np.array([int(char) for char in s]), (10,)) for s in Dataset.palindromes])\n",
    "# y_palindromes = np.array([1]*32)\n",
    "# accuracies, losses = model.train(x_palindromes,y_palindromes,epochs=1000)\n",
    "# predictions = model.predict(x_palindromes)\n",
    "# print(predictions)\n",
    "# accuracy_metric(predictions, y_palindromes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(model,X:np.ndarray, y:np.ndarray, k_folds:int = 4, epochs_per_fold:int = 25):\n",
    "        fold_size = len(X) // k_folds\n",
    "        accuracies_fold = []\n",
    "        accuracies=[]\n",
    "        losses = []\n",
    "        for i in range(k_folds):\n",
    "            start, end = i * fold_size, (i + 1) * fold_size\n",
    "            X_test_fold, y_test_fold = X[start:end], y[start:end]\n",
    "            X_train_fold = np.concatenate([X[:start], X[end:]])\n",
    "            y_train_fold = np.concatenate([y[:start], y[end:]])\n",
    "            print(f\"Training Fold {i+1}\\n\")\n",
    "            accuracy, loss = model.train(X_train_fold, y_train_fold, epochs_per_fold)\n",
    "            accuracies.extend(accuracy)\n",
    "            losses.extend(loss)\n",
    "            print(\"\\n\"+10*\"----\"+\"\\n\")\n",
    "            predictions = model.predict(X_test_fold)\n",
    "            accuracies_fold.append(accuracy_metric(predictions, y_test_fold))\n",
    "        return accuracies_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 5013.55sample/s, accuracy=51.7, loss=419]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 5751.69sample/s, accuracy=55.4, loss=227]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5245.13sample/s, accuracy=54.8, loss=191]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 4928.89sample/s, accuracy=56, loss=175]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 4581.24sample/s, accuracy=56.4, loss=163]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 4826.38sample/s, accuracy=54.6, loss=154]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 5126.53sample/s, accuracy=55.3, loss=146]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5346.22sample/s, accuracy=56.1, loss=140]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 3759.49sample/s, accuracy=56.4, loss=134]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 4844.72sample/s, accuracy=56.7, loss=130]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5192.32sample/s, accuracy=56.7, loss=126]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 5101.14sample/s, accuracy=57.2, loss=122]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 4307.43sample/s, accuracy=57.4, loss=119]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 4853.65sample/s, accuracy=57.9, loss=117]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 4375.11sample/s, accuracy=58.1, loss=114]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 4862.63sample/s, accuracy=58.2, loss=112]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 4781.58sample/s, accuracy=58.5, loss=110]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5370.91sample/s, accuracy=58.9, loss=108]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 5237.86sample/s, accuracy=59.2, loss=106]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 5522.62sample/s, accuracy=59.4, loss=105]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 5138.02sample/s, accuracy=59.7, loss=103]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 5504.78sample/s, accuracy=58.5, loss=102]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 5597.66sample/s, accuracy=58.5, loss=101]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 5409.35sample/s, accuracy=58.8, loss=99.8]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 5232.36sample/s, accuracy=58.9, loss=98.7]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5746.11sample/s, accuracy=58.9, loss=97.7]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5469.94sample/s, accuracy=59, loss=96.8]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5551.11sample/s, accuracy=59.1, loss=95.9]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5221.56sample/s, accuracy=59.1, loss=95]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5219.06sample/s, accuracy=59.1, loss=94.2]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5266.39sample/s, accuracy=59.2, loss=93.5]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 5683.44sample/s, accuracy=59.3, loss=92.8]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 5751.22sample/s, accuracy=59.4, loss=92.1]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5513.50sample/s, accuracy=59.5, loss=91.4]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 5597.73sample/s, accuracy=59.5, loss=90.8]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5658.52sample/s, accuracy=59.5, loss=90.2]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5509.52sample/s, accuracy=59.5, loss=89.7]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 5603.34sample/s, accuracy=59.5, loss=89.2]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 5659.25sample/s, accuracy=59.5, loss=88.7]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 5383.79sample/s, accuracy=59.5, loss=88.2]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 5715.08sample/s, accuracy=59.5, loss=87.7]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5677.64sample/s, accuracy=59.5, loss=87.3]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5491.72sample/s, accuracy=59.5, loss=86.8]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 5741.78sample/s, accuracy=59.5, loss=86.4]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 5587.66sample/s, accuracy=59.5, loss=86]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 5599.87sample/s, accuracy=59.5, loss=85.7]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 5627.91sample/s, accuracy=59.5, loss=85.3]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 5581.25sample/s, accuracy=59.5, loss=85]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 5695.99sample/s, accuracy=59.5, loss=84.6]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 5611.25sample/s, accuracy=59.5, loss=84.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 4186.46sample/s, accuracy=59.5, loss=87.8]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 5070.41sample/s, accuracy=59.5, loss=88.8]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5379.48sample/s, accuracy=59.5, loss=88.6]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5689.36sample/s, accuracy=59.5, loss=88.2]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 4348.28sample/s, accuracy=59.5, loss=87.8]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 4976.49sample/s, accuracy=59.5, loss=87.4]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 5244.10sample/s, accuracy=59.5, loss=87]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5529.90sample/s, accuracy=59.5, loss=86.6]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 5614.90sample/s, accuracy=59.5, loss=86.2]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 5791.47sample/s, accuracy=59.5, loss=85.7]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5657.52sample/s, accuracy=59.5, loss=85.3]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 5850.21sample/s, accuracy=59.5, loss=85]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 5736.64sample/s, accuracy=59.5, loss=84.6]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 5599.43sample/s, accuracy=59.5, loss=84.2]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 5725.74sample/s, accuracy=59.5, loss=83.9]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 5678.14sample/s, accuracy=59.5, loss=83.5]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 5571.60sample/s, accuracy=59.5, loss=83.2]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 3978.21sample/s, accuracy=59.5, loss=82.9]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 5182.22sample/s, accuracy=59.5, loss=82.6]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 5527.52sample/s, accuracy=59.5, loss=82.3]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 5464.93sample/s, accuracy=59.5, loss=82]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 5705.96sample/s, accuracy=59.5, loss=81.8]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 5701.68sample/s, accuracy=59.5, loss=81.5]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 5687.32sample/s, accuracy=59.5, loss=81.3]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 5565.59sample/s, accuracy=59.5, loss=81]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5844.88sample/s, accuracy=59.5, loss=80.8]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5783.02sample/s, accuracy=59.5, loss=80.6]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5845.79sample/s, accuracy=59.5, loss=80.3]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5769.72sample/s, accuracy=59.5, loss=80.1]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5703.82sample/s, accuracy=59.5, loss=79.9]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5811.01sample/s, accuracy=59.5, loss=79.7]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 5663.06sample/s, accuracy=59.5, loss=79.6]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 5728.21sample/s, accuracy=59.5, loss=79.4]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5643.75sample/s, accuracy=59.5, loss=79.2]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 5781.13sample/s, accuracy=59.5, loss=79]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5724.29sample/s, accuracy=59.5, loss=78.9]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5783.19sample/s, accuracy=59.5, loss=78.7]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 5847.10sample/s, accuracy=59.5, loss=78.5]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 5576.71sample/s, accuracy=59.5, loss=78.4]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 5549.51sample/s, accuracy=59.5, loss=78.2]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 5686.21sample/s, accuracy=59.5, loss=78.1]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5696.43sample/s, accuracy=59.5, loss=78]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5658.39sample/s, accuracy=59.5, loss=77.8]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 4008.68sample/s, accuracy=59.5, loss=77.7]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 3893.25sample/s, accuracy=59.5, loss=77.6]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 4547.94sample/s, accuracy=59.5, loss=77.5]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 3600.45sample/s, accuracy=59.5, loss=77.3]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 3706.88sample/s, accuracy=59.5, loss=77.2]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 4604.01sample/s, accuracy=59.5, loss=77.1]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 4981.62sample/s, accuracy=59.5, loss=77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 4017.78sample/s, accuracy=60.8, loss=73.4]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 4830.99sample/s, accuracy=60.8, loss=81.3]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 4321.06sample/s, accuracy=60.8, loss=82.1]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 3484.23sample/s, accuracy=60.8, loss=82.2]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 4326.22sample/s, accuracy=60.8, loss=82.2]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 4874.23sample/s, accuracy=60.8, loss=82.3]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 5236.84sample/s, accuracy=60.8, loss=82.4]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5432.57sample/s, accuracy=60.8, loss=82.5]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 5798.83sample/s, accuracy=60.8, loss=82.6]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 5593.56sample/s, accuracy=60.8, loss=82.7]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 5957.47sample/s, accuracy=60.8, loss=82.7]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 6088.60sample/s, accuracy=60.8, loss=82.8]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 5877.46sample/s, accuracy=60.8, loss=82.9]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 6000.50sample/s, accuracy=60.8, loss=83]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 6064.12sample/s, accuracy=60.8, loss=83.1]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 5844.75sample/s, accuracy=60.8, loss=83.2]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 5960.00sample/s, accuracy=60.8, loss=83.2]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5712.39sample/s, accuracy=60.8, loss=83.3]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 5772.91sample/s, accuracy=60.8, loss=83.4]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 5840.11sample/s, accuracy=60.8, loss=83.4]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 5819.45sample/s, accuracy=60.8, loss=83.5]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 5980.75sample/s, accuracy=60.8, loss=83.5]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 5610.07sample/s, accuracy=60.8, loss=83.5]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 5896.42sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 5956.91sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 6020.88sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 5981.15sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5986.46sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 5962.89sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5848.44sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5592.96sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 5566.03sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 5733.19sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5937.28sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 5752.85sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5734.33sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5833.63sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 4405.92sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 5158.28sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 4823.92sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 5258.82sample/s, accuracy=60.8, loss=83.7]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5605.64sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5040.74sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 5615.91sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 5627.22sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 5212.54sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 5532.11sample/s, accuracy=60.8, loss=83.6]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 5634.42sample/s, accuracy=60.8, loss=83.5]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 5449.46sample/s, accuracy=60.8, loss=83.5]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 5860.40sample/s, accuracy=60.8, loss=83.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Fold 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1248/1248 [00:00<00:00, 5033.41sample/s, accuracy=58.7, loss=104]\n",
      "Epoch 2/50: 100%|██████████| 1248/1248 [00:00<00:00, 5026.81sample/s, accuracy=58.7, loss=71.1]\n",
      "Epoch 3/50: 100%|██████████| 1248/1248 [00:00<00:00, 5457.27sample/s, accuracy=58.7, loss=67.8]\n",
      "Epoch 4/50: 100%|██████████| 1248/1248 [00:00<00:00, 5821.99sample/s, accuracy=58.7, loss=68.1]\n",
      "Epoch 5/50: 100%|██████████| 1248/1248 [00:00<00:00, 6013.28sample/s, accuracy=58.7, loss=68.7]\n",
      "Epoch 6/50: 100%|██████████| 1248/1248 [00:00<00:00, 5970.46sample/s, accuracy=58.7, loss=69.1]\n",
      "Epoch 7/50: 100%|██████████| 1248/1248 [00:00<00:00, 6091.27sample/s, accuracy=58.7, loss=69.4]\n",
      "Epoch 8/50: 100%|██████████| 1248/1248 [00:00<00:00, 5765.34sample/s, accuracy=58.7, loss=69.6]\n",
      "Epoch 9/50: 100%|██████████| 1248/1248 [00:00<00:00, 6142.77sample/s, accuracy=58.7, loss=69.7]\n",
      "Epoch 10/50: 100%|██████████| 1248/1248 [00:00<00:00, 5962.26sample/s, accuracy=58.7, loss=69.7]\n",
      "Epoch 11/50: 100%|██████████| 1248/1248 [00:00<00:00, 6148.63sample/s, accuracy=58.7, loss=69.7]\n",
      "Epoch 12/50: 100%|██████████| 1248/1248 [00:00<00:00, 6130.59sample/s, accuracy=58.7, loss=69.7]\n",
      "Epoch 13/50: 100%|██████████| 1248/1248 [00:00<00:00, 5959.27sample/s, accuracy=58.7, loss=69.6]\n",
      "Epoch 14/50: 100%|██████████| 1248/1248 [00:00<00:00, 6232.06sample/s, accuracy=58.7, loss=69.6]\n",
      "Epoch 15/50: 100%|██████████| 1248/1248 [00:00<00:00, 6149.35sample/s, accuracy=58.7, loss=69.5]\n",
      "Epoch 16/50: 100%|██████████| 1248/1248 [00:00<00:00, 5991.31sample/s, accuracy=58.7, loss=69.4]\n",
      "Epoch 17/50: 100%|██████████| 1248/1248 [00:00<00:00, 6056.24sample/s, accuracy=58.7, loss=69.3]\n",
      "Epoch 18/50: 100%|██████████| 1248/1248 [00:00<00:00, 5806.60sample/s, accuracy=58.7, loss=69.3]\n",
      "Epoch 19/50: 100%|██████████| 1248/1248 [00:00<00:00, 6015.45sample/s, accuracy=58.7, loss=69.2]\n",
      "Epoch 20/50: 100%|██████████| 1248/1248 [00:00<00:00, 5834.52sample/s, accuracy=58.7, loss=69.1]\n",
      "Epoch 21/50: 100%|██████████| 1248/1248 [00:00<00:00, 5703.34sample/s, accuracy=58.7, loss=69]\n",
      "Epoch 22/50: 100%|██████████| 1248/1248 [00:00<00:00, 5973.70sample/s, accuracy=58.7, loss=68.9]\n",
      "Epoch 23/50: 100%|██████████| 1248/1248 [00:00<00:00, 5978.31sample/s, accuracy=58.7, loss=68.9]\n",
      "Epoch 24/50: 100%|██████████| 1248/1248 [00:00<00:00, 6101.05sample/s, accuracy=58.7, loss=68.8]\n",
      "Epoch 25/50: 100%|██████████| 1248/1248 [00:00<00:00, 6084.47sample/s, accuracy=58.7, loss=68.7]\n",
      "Epoch 26/50: 100%|██████████| 1248/1248 [00:00<00:00, 5863.63sample/s, accuracy=58.7, loss=68.6]\n",
      "Epoch 27/50: 100%|██████████| 1248/1248 [00:00<00:00, 6085.77sample/s, accuracy=58.7, loss=68.6]\n",
      "Epoch 28/50: 100%|██████████| 1248/1248 [00:00<00:00, 5979.95sample/s, accuracy=58.7, loss=68.5]\n",
      "Epoch 29/50: 100%|██████████| 1248/1248 [00:00<00:00, 4694.16sample/s, accuracy=58.7, loss=68.5]\n",
      "Epoch 30/50: 100%|██████████| 1248/1248 [00:00<00:00, 5606.17sample/s, accuracy=58.7, loss=68.4]\n",
      "Epoch 31/50: 100%|██████████| 1248/1248 [00:00<00:00, 5780.49sample/s, accuracy=58.7, loss=68.4]\n",
      "Epoch 32/50: 100%|██████████| 1248/1248 [00:00<00:00, 5793.13sample/s, accuracy=58.7, loss=68.3]\n",
      "Epoch 33/50: 100%|██████████| 1248/1248 [00:00<00:00, 5928.69sample/s, accuracy=58.7, loss=68.3]\n",
      "Epoch 34/50: 100%|██████████| 1248/1248 [00:00<00:00, 5652.07sample/s, accuracy=58.7, loss=68.2]\n",
      "Epoch 35/50: 100%|██████████| 1248/1248 [00:00<00:00, 5578.47sample/s, accuracy=58.7, loss=68.2]\n",
      "Epoch 36/50: 100%|██████████| 1248/1248 [00:00<00:00, 5657.86sample/s, accuracy=58.7, loss=68.1]\n",
      "Epoch 37/50: 100%|██████████| 1248/1248 [00:00<00:00, 5926.44sample/s, accuracy=58.7, loss=68.1]\n",
      "Epoch 38/50: 100%|██████████| 1248/1248 [00:00<00:00, 5741.32sample/s, accuracy=58.7, loss=68]\n",
      "Epoch 39/50: 100%|██████████| 1248/1248 [00:00<00:00, 5354.48sample/s, accuracy=58.7, loss=68]\n",
      "Epoch 40/50: 100%|██████████| 1248/1248 [00:00<00:00, 5154.11sample/s, accuracy=58.7, loss=68]\n",
      "Epoch 41/50: 100%|██████████| 1248/1248 [00:00<00:00, 5150.03sample/s, accuracy=58.7, loss=67.9]\n",
      "Epoch 42/50: 100%|██████████| 1248/1248 [00:00<00:00, 5420.62sample/s, accuracy=58.7, loss=67.9]\n",
      "Epoch 43/50: 100%|██████████| 1248/1248 [00:00<00:00, 5564.43sample/s, accuracy=58.7, loss=67.9]\n",
      "Epoch 44/50: 100%|██████████| 1248/1248 [00:00<00:00, 4420.00sample/s, accuracy=58.7, loss=67.8]\n",
      "Epoch 45/50: 100%|██████████| 1248/1248 [00:00<00:00, 4886.30sample/s, accuracy=58.7, loss=67.8]\n",
      "Epoch 46/50: 100%|██████████| 1248/1248 [00:00<00:00, 5249.79sample/s, accuracy=58.7, loss=67.8]\n",
      "Epoch 47/50: 100%|██████████| 1248/1248 [00:00<00:00, 5213.55sample/s, accuracy=58.7, loss=67.8]\n",
      "Epoch 48/50: 100%|██████████| 1248/1248 [00:00<00:00, 4968.79sample/s, accuracy=58.7, loss=67.7]\n",
      "Epoch 49/50: 100%|██████████| 1248/1248 [00:00<00:00, 5346.75sample/s, accuracy=58.7, loss=67.7]\n",
      "Epoch 50/50: 100%|██████████| 1248/1248 [00:00<00:00, 5604.06sample/s, accuracy=58.7, loss=67.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accs = k_fold_cross_validation(model, x, y, epochs_per_fold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.61538461538462"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60.09615384615385, 60.09615384615385, 56.00961538461539, 62.25961538461539]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.61538461538461"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x)\n",
    "accuracy_metric(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'layer-1',\n",
       "  'weights': array([[ 0.92075584,  0.98020454, -0.17354498,  0.54963896, -0.61341082],\n",
       "         [-0.3069449 , -0.31859287, -0.7935808 ,  0.24452297, -1.06643863],\n",
       "         [ 0.32264924, -0.32461446, -0.21445626, -0.47678489, -0.25638755],\n",
       "         [-0.62537194, -0.19053209, -0.21555031, -0.40445053, -0.1660093 ],\n",
       "         [-0.07174505,  0.42259881, -0.24471143, -0.01031693, -0.81025356],\n",
       "         [ 0.69404405,  0.21085697, -0.28454665,  0.52845819, -0.09958278],\n",
       "         [-0.14040927,  0.51493797,  0.30452068, -0.20036355,  0.52997397],\n",
       "         [ 0.35928047,  0.55598655,  0.20385861,  0.29601196, -0.03650077],\n",
       "         [-0.37006127, -0.24986717, -0.1882553 ,  0.28326173,  0.48526483],\n",
       "         [-0.69906679,  0.24546093, -0.45782992,  0.78897229, -0.65061248]]),\n",
       "  'biases': array([ 1.03922811, -0.59154367, -0.61716551, -0.83110799,  0.51746456]),\n",
       "  'activation': 'linear'},\n",
       " {'name': 'layer-2',\n",
       "  'weights': array([[ 0.03572792],\n",
       "         [ 0.08053775],\n",
       "         [-0.13718967],\n",
       "         [-0.02308033],\n",
       "         [ 0.03733735]]),\n",
       "  'biases': array([-0.57042209]),\n",
       "  'activation': 'sigmoid'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y)):\n",
    "    if predictions[i]==1:\n",
    "        count+=1\n",
    "        # print(x[i], y[i], predictions[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sem8",
   "language": "python",
   "name": "env_sem8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
