{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    with open(\"./data/train.jsonl\", 'r') as f:\n",
    "        train_data = [json.loads(line) for line in f]\n",
    "\n",
    "    tag_mapping = {1: \"NN\", 2: \"DT\", 3: \"JJ\", 4: \"OT\"}\n",
    "\n",
    "    # Preprocess training data\n",
    "    train_sentences = []\n",
    "    train_labels = []\n",
    "    for entry in train_data:\n",
    "        tokens = entry['tokens']\n",
    "        pos_tags = entry['pos_tags']\n",
    "        chunk_tags = entry['chunk_tags']\n",
    "        \n",
    "        train_sentences.append(pos_tags)\n",
    "        train_labels.append(chunk_tags)\n",
    "\n",
    "    with open(\"./data/test.jsonl\", 'r') as f:\n",
    "        test_data = [json.loads(line) for line in f]\n",
    "    # Preprocess training data\n",
    "    test_sentences = []\n",
    "    test_labels = []\n",
    "    for entry in test_data:\n",
    "        tokens = entry['tokens']\n",
    "        pos_tags = entry['pos_tags']\n",
    "        chunk_tags = entry['chunk_tags']\n",
    "        \n",
    "        test_sentences.append(pos_tags)\n",
    "        test_labels.append(chunk_tags)\n",
    "    \n",
    "    return train_sentences, test_sentences,  train_labels, test_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test= fetch_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 3, 1, 4, 4, 3, 1, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(input_list):\n",
    "    encoded_list = []\n",
    "    for item in input_list:\n",
    "        one_hot_vector = np.zeros(4)\n",
    "        one_hot_vector[item - 1] = 1  # Adjust index to start from 0\n",
    "        encoded_list.append(one_hot_vector.tolist())\n",
    "    return np.array(encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.array([1,0,0]), np.array([1,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_ho(X_train):\n",
    "    X_train_ho = []\n",
    "    for i in range(len(X_train)):\n",
    "        X = one_hot_encode(X_train[i])\n",
    "        temp = []\n",
    "        for j in range(len(X)):\n",
    "            if j==0:\n",
    "                temp.append(np.concatenate([np.array([1.0,0.0,0.0,0.0,0.0]), X[j]]))\n",
    "            else:\n",
    "                temp.append((np.concatenate([np.array([0]), X[j-1], X[j]] )))\n",
    "        X_train_ho.append(np.array(temp))\n",
    "    return X_train_ho\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ho = into_ho(X_train)\n",
    "X_test_ho = into_ho(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train[0],\"\\n\",X_train_ho[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ho[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1.0+(np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.array([0]), X_train_ho[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleRecurrentPerceptron:\n",
    "    def __init__(self, vec_len):\n",
    "          \n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.random.randn(vec_len+1)\n",
    "        self.threshold = np.random.randn(1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Input is of shape (Tx, 10) where tx is number of words in that example and 10 is length of vector representation of one word\"\"\"\n",
    "        out= []\n",
    "        Tx, _ = inputs.shape\n",
    "        y_prev=0\n",
    "        for i in range(Tx):\n",
    "            x = np.concatenate([np.array([y_prev]),inputs[i]])\n",
    "            x = x.T @ self.weights - self.threshold[0]\n",
    "            x = sigmoid(x)\n",
    "            y_prev = x\n",
    "            out.append(x)\n",
    "        return np.array(out)\n",
    "    \n",
    "    def backward(self, inputs, target):\n",
    "        prediction = self.forward(inputs)\n",
    "        prediction = np.array(prediction)  # Ensure prediction is a NumPy array\n",
    "        target = np.array(target)  # Ensure target is a NumPy array\n",
    "        target = target[:, np.newaxis]  # Reshape target to match prediction's shape\n",
    "        inputs = inputs[:, np.newaxis]  # Reshape inputs to match prediction's shape\n",
    "        print(\"Target:\", target)\n",
    "        print(\"Prediction:\", prediction)\n",
    "        print(\"Inputs:\", inputs)\n",
    "        print(\"Target shape:\", target.shape)\n",
    "        print(\"Prediction shape:\", prediction.shape)\n",
    "        print(\"Inputs shape:\", inputs.shape)\n",
    "        error = target - prediction\n",
    "        self.weights += self.learning_rate * error * inputs\n",
    "        self.bias += self.learning_rate * error\n",
    "\n",
    "        \n",
    "    def train(self, inputs, targets, epochs):\n",
    "        for _ in range(epochs):\n",
    "            for i in range(len(inputs)):\n",
    "                self.backward(inputs[i], targets[i])\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        predictions = []\n",
    "        for input_data in inputs:\n",
    "            prediction = self.forward(input_data)\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleRecurrentPerceptron(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31393441, 0.11372466])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(X_train_ho[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_mapping = {1: \"NN\", 2: \"DT\", 3: \"JJ\", 4: \"OT\"}\n",
    "\n",
    "# Calculate the number of unique POS tags\n",
    "num_unique_tags = len(tag_mapping)\n",
    "\n",
    "# Preprocess training data\n",
    "# Preprocess training data\n",
    "train_sentences = []\n",
    "train_labels = []\n",
    "for entry in train_data:\n",
    "    tokens = entry['tokens']\n",
    "    pos_tags = entry['pos_tags']\n",
    "    chunk_tags = entry['chunk_tags']\n",
    "    \n",
    "    # Convert POS tags to one-hot encoded representation\n",
    "    pos_tags_one_hot = np.zeros((len(pos_tags), num_unique_tags))\n",
    "    for i, tag in enumerate(pos_tags):\n",
    "        pos_tags_one_hot[i, tag - 1] = 1  # Subtract 1 to account for 0-based indexing\n",
    "    \n",
    "    # Flatten one-hot encoded representation\n",
    "    flattened_tags = pos_tags_one_hot.flatten()\n",
    "    \n",
    "    train_sentences.append(flattened_tags)\n",
    "    train_labels.append(chunk_tags)\n",
    "\n",
    "\n",
    "# Initialize and train the single recurrent perceptron\n",
    "# Initialize and train the single recurrent perceptron\n",
    "input_size = len(train_sentences[0])  # Get input size from the first sample\n",
    "output_size = 2  # Binary classification (1 for chunk, 0 for not chunk)\n",
    "perceptron = SingleRecurrentPerceptron(input_size, output_size)\n",
    "perceptron.train(train_sentences, train_labels, epochs=10)\n",
    "\n",
    "\n",
    "\n",
    "# Load test data\n",
    "with open('test.jsonl', 'r') as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Preprocess test data\n",
    "test_sentences = []\n",
    "test_labels = []\n",
    "for entry in test_data:\n",
    "    tokens = entry['tokens']\n",
    "    pos_tags = entry['pos_tags']\n",
    "    chunk_tags = entry['chunk_tags']\n",
    "    \n",
    "    # Convert POS tags to one-hot encoded representation\n",
    "    pos_tags_one_hot = np.zeros((len(pos_tags), len(tag_mapping)))\n",
    "    for i, tag in enumerate(pos_tags):\n",
    "        pos_tags_one_hot[i, tag - 1] = 1  # Subtract 1 to account for 0-based indexing\n",
    "    \n",
    "    test_sentences.append(pos_tags_one_hot)\n",
    "    test_labels.append(chunk_tags)\n",
    "\n",
    "# Evaluate the trained perceptron\n",
    "predictions = perceptron.predict(test_sentences)\n",
    "\n",
    "# Assuming we have some evaluation function to compute accuracy\n",
    "# Let's assume a simple accuracy calculation for demonstration\n",
    "def accuracy(predictions, targets):\n",
    "    correct = 0\n",
    "    total = len(predictions)\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        pred_labels = [1 if p > 0 else 0 for p in pred]\n",
    "        if pred_labels == target:\n",
    "            correct += 1\n",
    "    return correct / total\n",
    "\n",
    "acc = accuracy(predictions, test_labels)\n",
    "print(\"Accuracy:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice_linux",
   "language": "python",
   "name": "practice_linux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
