{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    with open(\"./data/train.jsonl\", 'r') as f:\n",
    "        train_data = [json.loads(line) for line in f]\n",
    "\n",
    "    tag_mapping = {1: \"NN\", 2: \"DT\", 3: \"JJ\", 4: \"OT\"}\n",
    "\n",
    "    # Preprocess training data\n",
    "    train_sentences = []\n",
    "    train_labels = []\n",
    "    for entry in train_data:\n",
    "        tokens = entry['tokens']\n",
    "        pos_tags = entry['pos_tags']\n",
    "        chunk_tags = np.array(entry['chunk_tags'])\n",
    "        \n",
    "        train_sentences.append(pos_tags)\n",
    "        train_labels.append(chunk_tags)\n",
    "\n",
    "    with open(\"./data/test.jsonl\", 'r') as f:\n",
    "        test_data = [json.loads(line) for line in f]\n",
    "    # Preprocess training data\n",
    "    test_sentences = []\n",
    "    test_labels = []\n",
    "    for entry in test_data:\n",
    "        tokens = entry['tokens']\n",
    "        pos_tags = entry['pos_tags']\n",
    "        chunk_tags = np.array(entry['chunk_tags'])\n",
    "        \n",
    "        test_sentences.append(pos_tags)\n",
    "        test_labels.append(chunk_tags)\n",
    "    \n",
    "    return train_sentences, test_sentences,  train_labels, test_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test= fetch_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(input_list):\n",
    "    encoded_list = []\n",
    "    for item in input_list:\n",
    "        one_hot_vector = np.zeros(4)\n",
    "        one_hot_vector[item - 1] = 1  # Adjust index to start from 0\n",
    "        encoded_list.append(one_hot_vector.tolist())\n",
    "    return np.array(encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.array([1,0,0]), np.array([1,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_ho(X_train):\n",
    "    X_train_ho = []\n",
    "    for i in range(len(X_train)):\n",
    "        X = one_hot_encode(X_train[i])\n",
    "        temp = []\n",
    "        for j in range(len(X)):\n",
    "            if j==0:\n",
    "                temp.append(np.concatenate([np.array([1.0,0.0,0.0,0.0,0.0]), X[j]]))\n",
    "            else:\n",
    "                temp.append((np.concatenate([np.array([0]), X[j-1], X[j]] )))\n",
    "        X_train_ho.append(np.array(temp))\n",
    "    return X_train_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ho = into_ho(X_train)\n",
    "X_test_ho = into_ho(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train[0],\"\\n\",X_train_ho[0])\n",
    "# X_train_ho[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1.0+(np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.array([0]), X_train_ho[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9, 8.9])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8.9*np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy_loss(y_true, y_pred, epsilon=1e-15):\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    total_loss = np.sum(loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleRecurrentPerceptron:\n",
    "    def __init__(self, vec_len, lr):\n",
    "          \n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(vec_len)\n",
    "        self.threshold = np.random.randn(1)\n",
    "        self.lr = lr\n",
    "\n",
    "   \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"inputs-- (B, Tx, 10)\"\"\"   \n",
    "        prediction= []    #(B, Tx)\n",
    "        X_i_b = []      #(B, Tx, 10)\n",
    "        for j in range(len(inputs)):\n",
    "            out=[]\n",
    "            X_i_j = []\n",
    "            Tx, _ = inputs[j].shape\n",
    "            y_prev=0\n",
    "            for i in range(Tx):\n",
    "                x = np.concatenate([inputs[j][i], np.array([y_prev])])\n",
    "                X_i_j.append(x)\n",
    "                net = x.T @ self.weights - self.threshold[0]\n",
    "                oi = sigmoid(net)\n",
    "                y_prev = oi\n",
    "                out.append(oi)\n",
    "            prediction.append(np.array(out))\n",
    "            X_i_b.append(np.array(X_i_j))\n",
    "        return X_i_b, prediction\n",
    "    \n",
    "    def forward_per_input(self, inputs):\n",
    "        \"\"\"inputs-- (Tx, 10) \"\"\"   \n",
    "        out=[]    #(Tx, 1)\n",
    "        X_i_j = []  #(Tx, 10)\n",
    "        Tx = len(inputs)\n",
    "        y_prev=0\n",
    "        for i in range(Tx):\n",
    "            x = np.concatenate([inputs[i], np.array([y_prev])])\n",
    "            X_i_j.append(x)\n",
    "            x = x.T @ self.weights - self.threshold[0]\n",
    "            x = sigmoid(x)\n",
    "            y_prev = x\n",
    "            out.append(x)\n",
    "\n",
    "        return np.array(X_i_j), out\n",
    "\n",
    "    def backward(self, inputs, target):\n",
    "        \"\"\"inputs-- (B, Tx, 10)\n",
    "           target-- (B, Tx)\n",
    "            \"\"\"   \n",
    "        X, prediction = self.forward(inputs)\n",
    "\n",
    "        for i in range(len(inputs)):      # iterate over each example\n",
    "            delta_w = np.zeros(10)\n",
    "            for j in range(len(inputs[i])):     # iterate over each time\n",
    "                x = X[i][j]\n",
    "                delta_w += -self.lr * (target[i][j]-prediction[i][j]) * (x)\n",
    "            self.weights += delta_w\n",
    "    \n",
    "\n",
    "    def backward_per_input(self, inputs, target):\n",
    "        \"\"\"inputs-- (B, Tx, 10)\n",
    "           target-- (B, Tx)\n",
    "            \"\"\"   \n",
    "        # print(self.weights)\n",
    "        for i in range(len(inputs)): \n",
    "            X, prediction = self.forward_per_input(inputs[i])\n",
    "            delta_w = np.zeros(10)\n",
    "            for j in range(len(inputs[i])):     # iterate over each time\n",
    "                delta_w += self.lr * (target[i][j]-prediction[j]) * X[j]\n",
    "            self.weights += delta_w\n",
    "        # print(self.weights)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_loss(self, inputs, targets):\n",
    "        loss = 0\n",
    "        for i in range(len(inputs)):\n",
    "            _ , y_pred = self.forward_per_input(inputs[i])\n",
    "            loss += binary_crossentropy_loss(targets[i], y_pred, epsilon=1e-15)\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def train(self, inputs, targets, epochs):\n",
    "        \"\"\"inputs-- (B, Tx, 10)\n",
    "           target-- (B, Tx)\n",
    "            \"\"\"           \n",
    "        for iter in range(epochs):\n",
    "            self.backward_per_input(inputs, targets)\n",
    "            loss = self.calculate_loss(inputs, targets)\n",
    "            print(f\"epoch: {iter}, training loss : {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleRecurrentPerceptron(10, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.forward_per_input(X_train_ho[0:8][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, training loss : 93463.06759993888\n",
      "epoch: 1, training loss : 93459.3304778473\n",
      "epoch: 2, training loss : 93458.12251875624\n",
      "epoch: 3, training loss : 93457.52444166772\n",
      "epoch: 4, training loss : 93457.16753589087\n",
      "epoch: 5, training loss : 93456.93043352004\n",
      "epoch: 6, training loss : 93456.76149540758\n",
      "epoch: 7, training loss : 93456.63502768459\n",
      "epoch: 8, training loss : 93456.53680672772\n",
      "epoch: 9, training loss : 93456.45832167412\n",
      "epoch: 10, training loss : 93456.3941683143\n",
      "epoch: 11, training loss : 93456.34075023656\n",
      "epoch: 12, training loss : 93456.29558132659\n",
      "epoch: 13, training loss : 93456.25688803032\n",
      "epoch: 14, training loss : 93456.22337114139\n",
      "epoch: 15, training loss : 93456.19405718618\n",
      "epoch: 16, training loss : 93456.16820236985\n",
      "epoch: 17, training loss : 93456.14522859486\n",
      "epoch: 18, training loss : 93456.12467978313\n",
      "epoch: 19, training loss : 93456.1061912841\n",
      "epoch: 20, training loss : 93456.08946806188\n",
      "epoch: 21, training loss : 93456.07426884418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[504], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m128\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_per_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_ho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcalculate_loss(X_train_ho, y_train)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, training loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[500], line 66\u001b[0m, in \u001b[0;36mSingleRecurrentPerceptron.backward_per_input\u001b[0;34m(self, inputs, target)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(self.weights)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)): \n\u001b[0;32m---> 66\u001b[0m     X, prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_per_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     delta_w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs[i])):     \u001b[38;5;66;03m# iterate over each time\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[500], line 37\u001b[0m, in \u001b[0;36mSingleRecurrentPerceptron.forward_per_input\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     35\u001b[0m y_prev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Tx):\n\u001b[0;32m---> 37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_prev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     X_i_j\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iter in range(128):\n",
    "    model.backward_per_input(X_train_ho, y_train)\n",
    "    loss = model.calculate_loss(X_train_ho, y_train)\n",
    "    print(f\"epoch: {iter}, training loss : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.64954474060637"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.calculate_loss(X_train_ho[:9], y_train[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backward_per_input(X_train_ho[1:90], y_train[1:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, training loss : 93456.04958774277\n",
      "epoch: 1, training loss : 93456.036413005\n",
      "epoch: 2, training loss : 93456.02558587158\n",
      "epoch: 3, training loss : 93456.01556359754\n",
      "epoch: 4, training loss : 93456.00625960386\n"
     ]
    }
   ],
   "source": [
    "model.train(X_train_ho, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backward_per_input(X_train_ho[1:8], y_train[1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.53673132608883"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_crossentropy_loss(y_train[0], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_mapping = {1: \"NN\", 2: \"DT\", 3: \"JJ\", 4: \"OT\"}\n",
    "\n",
    "# Calculate the number of unique POS tags\n",
    "num_unique_tags = len(tag_mapping)\n",
    "\n",
    "# Preprocess training data\n",
    "# Preprocess training data\n",
    "train_sentences = []\n",
    "train_labels = []\n",
    "for entry in train_data:\n",
    "    tokens = entry['tokens']\n",
    "    pos_tags = entry['pos_tags']\n",
    "    chunk_tags = entry['chunk_tags']\n",
    "    \n",
    "    # Convert POS tags to one-hot encoded representation\n",
    "    pos_tags_one_hot = np.zeros((len(pos_tags), num_unique_tags))\n",
    "    for i, tag in enumerate(pos_tags):\n",
    "        pos_tags_one_hot[i, tag - 1] = 1  # Subtract 1 to account for 0-based indexing\n",
    "    \n",
    "    # Flatten one-hot encoded representation\n",
    "    flattened_tags = pos_tags_one_hot.flatten()\n",
    "    \n",
    "    train_sentences.append(flattened_tags)\n",
    "    train_labels.append(chunk_tags)\n",
    "\n",
    "\n",
    "# Initialize and train the single recurrent perceptron\n",
    "# Initialize and train the single recurrent perceptron\n",
    "input_size = len(train_sentences[0])  # Get input size from the first sample\n",
    "output_size = 2  # Binary classification (1 for chunk, 0 for not chunk)\n",
    "perceptron = SingleRecurrentPerceptron(input_size, output_size)\n",
    "perceptron.train(train_sentences, train_labels, epochs=10)\n",
    "\n",
    "\n",
    "\n",
    "# Load test data\n",
    "with open('test.jsonl', 'r') as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Preprocess test data\n",
    "test_sentences = []\n",
    "test_labels = []\n",
    "for entry in test_data:\n",
    "    tokens = entry['tokens']\n",
    "    pos_tags = entry['pos_tags']\n",
    "    chunk_tags = entry['chunk_tags']\n",
    "    \n",
    "    # Convert POS tags to one-hot encoded representation\n",
    "    pos_tags_one_hot = np.zeros((len(pos_tags), len(tag_mapping)))\n",
    "    for i, tag in enumerate(pos_tags):\n",
    "        pos_tags_one_hot[i, tag - 1] = 1  # Subtract 1 to account for 0-based indexing\n",
    "    \n",
    "    test_sentences.append(pos_tags_one_hot)\n",
    "    test_labels.append(chunk_tags)\n",
    "\n",
    "# Evaluate the trained perceptron\n",
    "predictions = perceptron.predict(test_sentences)\n",
    "\n",
    "# Assuming we have some evaluation function to compute accuracy\n",
    "# Let's assume a simple accuracy calculation for demonstration\n",
    "def accuracy(predictions, targets):\n",
    "    correct = 0\n",
    "    total = len(predictions)\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        pred_labels = [1 if p > 0 else 0 for p in pred]\n",
    "        if pred_labels == target:\n",
    "            correct += 1\n",
    "    return correct / total\n",
    "\n",
    "acc = accuracy(predictions, test_labels)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice_linux",
   "language": "python",
   "name": "practice_linux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
